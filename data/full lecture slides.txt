CS 15: Data Structures
     Binary Search
---
Find Element in List
•  We’ve talked about variations of a find operation
   for lists
   ‣  Given an element and a list, return true if element is in list,
      false otherwise
                             2
---
     Find Element in List
                             Consider a list of ints:
             ArrayList
bool ArrayList::find(int   x)
{
    for  (int i = 0; i  <  size; i++) {
         if  (array[i] ==  x)
             return true;
    }
    return   false;
}
                                        3
---
     Find Element in List
                             Consider a list of ints:
             ArrayList                                  Linked List
bool ArrayList::find(int   x)                   bool LinkedList::find(int   x)
{   for  (int i = 0; i  <  size; i++) {         {   Node *curr  = front;
         if  (array[i] ==  x)                       while (curr !=  nullptr) {
             return true;                               if  (curr->data ==  x)
    }                                                   currreturn  true;
}   return   false;                                 }        =  curr->next;
                                                    return  false;
                                                }
                   Assuming a list of size n, what are
               the time complexities in Big O notation?
                                        4
---
     Find Element in List
                             Consider a list of ints:
             ArrayList                                  Linked List
bool ArrayList::find(int   x)                   bool LinkedList::find(int   x)
{   for  (int i = 0; i  <  size; i++) {         {   Node *curr  = front;
         if  (array[i] ==  x)  O(1)    O(n)         while (curr !=  nullptr) {
             return true;                               if  (curr->data ==  x)
    }                                                   currreturn  true;
}   return   false;  O(1)                           }        =  curr->next;
                                                    return  false;
                                                }
     O(n) * O(1) + O(1) is O(n)!
                                        5
---
     Find Element in List
                             Consider a list of ints:
             ArrayList                                  Linked List
bool ArrayList::find(int   x)                   bool LinkedList::find(int   x)
{   for  (int i = 0; i  <  size; i++) {         {   Node *curr  = front;
         if  (array[i] ==  x)                       while (curr !=  nullptr) {
             return true;                               if  (curr->data ==  x)
    }                                                   currreturn  true;
}   return   false;                                 }        =  curr->next;
                                                    return  false;
                                                }
     O(n) * O(1) + O(1) is O(n)!                Analysis is similar: O(n)
                                        6
---
Find: Can we do better?
•  Not if we don’t know anything about the list
   ‣ Have no info, so we must compare with each element
                             7
---
Find in a Sorted List
•  What if the list is sorted?
   ‣  Say, from smallest to largest
   ‣  e.g., [1, 5, 9, 13, 20, … ]
•  What process can I use to search for an element x?
                             8
---
Step 1: the High-Level Algorithm
Searching for an integer x:
1.  Start with the index   middle=list.size()/2
2.  If list[middle]      ==  x, we’re done! Return true.
3.  Otherwise:
   -  If x<list[middle], we know that x can only be in the first half
      of the list. Start from Step 1 with subarray from 0 to middle-1
   -  If list[middle]<x, we know that x can only be in the second
      half of the list. Start from Step 1 with subarray from middle+1
      to size-1.
Continue until remaining list is empty, then return false.
                             9
---
Binary Search
•  This algorithm is called binary search
•  You’ve probably used this algorithm before!
   ‣  To look up a word in a dictionary
   ‣  To look up a number in a phonebook
   ‣  Playing the guessing game: “I’m thinking of a number from 1 to N”
                            10
---
   Binary Search: Code
                                                        is_in_array.cpp
/*                                                 Credit: Mark Sheldon
 *  Return true if target   is in array slots [start .. end)
 *  Note:  includes start   index,  but not end index
 *         i. e., search a whole    array by searching in [0 .. length)
 */
bool is_in_array(ElemType array[], ElemType target, int start, int end)
{
        int length  =  end  - start;
        int middle  =  start + (length / 2);
        if (end   <= start)
                  return false;
        else  if  (target  == array[middle])
                  return true;
        else  if  (target  > array[middle])
                  return is_in_array(array, target, middle  + 1, end);
        else
                  return is_in_array(array, target, start,  middle);
}
                                    11
---
Binary Search: Complexity?
• Notice: For each comparison we make, we cut the
   search space in half
   ‣ We’ve seen this pattern before…
• Time complexity: O(log n)!
•  Any time we continuously cut a number n in half, we
   can do so log₂(n) times
   ‣  This pattern comes up frequently in CS!
   ‣  See Computational Complexity slides for more details
                            12
---
Binary Search Restrictions
•  List must be sortable. This means the element type
   must be comparable.
   ‣  ints are comparable with <, >
   ‣  strings are comparable with <, > (which use lexicographic order)
   ‣  A custom type, e.g. Person, may not be comparable
      - Unless we define custom comparison operations
                               13
---
Binary Search Restrictions
•  Should we use an ArrayList or Linked List with binary
   search?
• Answer: ArrayList.
   ‣  It gives us constant-time access to any index in list, which is
      why we can achieve O(log n) binary search
   ‣  With linked list, need to traverse list to reach elements
                            14
---
Binary Search Restrictions
•  What is the complexity for inserting/removing from a
   sorted ArrayList if we want to maintain sorted order?
• Answer: O(n) for both insertion and removal
   ‣  Can’t just insert at back: need to insert at a specific index to
      maintain sorted order
• Binary search improves search complexity to O(log n),
   but does not improve insertion/removal complexity
•  In contrast, a balanced BST (e.g., an AVL tree) can
   oﬀer O(log n) for insertion/removal as well
                         15
---
   CS 15: Data Structures
Binary Trees and their Traversals
---
Last Time
•  We saw trees: a non-linear, hierarchical data structure
•  Recall:
   ‣  A tree is either empty or non-empty
   ‣  If non-empty, there is a distinguished root node, and each node
      has pointers to 0 or more subtrees
   ‣  Every node has exactly one parent, except the root which has
      no parent
                              2
---
Binary Trees
• Today, we focus on binary trees: trees where each
   node has a maximum of 2 children
•  We call these children the left child and right child
     struct   BinaryTreeNode     {
        int  data;
        BinaryTreeNode    *left, *right;
     };
                        A
                  B           C
               left child  right child
                        3
---
Detour: Finite Map ADT
•  Recall: ArrayLists, Linked Lists often used to implement
   the list ADT
•  Trees, and especially binary trees, are often used to
   implement the finite map ADT
   ‣ Other names/variations: maps, dictionaries, associative arrays
•  Main idea: a finite map is a collection of (key, value) pairs
   • The key is what we use for lookup
   • The value is the data we want to store
                           4
---
Finite Map: Examples
•  Dictionaries
   ‣  Key is word, value is definition
•  Contact list
   ‣  Key is person’s name, value is info (phone #, address, …)
•  Hospital records
   ‣  Key is wristband number, value is patient information
• …
                             5
---
Finite Map ADT
add(KeyType key, ValueType val)
 ‣ map.add(k,v) is often expressed map[k]=v
                    6
---
Finite Map ADT
add(KeyType key,     ValueType   val)
  ‣  map.add(k,v) is often expressed map[k]=v
remove(KeyType    key)
  ‣  Removes (key, value) pair from the map
                        7
---
Finite Map ADT
add(KeyType key,     ValueType   val)
  ‣  map.add(k,v) is often expressed map[k]=v
remove(KeyType    key)
  ‣  Removes (key, value) pair from the map
lookup(KeyType    key)
  ‣  Returns the associated value
  ‣  map.lookup(k) is often expressed map[k]
                        8
---
Finite Map ADT
add(KeyType key,     ValueType   val)
  ‣  map.add(k,v) is often expressed map[k]=v
remove(KeyType    key)
  ‣  Removes (key, value) pair from the map
lookup(KeyType    key)
  ‣  Returns the associated value
  ‣  map.lookup(k) is often expressed map[k]
reassign(KeyType key,      ValueType   val)
  ‣  Again map.reassign(k,v) is often expressed map[k]=v
                        9
---
Finite Map ADT
•  May include other operations like contains,
   size, construction of an iterator, etc.
                        10
---
  Binary Trees as Finite Maps
  •  We’ll see soon why binary trees work well as finite maps
     ‣ They can oﬀer quick lookup, insertion, deletion
  •  Just need to tweak binary tree node, so it stores both
     key and value:
     could also store these  struct BinaryTreeNode {
     in a separate struct,  KeyType key;
          depending on      ValueType val;
implementation              BinaryTreeNode *left, *right;
                  };
                             11
---
Binary Trees as Finite Maps
•  Note: Sometimes we’ll use binary trees as a finite map,
   other times, we’ll just store one data element in each
   node
   ‣  e.g., a string or an integer without an associated key
   ‣  We can also think of this as the key and value being the same
                            12
---
 Binary Trees: Height
             A                                  17
     B              C                  42              42
D       E      F        G                  10      2
       Height = 2                             29       30
                                              Height = 3
       Recall: The height of a node is the length of
         the longest path from that node to a leaf.
         The height of a tree is the height of the root.
             What are the heights of these trees?
                              13
---
    Binary Trees: Height
                A                                 17
       B              C                  42             42
   D       E      F       G                  10     2
                                                29      30
For a tree with N nodes, what is the    Max height = N-1
   maximum possible tree height?           -When the tree is a linked list
                                14
---
     Binary Trees: Height
                 A                                 17
        B              C                  42             42
    D       E      F       G                  10     2
                                                 29      30
For a binary tree with N nodes, what is the
       minimum possible tree height?
                                 15
---
Minimum Tree Height
•  Tree height is minimum when we “fill up” each level before
   adding nodes to the next level
•  Level 0 can store 1 node, level 1 can store 2 nodes, level 2
   can store 4 nodes…
   ‣  In general, level x can store 2ˣ nodes
•  A full binary tree with m levels:
   ‣  Has height m-1
   ‣  Can store up to 2⁰ + 2¹ +…+ 2ᵐ⁻¹ nodes. This is 2ᵐ-1 (proof omitted)
                               16
---
Minimum Tree Height
For tree with N nodes, min_height=m-1 when N=2ᵐ-1
Solve for m!
m=log(N+1)
min_height=log(N+1)-1
Actually, min_height should always be an integer, so we
need to apply ceiling:
min_height=ceil(log(N+1)-1)
Or, using Big O, min_height is O(log N)
                       17
---
Binary Tree: Example Use
•  We can use binary trees to represent arithmetic
   operations
   ‣  When the operations are over two operands
   ‣  Such trees are sometimes called expression trees
•  Leaves represent numbers or variables, internal
   nodes represent operations carried out on subtrees
Example: (a   + 3)   * (b  - 2)
                           *
                    +            -
                 a     3      b     2
                          18
---
Binary Tree: Example Use
(a +   3) *  (b -   2)     *
                    +            -
                 a     3      b     2
•  Notice: we don’t have to store parentheses in the tree.
   The structure of the expression is built in to the tree
                          19
---
Binary Tree: Example Use
• Come up with the binary expression tree representing:
a * (4 + 3) - b
                          20
---
Binary Tree: Example Use
• Come up with the binary expression tree representing:
a * (4 + 3) - b
                                -
                        *
                            +
                 a      4     3        b
                          21
---
 Practice Problem
 Let’s go in the other direction: Given the root of a tree
 representing an arithmetic expression, define a pseudocode
 procedure printExp(node)       which prints out the arithmetic
 expression.
 The printed expression should be correctly parenthesized. It’s
 okay if it contains more parentheses than necessary.
 Example:                              printExp(root) should print:
root
              *                              ((a + 3) * (b - 2))
                                                    or
      +               -                     ((a) + (3)) * ((b) - (2))
  a       3       b      2         or any correct paren placement
                                22
---
Practice Problem
printExp(node):
  if  (node is empty tree)
      return;
  else
      cout  << “(“;
      printExp(node->left);
      cout  << node->data;
      printExp(node->right);
      cout  << “)”;
                              23
---
Practice Problem
printExp(node):                      root
  if  (node is empty tree)                        *
      return;
  else                                     +              -
      cout  << “(“;
      printExp(node->left);            a      3       b      2
      cout  << node->data;                printExp(root) output:
      printExp(node->right);
      cout  << “)”;                  (((a)+(3))*((b)-(2)))
             Note: We could also come up with ways
             to reduce unneeded parentheses, e.g.,
             add a “node is  leaf” case
                              24
---
In-Order Traversal
•  Notice the order we visited nodes in the tree:
   ‣  Recursively visit left subtree of current node
   ‣  Visit current node
   ‣  Recursively visit right subtree of current node
•  This is called an in-order traversal
                            25
---
     Binary Tree Traversals
In-Order                    Pre-Order                    Post-Order
   ‣  Handle empty tree        ‣  Handle empty tree         ‣  Handle empty tree
   ‣  Visit left subtree       ‣  Visit current node        ‣  Visit left subtree
   ‣  Visit current node       ‣  Visit left subtree        ‣  Visit right subtree
   ‣  Visit right subtree      ‣  Visit right subtree       ‣  Visit current node
                                       26
---
     Binary Tree Traversals
In-Order                    Pre-Order                    Post-Order
   ‣  Handle empty tree        ‣  Handle empty tree         ‣  Handle empty tree
   ‣  Visit left subtree       ‣  Visit current node        ‣  Visit left subtree
   ‣  Visit current node       ‣  Visit left subtree        ‣  Visit right subtree
   ‣  Visit right subtree      ‣  Visit right subtree       ‣  Visit current node
    Visiting Order:               Visiting Order:              Visiting Order:
    DBEAFCG                           ABDECFG                      DEBFGCA
                                         A
                               B                 C
                         D         E        F         G
                                       27
---
     Binary Tree Traversals
In-Order                     Pre-Order                    Post-Order
   ‣  Handle empty tree         ‣  Handle empty tree         ‣  Handle empty tree
   ‣  Visit left subtree        ‣  Visit current node        ‣  Visit left subtree
   ‣  Visit current node        ‣  Visit left subtree        ‣  Visit right subtree
   ‣  Visit right subtree       ‣  Visit right subtree       ‣  Visit current node
    Visiting Order:                     Visiting Order:        Visiting Order:
  42, 10, 17, 29, 2, 30, 42        17, 42, 10, 42, 2, 29, 30  17  10, 42, 29, 30, 2, 42, 17
                                              42               42
                                                  10       2
                                                      29       30
                                        28
---
    Binary Tree Traversals
In-Order                  Pre-Order                  Post-Order
  ‣  Handle empty tree       ‣  Handle empty tree       ‣  Handle empty tree
  ‣  Visit left subtree      ‣  Visit current node      ‣  Visit left subtree
  ‣  Visit current node      ‣  Visit left subtree      ‣  Visit right subtree
  ‣  Visit right subtree     ‣  Visit right subtree     ‣  Visit current node
 •  In-order, pre-order, and post-order traversals are all types
    of depth-first traversal
    ‣ Go as deep into tree as possible before backtracking
                                     29
---
    Binary Tree Traversals
In-Order                  Pre-Order                  Post-Order
  ‣  Handle empty tree       ‣  Handle empty tree       ‣  Handle empty tree
  ‣  Visit left subtree      ‣  Visit current node      ‣  Visit left subtree
  ‣  Visit current node      ‣  Visit left subtree      ‣  Visit right subtree
  ‣  Visit right subtree     ‣  Visit right subtree     ‣  Visit current node
 •  Note: thus far, we have only looked at printing nodes
    according to diﬀerent traversals
 • But you may also want to perform some computation as
    you traverse the tree, too
                                     30
---
    Binary Tree Traversals
In-Order                  Pre-Order                  Post-Order
  ‣  Handle empty tree       ‣  Handle empty tree       ‣  Handle empty tree
  ‣  Visit left subtree      ‣  Visit current node      ‣  Visit left subtree
  ‣  Visit current node      ‣  Visit left subtree      ‣  Visit right subtree
  ‣  Visit right subtree     ‣  Visit right subtree     ‣  Visit current node
 • Question: Say your tree nodes are heap-allocated. What
    type of traversal should you use to recycle the nodes?
                         Answer: post-order!
                 Current node should be visited last,
                    otherwise you lose the pointers
                             to its subtrees.
                                     31
---
Breadth-First Traversal
• A breadth-first traversal    first visits the root, then all
   nodes at depth 1 from left-to-right, then all nodes at
   depth 2…
   ‣ Also called a level-order traversal
                              A
                      B              C
                 D       E       F       G
                  Order: A, B, C, D, E, F, G
                              32
---
Breadth-First Traversal
• A breadth-first traversal       first visits the root, then all
   nodes at depth 1 from left-to-right, then all nodes at
   depth 2…
   ‣ Also called a level-order traversal
                                17
                       42              42
                           10      2
                              29       30
                 Order: 17, 42, 42, 10, 2, 29, 30
                                 33
---
Breadth-First: Recursion?
•  It’s tricky to implement a breadth-first traversal
   recursively
   ‣ Possible, but ineﬃcient and unintuitive
• See why?
                             A
                     B              C
                D        E      F        G
                  Order: A, B, C, D, E, F, G
                              34
---
Breadth-First: Recursion?
•  When we call a function on a subtree, we only have
   access to that subtree
• But breadth-fiᵣₛₜ jumps between subtrees on
   diﬀerent sides
   ‣  e.g., we visit B (from left side), then C (from right side),
    then D and E, then …
                           A
                   B             C
              D       E      F       G
                 Order: A, B, C, D, E, F, G
                          35
---
Breadth-First Traversal
•  Can you come up with a non-recursive algorithm
   for breadth-first traversal?
   ‣ Hint: it uses a diﬀerent data structure we’ve learned about
                                                   A
                                           B              C
                                      D       E       F       G
                                        Order: A, B, C, D, E, F, G
                              36
---
Breadth-First Traversal
BFTraversal(root):
  queue<Node> q;
  q.enqueue(root);
  while(!q.isEmpty()):
    curr = q.top();
    if (curr  != nullptr)
       visit  curr;
       q.enqueue(curr->left)                      A
       q.enqueue(curr->right)
    q.dequeue()                           B              C
                                     D       E      F        G
                             37
---
 Breadth-First Traversal
 BFTraversal(root):
   queue<Node> q;
   q.enqueue(root);
   while(!q.isEmpty()):
     curr = q.top();
     if (curr  != nullptr)
        visit  curr;
        q.enqueue(curr->left)                      A
        q.enqueue(curr->right)
     q.dequeue()                           B              C
Example run:
    Queue: A                          D       E      F        G
    Visited:
                              38
---
 Breadth-First Traversal
 BFTraversal(root):
   queue<Node> q;
   q.enqueue(root);
   while(!q.isEmpty()):
     curr = q.top();
     if (curr  != nullptr)
        visit  curr;
        q.enqueue(curr->left)                      A
        q.enqueue(curr->right)
     q.dequeue()                           B              C
Example run:
    Queue: B, C                       D       E      F        G
    Visited: A
                              39
---
 Breadth-First Traversal
 BFTraversal(root):
   queue<Node> q;
   q.enqueue(root);
   while(!q.isEmpty()):
     curr = q.top();
     if (curr  != nullptr)
        visit  curr;
        q.enqueue(curr->left)                      A
        q.enqueue(curr->right)
     q.dequeue()                           B              C
Example run:
    Queue: C, D, E                    D       E      F        G
    Visited: A, B
                              40
---
 Breadth-First Traversal
 BFTraversal(root):
   queue<Node> q;
   q.enqueue(root);
   while(!q.isEmpty()):
     curr = q.top();
     if (curr  != nullptr)
        visit  curr;
        q.enqueue(curr->left)                      A
        q.enqueue(curr->right)
     q.dequeue()                           B              C
Example run:
    Queue: D, E, F, G                 D       E      F        G
    Visited: A, B, C
                              41
---
 Breadth-First Traversal
 BFTraversal(root):
   queue<Node> q;
   q.enqueue(root);
   while(!q.isEmpty()):
     curr = q.top();
     if (curr  != nullptr)
        visit  curr;
        q.enqueue(curr->left)                      A
        q.enqueue(curr->right)
     q.dequeue()                           B              C
Example run:
    Queue: E, F, G, nullptr, nullptr  D       E      F        G
    Visited: A, B, C, D
                              42
---
 Breadth-First Traversal
 BFTraversal(root):
   queue<Node> q;
   q.enqueue(root);
   while(!q.isEmpty()):
     curr = q.top();
     if (curr  != nullptr)
        visit  curr;
        q.enqueue(curr->left)                      A
        q.enqueue(curr->right)
     q.dequeue()                           B              C
Example run:
    Queue: F, G, nullptr, nullptr, nullptr, nullptr  D  E  F  G
    Visited: A, B, C, D, E
                              43
---
 Breadth-First Traversal
 BFTraversal(root):
   queue<Node> q;
   q.enqueue(root);
   while(!q.isEmpty()):
     curr = q.top();
     if (curr  != nullptr)
        visit  curr;
        q.enqueue(curr->left)                      A
        q.enqueue(curr->right)
     q.dequeue()                           B              C
Example run:
    Queue: G, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr  D  E  F  G
    Visited: A, B, C, D, E, F
                              44
---
 Breadth-First Traversal
 BFTraversal(root):
   queue<Node> q;
   q.enqueue(root);
   while(!q.isEmpty()):
     curr = q.top();
     if (curr  != nullptr)
        visit  curr;
        q.enqueue(curr->left)                      A
        q.enqueue(curr->right)
     q.dequeue()                           B              C
Example run:
    Queue:  nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr, nullptr D  E  F  G
    Visited: A, B, C, D, E, F, G  loop continues until all
                             nullptrs have been dequeued
                              45
---
Non-Recursive Depth-First
•  The depth-first traversals (in-order, pre-order, post-
   order) can also be implemented non-recursively
   ‣  Instead of a queue, we would use a stack
   ‣  Try it out on your own, see if you can come up with a solution!
                             46
---
Binary Tree Exercises
•  numLeaves(node): count number of leaves in the tree
   rooted at node
•  concatLeaves(node): For a tree rooted at node that
   stores strings, return the concatenation of all strings stored
   in the leaves of the tree only
•  pathToValue(node,val): return “” if val is not in tree,
   otherwise return directions, like “went left, went right, went
   right, went left, found it!” (Don’t worry about punctuation
   and spacing — can just return a string like “LRRLTarget”
   where Target is the item we’re looking for.)
                               47
---
Binary Tree Exercises
•  All the previous exercises would be good exam
   questions
•  Additionally: given a tree, provide the in-order, pre-
   order, post-order, and level-order traversals
                         48
---
BST Invariant
• The BST invariant is a condition that must be true
   of every node in a BST
•  Invariant: For a given node n with key k,
   ‣  All nodes with keys less than k are in n’s left subtree
   ‣  All nodes with keys greater than k are in n’s right subtree
               42                        Remember:
                                    The BST invariant is
       17            84            true of every node in
  …         …     …      …                the BST.
                            1
---
 BST Implementation
class BST
{
public:
    BST();
    ~BST();
    ...
private:
    struct BSTNode {        As with linked lists, we keep
        int      key;
        BSTNode *left;          a private node struct,
    };  BSTNode *right;         and keep track of root
    BSTNode *root;             (instead of front) node
    ...
};
                           2
---
    BST: contains
// Return true if this BST contains given key, false otherwise
 bool BST::contains(KeyType key)
{
    return contains(key, root);
}
// Return true  if BST rooted at  tree contains given key, false otherwise
bool BST::contains(KeyType key,   BSTNode *tree)
{
    if (isEmpty(tree))
        return  false;
    else  if  (tree->key == key)
        return  true;
     What should go here?
    else  if  (key < tree->key)
        return  contains(tree->left);
    else  //  key > tree->key
        return  contains(tree->right);
}
                                   3
---
    BST: contains
// Return true if this BST contains given key, false otherwise
 bool BST::contains(KeyType key)
{
    return contains(key, root);
}
// Return true  if BST rooted at  tree contains given key, false otherwise
bool BST::contains(KeyType key,   BSTNode *tree)
{
    if (isEmpty(tree))
        return  false;
    else  if  (tree->key == key)
        return  true;
    else  if  (key < tree->key)
        return  contains(key,  tree->left);
    else  //  key > tree->key
        return  contains(key,  tree->right);
}
                                   4
---
    BST: contains
// Return true if this BST contains given key, false otherwise
 bool BST::contains(KeyType key)
{
    return contains(key, root);
}
// Return true  if BST rooted at  tree contains given key, false otherwise
bool BST::contains(KeyType key,   BSTNode *tree)
{
    if (isEmpty(tree))
    elsereturn  false;                        We can take advantage
          if  (tree->key == key)             of BST invariant. Don’t
    elsereturn  true;                      need to explore whole tree!
          if  (key < tree->key)
        return  contains(key,  tree->left);
    else  //  key > tree->key
        return  contains(key,  tree->right);
}
                                   4
---
BST: contains
•  Is 16 in this tree?
                               35
                     17                57
               12         28       40        84
            1       16
                                   5
---
BST: contains
•  Is 16 in this tree?
                                             16 < 35, so explore left
                               35
                     17                57
               12         28       40        84
            1       16
                                   5
---
BST: contains
•  Is 16 in this tree?
                               35
                     17                57
               12         28       40        84
            1       16
                                   6
---
BST: contains
•  Is 16 in this tree?
                                             16 < 17, so explore left
                               35
                     17                57
               12         28       40        84
            1       16
                                   6
---
BST: contains
•  Is 16 in this tree?
                               35
                     17                57
               12         28       40        84
            1       16
                                   7
---
BST: contains
•  Is 16 in this tree?
                                            16 > 12, so explore right
                               35
                     17                57
               12         28       40        84
            1       16
                                   7
---
BST: contains
•  Is 16 in this tree?
                                                    return true!
                               35
                     17                57
               12         28       40        84
            1       16
                                   8
---
contains: Complexity?
•  For tree of size n, what is the time complexity of BST
   contains?
                     9
---
contains: Complexity?
•  For tree of size n, what is the time complexity of BST
   contains?
•  If the BST is balanced: O(log n)
   ‣  Every step in tree cuts the search space in half. For n, this is at
      most log(n) steps.
   ‣  Can also think of it as: height of tree is O(log(n)), at most have
      to take height-of-tree steps
                           9
---
contains: Complexity?
•  For tree of size n, what is the time complexity of BST
   contains?
•  If the BST is balanced: O(log n)
   ‣  Every step in tree cuts the search space in half. For n, this is at
      most log(n) steps.
   ‣  Can also think of it as: height of tree is O(log(n)), at most have
      to take height-of-tree steps
•  In general, BST may not be balanced. So overall: O(n)
   ‣  Same as linked list. Potentially need to visit every element!
                           9
---
contains: Complexity?
•  For tree of size n, what is the time complexity of BST
   contains?
•  If the BST is balanced: O(log n)
   ‣  Every step in tree cuts the search space in half. For n, this is at
      most log(n) steps.
   ‣  Can also think of it as: height of tree is O(log(n)), at most have
      to take height-of-tree steps
•  In general, BST may not be balanced. So overall: O(n)
   ‣  Same as linked list. Potentially need to visit every element!
•  If we know tree height, we can say: O(height)
                           9
---
  BST: minimum
// Return minimum key in this BST.
// Returns INT_MAX if tree is empty.
int BST::min() {
    return min(root);
}
// Return minimum key in BST rooted at given tree.
// Returns INT_MAX if tree is empty.
int BST::min(BSTNode *tree) {
    if (tree == nullptr)
        return INT_MAX;
    else if (tree->left == nullptr)
    What should go here?
        return tree->key;
    else
        return min(tree->left);
}
                            10
---
  BST: minimum
// Return minimum key in this BST.
// Returns INT_MAX if tree is empty.
int BST::min() {
    return min(root);
}
// Return minimum key in BST rooted at given tree.
// Returns INT_MAX if tree is empty.
int BST::min(BSTNode *tree) {
    if (tree == nullptr)
        return INT_MAX;
    else if (tree->left == nullptr)
        return tree->key;
    else
        return min(tree->left);
}
                            11
---
  BST: minimum
// Return minimum key in this BST.
// Returns INT_MAX if tree is empty.
int BST::min() {
    return min(root);
}
// Return minimum key in BST rooted at given tree.
// Returns INT_MAX if tree is empty.
int BST::min(BSTNode *tree) {
    if (tree == nullptr)
        return INT_MAX;               BST invariant means
    else if (tree->left == nullptr)    min will always be
    elsereturn tree->key;              left-most element
        return min(tree->left);
}
                            11
---
min: Complexity?
• Same as contains:
   ‣  O(log n) for balanced BST
   ‣  O(n) for general BST
                            12
---
BST: insert
•  We want to insert a new key into our tree
• Cases:
   ‣  Tree is empty: Make new node, set it as root
   ‣  If item < key, insert left
   ‣  If item > key, insert right
• Remember: for now we are ignoring duplicates
                            13
---
BST: insert complexity
•  Need to:
    1.  Find correct spot in tree to insert.
    2.  Create a new node and return pointer.
                                  14
---
BST: insert complexity
• Need to:
   1.  Find correct spot in tree to insert.
   2.  Create a new node and return pointer.
•  Step #2 is constant time (O(1))
                               14
---
BST: insert complexity
•  Need to:
     1.  Find correct spot in tree to insert.
     2.  Create a new node and return pointer.
•   Step #2 is constant time (O(1))
•   Step #1 is like contains and min:
   ‣  O(log(n)) for a well-balanced BST
   ‣  O(n) in the general case
                            14
---
BST: insert complexity
•  Need to:
     1.  Find correct spot in tree to insert.
     2.  Create a new node and return pointer.
•   Step #2 is constant time (O(1))
•   Step #1 is like contains and min:
   ‣  O(log(n)) for a well-balanced BST
   ‣  O(n) in the general case
•  So, overall general case complexity: O(n)
                            14
---
BST: removal
•  The trickier BST operation: remove(key)
   ‣  Our goal: remove key from the BST
•  Quite a few cases
   ‣  Solution takes up to ~30 lines
                            15
---
BST: removal
•  First, find node to remove
   ‣ Similar to contains, insert, etc.
                                16
---
BST: removal
•  First, find node to remove
   ‣  Similar to contains, insert, etc.
•  Easy cases:
   ‣  Empty tree (i.e., value wasn’t in tree): nothing to do
   ‣  Leaf: delete it (but also: update parent’s pointer to leaf)
      -  This means you must have access to parent’s pointer
      -  Must be careful for root case
                                  17
---
BST: removal
•  Harder case: node to be removed has one child
   ‣ “Bypass” the node: node’s parent points to node’s child
                            18
---
BST: removal
•  Harder case: node to be removed has one child
   ‣ “Bypass” the node: node’s parent points to node’s child
                                    Say our goal is to remove 12
                              35
                     17              57
                12       28      40       84
             1
                               19
---
BST: removal
•  Harder case: node to be removed has one child
   ‣ “Bypass” the node: node’s parent points to node’s child
                                    Say our goal is to remove 12
                              35
                     17              57
                12       28      40       84
             1
                               19
---
BST: removal
•  Harder case: node to be removed has one child
   ‣ “Bypass” the node: node’s parent points to node’s child
                                 Say our goal is to remove 12
                           35
                   17            57
              12       28     40      84
            1
                       Note: once again, need access to
                    parent’s pointers, and handle root case
                            19
---
BST: removal
•  Hardest case: node to be removed has two children
    Say our goal is to remove 17
                                        35
                         17                          57
               12                 28         40             84
         1          16       20        30
                                   20
---
  BST: removal
  • Hardest case: node to be removed has two children
     Say our goal is to remove 17
To maintain BST invariant, need to replace it with a value that is:
   ‣ Larger than everything in left subtree
   ‣ Smaller than everything in right subtree
What values work as replacements?
                                 35
                     17                    57
              12             28      40          84
          1       16     20      30
                             20
---
 BST: removal
•  In general, to replace a node with two children, we can
   replace with either:
   ‣  Largest (equivalently: rightmost) value in left subtree
      -  It is larger than everything in the left subtree, smaller than everything in right
   ‣  Smallest value in right subtree (by the same reasoning)
                                         35
                          17                          57
                12                 28         40             84
          1          16       20        30
                                    21
---
  BST: removal
 •  In general, to replace a node with two children, we can
    replace with either:
    ‣  Largest (equivalently: rightmost) value in left subtree
       -  It is larger than everything in the left subtree, smaller than everything in right
    ‣  Smallest value in right subtree (by the same reasoning)
We’ll use this one, for now               35
                           17                          57
                 12                 28         40             84
           1          16       20        30
                                     21
---
 BST: removal
1.   Replace node value with largest node value in left
     subtree.
                                         35
                     16   17                          57
                12                 28         40             84
          1          16       20        30
                                    22
---
 BST: removal
1.   Replace node value with largest node value in left
     subtree.
2.   Recursively call remove on left subtree for 16
                                         35
                     16   17                          57
                12                 28         40             84
          1          16       20        30
                                    23
---
BST: removal recap
•  First, find node to remove
• Easy cases
   ‣  Empty tree (i.e., value wasn’t in tree): nothing to do
   ‣  Leaf: delete it (but also: update parent’s pointer to leaf)
•  Harder case: node to remove has one child
•  Hardest case: node to remove has two children
                            24
---
BST: removal complexity?
•  First, find node to remove
• Easy cases
   ‣  Empty tree (i.e., value wasn’t in tree): nothing to do
   ‣  Leaf: delete it (but also: update parent’s pointer to leaf)
•  Harder case: node to remove has one child
•  Hardest case: node to remove has two children
---
BST: removal complexity?
•  First, find node to remove   O(tree height)
• Easy cases
   ‣  Empty tree (i.e., value wasn’t in tree): nothing to do
   ‣  Leaf: delete it (but also: update parent’s pointer to leaf)
•  Harder case: node to remove has one child
•  Hardest case: node to remove has two children
---
BST: removal complexity?
•  First, find node to remove   O(tree height)
• Easy cases
   ‣  Empty tree (i.e., value wasn’t in tree): nothing to do  O(1)
   ‣  Leaf: delete it (but also: update parent’s pointer to leaf)
•  Harder case: node to remove has one child
•  Hardest case: node to remove has two children
---
BST: removal complexity?
•  First, find node to remove   O(tree height)
• Easy cases
   ‣  Empty tree (i.e., value wasn’t in tree): nothing to do   O(1)
   ‣  Leaf: delete it (but also: update parent’s pointer to leaf)
•  Harder case: node to remove has one child                   O(1)
•  Hardest case: node to remove has two children
---
   BST: removal complexity?
   •  First, find node to remove  O(tree height)
   • Easy cases
      ‣  Empty tree (i.e., value wasn’t in tree): nothing to do   O(1)
      ‣  Leaf: delete it (but also: update parent’s pointer to leaf)
   •  Harder case: node to remove has one child                   O(1)
   •  Hardest case: node to remove has two children
O(tree height)
  ‣ Find max(left subtree): O(tree height)
  ‣ Call remove recursively. Recursive call will only happen once.
    - Removed node will have 0 or 1 children, because  it is
       rightmost node in subtree
---
  BST: removal complexity?
Overall complexity:
is O(tree height)
   - Just like before, O(log n) for well-balanced tree, O(n) in general
                              26
---
  BST: removal complexity?
Overall complexity:
      O(tree height) + O(1) + O(1) + O(tree height)
is O(tree height)
   - Just like before, O(log n) for well-balanced tree, O(n) in general
                              26
---
Practice Question
Draw the BST that results from executing the following
operations (in the given order). For removal, replace with
the maximal value in the left subtree of the removed node:
insert(30), insert(22),  insert(25), insert(45),
insert(11), insert(40),  insert(13), insert(23),
remove(22), remove(25),  remove(40)
                     27
---
Practice Question
Draw the BST that results from executing the following
operations (in the given order). For removal, replace with
the maximal value in the left subtree of the removed node:
insert(30), insert(22),  insert(25), insert(45),
insert(11), insert(40),  insert(13), insert(23),
remove(22), remove(25),  remove(40)
                   Try it out:
             https://www.cs.usfca.edu/
           ~galles/visualization/BST.html
                     27
---
CS 15: Data Structures
      AVL Trees
---
BST Insertion Review
•  Insert into a BST (in this order): 8, 7, 6, 5, 4, 3, 2
•  What does the resulting tree look like?
                           29
---
BST Insertion Review
•  Insert into a BST (in this order): 8, 7, 6, 5, 4, 3, 2
•  What does the resulting tree look like?
                                   8
                           30
---
BST Insertion Review
•  Insert into a BST (in this order): 8, 7, 6, 5, 4, 3, 2
•  What does the resulting tree look like?
                                      8
                                  7
                             31
---
BST Insertion Review
•  Insert into a BST (in this order): 8, 7, 6, 5, 4, 3, 2
•  What does the resulting tree look like?
                                      8
                                  7
                              6
                             32
---
BST Insertion Review
•  Insert into a BST (in this order): 8, 7, 6, 5, 4, 3, 2
•  What does the resulting tree look like?
                                              8
                                        7
                                   6
                              5
                         4
                     3
                2                  33
---
BST Insertion Review
•  Say we want to access node 2. Have to traverse entire
   tree!
                                              8
                                        7
                                   6
                              5
                         4
                     3
                2                  34
---
BST Insertion Review
•  Ideally, we would get a more balanced tree:
                                   5
                         3                     7
                  2           4          6          8
                                   35
---
BST Complexity
• We have seen a number of BST operations whose
   complexity depends on the height of the tree
   ‣  contains, min, insert, remove, …
   ‣  O(log n) when tree is well-balanced
   ‣  O(n) in the general case
•  We want an approach to BST insertion/removal that
   guarantees tree is well-balanced
                           36
---
BST Balance
•  A number of strategies exist for ensuring BST balance:
   ‣  AVL trees: we’ll focus on these
   ‣  Red-Black trees
   ‣  2-3 trees
   ‣  Splay trees
   ‣ …
                              37
---
AVL Trees
• Invented by Adelson-Velsky and Landis
•  AVL trees are self-balancing
   ‣ If the tree ever gets out of balance, it automatically re-balances
•  Want fast (O(1)) way to restore balance
                        38
---
AVL Trees: Balance
•  Not every tree can be perfectly well-balanced
   ‣  Only trees containing exactly 2ᵏ - 1 nodes can be perfectly
      balanced (this is called a perfect binary tree)
                                    20
                          15                25
                    1         16      23         27
•  Instead, AVL trees restrict how out-of-balance a tree
   can get
                                  39
---
AVL Balance Invariant
• AVL trees enforce the BST invariant, plus:
                         40
---
AVL Balance Invariant
•  AVL trees enforce the BST invariant, plus:
•  For every node in a non-empty tree, the node’s left and
   right subtrees can diﬀer in height by at most 1
   ‣ balance factor = abs(left subtree height - right subtree height)
   ‣ For all nodes in AVL tree: balance factor ≤ 1
                          40
---
AVL Balance Invariant
•  AVL trees enforce the BST invariant, plus:
•  For every node in a non-empty tree, the node’s left and
   right subtrees can diﬀer in height by at most 1
   ‣ balance factor = abs(left subtree height - right subtree height)
   ‣ For all nodes in AVL tree: balance factor ≤ 1
•  Recall:
   ‣  height of empty tree = -1
   ‣  height of any leaf = 0
   ‣  height of arbitrary node = length of longest path to a leaf
                           40
---
Is this an AVL tree?
                  41
---
Is this an AVL tree?
                                   7
                                   41
---
Is this an AVL tree?
                        7
                       Yes!
           Each subtree has height -1,
                balance factor is 0
                        41
---
Is this an AVL tree?
                                    42
                         17                 84
                                   42
---
Is this an AVL tree?
                               42
                      17              84
                 height = 0        height = 0
                            Yes!
                all nodes match AVL and
                      BST invariants
                              42
---
Is this an AVL tree?
                                    42
                         17                 0
                                   43
---
Is this an AVL tree?
                         42
                  17            0
                        No!
              BST invariant violated,
             and all AVL trees are BSTs
                         43
---
Is this an AVL tree?
                                    5
                          2                8
                    1         4         7
                         3
                                   44
---
Is this an AVL tree?
                               5
             height = 2  2           8 height = 1
                 1        4       7
        height = 0      height = 1  height = 0
                     3
                 height = 0
                            Yes!
         It’s a BST, and every node’s subtrees
              differ in height by at most 1
                              44
---
Is this an AVL tree?
                                    5
                          2                8
                    1         4
                         3
                                   45
---
Is this an AVL tree?
                               5
             height = 2  2           8 height = 0
                 1        4
        height = 0      height = 1
                     3
                 height = 0
                             No!
       Node 5 is out of balance, since subtree
                   heights differ by > 1
                              45
---
Is this an AVL tree?
                                    5
                             4            6
                        3                        7
                  2                                   8
                                   46
---
Is this an AVL tree?
                         5
                    4        6
                3                7
            2          No!           8
      Though node 5 matches AVL invariant,
      nodes 4 and 6 don’t, e.g., node 4’s left
     subtree has height 1, but its right subtree
    is empty, so it has height -1. This difference
                is greater than 1.
                        46
---
AVL Trees
• One tweak we must make to implement AVLs: we store
   each node’s height inside node
•  This way we can access any node’s height in O(1) time
•  Must be careful to correctly update heights whenever
   tree changes
                struct Node {
                    int    data;
                    int    height;
                    Node  *left;
                    Node  *right;
                };
                        47
---
   AVL Trees: insert
   •  AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree
                                     5
                           2               8
                      1         4       7
                           3
                                    48
---
   AVL Trees: insert
   • AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree                             6 > 5
                                   5
                          2               8
                     1        4       7
                          3
                                  49
---
   AVL Trees: insert
   • AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree                             6 < 8
                                   5
                          2               8
                     1        4       7
                          3
                                  50
---
   AVL Trees: insert
   • AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree                             6 < 7
                                   5
                          2               8
                     1        4       7
                          3
                                  51
---
   AVL Trees: insert
   •  AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree
                                     5
                           2               8
                      1         4       7
                           3         6
                                    52
---
AVL Trees: insert
•  Notice: our tree is now out of balance
   ‣ balance factor of node 8 is now 2
• Need to re-balance. Can you see how?
                                    5
                          2                8
                    1          4        7
                         3          6
                                   53
---
AVL Trees: insert
•  Notice: our tree is now out of balance
   ‣ balance factor of node 8 is now 2
• Need to re-balance. Can you see how?
                               5
                       2             7
                 1        4       6       8
                      3
            Let’s figure out how to automate this…
                              54
---
Insertion: Some Observations
                55
---
Insertion: Some Observations
•  Notice: only nodes on the path to newly inserted node can
   be out of balance
   ‣  All other nodes’ subtrees were untouched, so their balance factors
      remain the same
                              55
---
Insertion: Some Observations
•  Notice: only nodes on the path to newly inserted node can
   be out of balance
   ‣  All other nodes’ subtrees were untouched, so their balance factors
      remain the same
•  An out-of-balance node will be out of balance by exactly 2
   ‣  By AVL invariant, node’s balance factor was at most 1 before insert
   ‣  1 additional node can change height of subtree by at most 1
                              55
---
Insertion: Some Observations
•  Notice: only nodes on the path to newly inserted node can
   be out of balance
   ‣  All other nodes’ subtrees were untouched, so their balance factors
      remain the same
•  An out-of-balance node will be out of balance by exactly 2
   ‣  By AVL invariant, node’s balance factor was at most 1 before insert
   ‣  1 additional node can change height of subtree by at most 1
•  Therefore, only need to look down 2 levels to solve out of
   balance tree
   ‣  Always 2 levels, independent of tree size. This is O(1)!
                              55
---
Rebalancing after insert
•  After inserting: starting from inserted node, move up
   tree and   find  first node (if any) that is out-of-balance
                                       5
                             2                8
                      1          4        7
                            3          6
                                   56
---
Rebalancing after insert
•  After inserting: starting from inserted node, move up
   tree and   find  first node (if any) that is out-of-balance
                                       5
                             2                8
                      1          4        7
                            3          6
                                   57
---
Rebalancing after insert
•  After inserting: starting from inserted node, move up
   tree and   find  first node (if any) that is out-of-balance
                                       5
                             2                8
                      1          4        7
                            3          6
                                   58
---
Rebalancing after insert
• This is the subtree that we need to rebalance
      Next: Determine which “imbalance case”
               the subtree falls under
                         8
                    7
                  6
                         59
---
AVL Cases: Implementation
•  There are four cases for an out-of-balance node:
1.  New node was inserted into left child’s left subtree (LL)
2.  New node was inserted into right child’s right subtree (RR)
3.  New node was inserted into right child’s left subtree (RL)
4.  New node was inserted into left child’s right subtree (LR)
                                 60
---
     AVL Cases: Implementation
     • There are four cases for an out-of-balance node:
     1.  New node was inserted into left child’s left subtree (LL)
     2.  New node was inserted into right child’s right subtree (RR)
     3.  New node was inserted into right child’s left subtree (RL)
     4.  New node was inserted into left child’s right subtree (LR)
How do we figure out which case applies?
                                    60
---
    AVL Cases: Implementation
    •  There are four cases for an out-of-balance node:
    1.  New node was inserted into left child’s left subtree (LL)
    2.  New node was inserted into right child’s right subtree (RR)
    3.  New node was inserted into right child’s left subtree (RL)
    4.  New node was inserted into left child’s right subtree (LR)
How do we figure out which case applies?
  •  if height(node->left) > height(node->right), then:
                                60
---
    AVL Cases: Implementation
    •  There are four cases for an out-of-balance node:
    1.  New node was inserted into left child’s left subtree (LL)
    2.  New node was inserted into right child’s right subtree (RR)
    3.  New node was inserted into right child’s left subtree (RL)
    4.  New node was inserted into left child’s right subtree (LR)
How do we figure out which case applies?
  •  if height(node->left) > height(node->right), then:
     ‣ if height(node->left->left) > height(node->left->right): LL
                                60
---
    AVL Cases: Implementation
    •  There are four cases for an out-of-balance node:
    1.  New node was inserted into left child’s left subtree (LL)
    2.  New node was inserted into right child’s right subtree (RR)
    3.  New node was inserted into right child’s left subtree (RL)
    4.  New node was inserted into left child’s right subtree (LR)
How do we figure out which case applies?
  •  if height(node->left) > height(node->right), then:
     ‣ if height(node->left->left) > height(node->left->right): LL
     ‣ else: LR
                                60
---
    AVL Cases: Implementation
    •  There are four cases for an out-of-balance node:
    1.  New node was inserted into left child’s left subtree (LL)
    2.  New node was inserted into right child’s right subtree (RR)
    3.  New node was inserted into right child’s left subtree (RL)
    4.  New node was inserted into left child’s right subtree (LR)
How do we figure out which case applies?
  •  if height(node->left) > height(node->right), then:
     ‣ if height(node->left->left) > height(node->left->right): LL
  • ‣ else: LR
     else …
                                60
---
AVL Cases
              61
---
AVL Cases
• “outside” cases are
   easier
• Handle them with a
  single rotation
                         61
---
AVL Tree: Rebalancing
•  This is an LL case: 6 was inserted into 8’s left
   child’s left subtree
•  Fix it with a single rotation to the right
                               8
                          7
                       6
                              62
---
AVL Tree: Rebalancing
•  This is an LL case: 6 was inserted into 8’s left
   child’s left subtree
•  Fix it with a single rotation to the right
                               7
                          6         8
                              63
---
LL Rebalancing: General Case
•  Circles are nodes, triangles are subtrees
• k₂ out of balance due to LL insertion: left subtree
   height (starting at k₁) now 2 greater than right subtree
             k₂
      k₁             Z
             Y
X
                              64
---
LL Rebalancing: General Case
• Make k₁ new root of tree
  ‣  Whatever previously pointed to k₂ now points to k₁
             k₂                                   k₁
      k₁             Z                                   k₂
                                        X
             Y                                       Y         Z
X
                               65
---
LL Rebalancing: General Case
• k₂ now the right child of k₁
   ‣  This satisfies BST invariant, since (by previous tree) k₂ must
      have been greater than k₁
              k₂                                     k₁
       k₁              Z                                     k₂
                                          X
              Y                                          Y         Z
X
                                 66
---
LL Rebalancing: General Case
• k₂’s left subtree is now Y
   ‣  This satisfies BST invariant, since (by previous tree) all nodes
      in Y must have been greater than k₁ but less than k₂
              k₂                                     k₁
       k₁              Z                                     k₂
                                          X
              Y                                          Y          Z
X
                                 67
---
LL Rebalancing: General Case
•  Notice: we decreased left subtree height by 1,
   increased right subtree height by 1
   ‣ Because original height diﬀerence was 2, now diﬀerence is 0!
             k₂                                  k₁
      k₁             Z                                  k₂
                                       X
             Y                                      Y         Z
X
                              68
---
LL Rebalancing: General Case
•  This is called a single right rotation at k₂ because we
   “rotated” the nodes rightward to rebalance
             k₂                                  k₁
      k₁             Z                                  k₂
                                       X
             Y                                      Y         Z
X
                              69
---
LL Rebalancing: Complexity?
•  Had to update three pointers: original pointer to k₂,
   k₁’s right pointer, and k₂’s left pointer
•  Have to update heights of k₁ and k₂
              k₂                                     k₁
       k₁              Z                                     k₂
                                          X
              Y                                          Y         Z
X
                                 70
---
LL Rebalancing: Complexity?
•  Had to update three pointers: original pointer to k₂,
   k₁’s right pointer, and k₂’s left pointer
•  Have to update heights of k₁ and k₂
                            O(1)!
             k₂                                   k₁
      k₁             Z                                   k₂
                                       X
             Y                                       Y         Z
X
                              70
---
LL Rebalancing: Recap
               71
---
LL Rebalancing: Recap
1. Perform standard BST insertion.
                         71
---
LL Rebalancing: Recap
1.  Perform standard BST insertion.
2.  Moving from newly inserted node up to root,     find the
    first node (if any) that is out-of-balance.
                            71
---
LL Rebalancing: Recap
1.  Perform standard BST insertion.
2.  Moving from newly inserted node up to root,        find the
    first node (if any) that is out-of-balance.
3.  Perform single right rotation:
             k₂                                  k₁
      k₁             Z                                  k₂
                                       X
             Y                                       Y        Z
X
                              71
---
Practice Question
•  Insert 12 into the below AVL tree
   ‣  Remember: Once you find the out-of-balance node, you
      only need to look down two levels!
      -  i.e., all changes take place within two levels of out-of-balance node
                              50
                 20                  70
       10                 40      60       80
  5          15     30
                                   72
---
Solution
•  First, perform a standard BST insert
                              50
                 20                  70
       10                 40      60       80
  5          15     30
       12                          73
---
Solution
• Moving up from the new node,              find  first node (if
   any) that is out of balance
                              50
                 20                  70
       10                 40      60       80
  5          15     30
       12                          74
---
Solution
• Moving up from the new node,            find  first node (if
   any) that is out of balance
   ‣  Identify out-of-balance case. This is LL insertion!
                                         Balance factor = 2.
                             50         50 is out of balance!
                 20                70
       10                40     60       80
  5          15     30
       12                        75
---
Solution
•  Perform single right rotation to re-balance tree
                           20
             10                         50
       5          15            40             70
             12            30              60       80
                                   76
---
  RR Case
  • The RR Case is completely symmetrical
  • Re-balance by performing a single left rotation
        k₁                                        k₂
X             k₂                           k₁               Z
         Y                            X          Y
                    Z
                                77
---
AVL Cases
     Outside cases
?   LR and RL?
                       78
---
LR Case
• k₂ out of balance due to insertion in left child's right subtree
              k₂
       k₁              Z
 X
             Y
                              79
---
LR Case
•  Notice: Y must have at least one node
   ‣  We determined k₂ was out-of-balance because of LR insertion:
      -  k₂’s left subtree height 2 greater than right subtree
      -  k₁’s right subtree height 1 greater than left subtree ⇒ Y has at least one node
                k₂
         k₁               Z
 X
               Y
                                   80
---
LR Case
•  We can replace Y with a node k₃ and two (possibly empty)
   subtrees
              k₂
       k₁             Z
 X           k₃
         A         B
                              81
---
LR Case: Approach #1
•  One solution: just rewrite all the pointers in a way that
   balances the tree, satisfies BST invariant
                k₂                                         k₃
        k₁                Z                         k₁            k₂
 X             k₃                           X         A         B         Z
          A           B
                                   82
---
LR Case: Approach #1
•  If this solution works for you, then great!
   ‣ But it’s a bit unintuitive. Can we be more systematic?
                k₂                                         k₃
        k₁                Z                         k₁            k₂
 X             k₃                           X         A         B         Z
          A           B
                                   83
---
LR Case: Approach #2
•  An alternative approach is called a double rotation
   ‣  Key idea: Rotate once to get tree in a “familiar” state, rotate
      again to balance
              k₂
       k₁             Z
 X           k₃
         A         B
                              84
---
   LR Case: Approach #2
                k₂                                              k₂
        k₁               Z                               k₃              Z
 X             k₃                                 k₁            B
          A          B                      X            A
First, perform left rotation at k₁
                                      85
---
   LR Case: Approach #2
               k₂                                               k₂
        k₁               Z                                k₃              Z
X             k₃                                   k₁           B
         A           B                      X             A
           Now what?
                                      86
---
  LR Case: Approach #2
             k₂                                        k₂
      k₁             Z                           k₃            Z
X           k₃                             k₁          B
       A         B                    X          A
                              Notice: k₂ now out of balance
                              because left child’s left subtree is
         Now what?            heavy (LL). We can solve this!
                                86
---
    LR Case: Approach #2
                   k₂                                   k₃
              k₃           Z                   k₁             k₂
        k₁         B                      X        A       B      Z
  X           A
                                                     Balanced!
Perform right rotation at k₂
                                  87
---
LR Case: Recap
•  Recap: for LR case, we perform a double rotation
   ‣  First, perform left rotation at k₁
   ‣  Then, perform right rotation at k₂
                k₂
        k₁                Z
 X             k₃
          A           B
                                   88
---
RL Case: Mirror Image
•  Once again, the RL case is symmetric
   ‣  For out of balance node k:
      -  First perform right rotation at k->right
      -  Then perform left rotation at k
                            89
---
AVL: Removal
•  Node removal is a lot like insertion
   ‣  First perform standard BST removal
   ‣  Next, figure out where the extra weight lies: left child’s left
      subtree (LL), LR, RL, or RR
   ‣  Apply appropriate rotation(s) to re-balance tree
                              90
---
AVL Insertion Practice
•  Former exam question: Insert into an empty AVL tree
   2 1 4 5 9 3 7. Draw the tree after each insertion.
                         91
---
AVL Insertion Practice
•  Former exam question: Insert into an empty AVL tree
   2 1 4 5 9 3 7. Draw the tree after each insertion.
•  You can try it out using AVL visualization site:
http://www.cs.usfca.edu/~galles/visualization/
AVLtree.html
                          92
---
AVL: More Practice
•  At home, using the website (http://www.cs.usfca.edu/
   ~galles/visualization/AVLtree.html) try the following
   insertion sequences:
   ‣  Insert 3 2 1 4 5 6 7
   ‣  Insert 16 15 14 13 12 11 10 8 9
• Before each insertion, draw the tree you expect,
   then do the insertion on the website to check your
   work.
•  Over time, the tree rotations will become more intuitive
                        93
---
CS 15: Data Structures
  Binary Search Trees
---
Invariants
•  Oxford Dictionary: an invariant is a function, quantity,
   or property which remains unchanged when a specified
   transformation is applied
•  In CS: a program property that must always hold true
                          2
---
Invariants
•  Why is knowing/enforcing invariants useful?
   ‣  Because programming is challenging, humans are error-prone
   ‣  Established invariants let us assume a particular condition is
      true, without worrying about every implementation detail
•  We’ll focus specifically on representation invariants: a
   condition that always holds true of a data structure
                             3
---
Relationship Invariant Examples
•  ArrayList
   ‣  capacity always stores the size of the underlying array
      pointed to by ArrayList
   ‣  size is always the number of elements stored in the ArrayList
   ‣  size ≤ capacity
                             4
---
Relationship Invariant Examples
•  ArrayList
   ‣  capacity always stores the size of the underlying array
      pointed to by ArrayList
   ‣  size is always the number of elements stored in the ArrayList
   ‣  size ≤ capacity
•  Linked List
   ‣  front points to first node in list, or is nullptr
   ‣  Each node’s next pointer is either nullptr, in which case it is last
      node in list, or it points to the next node in the list
                             4
---
Relationship Invariant Examples
•  ArrayList
   ‣  capacity always stores the size of the underlying array
      pointed to by ArrayList
   ‣  size is always the number of elements stored in the ArrayList
   ‣  size ≤ capacity
•  Linked List
   ‣  front points to first node in list, or is nullptr
   ‣  Each node’s next pointer is either nullptr, in which case it is last
      node in list, or it points to the next node in the list
•  Sorted list
   ‣  For all indices i and j, if i≤j then list[i]≤list[j]
                             4
---
Invariant Checklist
1. Initialization/constructor establishes invariant
  - e.g., ArrayList size is 0, capacity is whatever initial capacity is
                              5
---
Invariant Checklist
1.  Initialization/constructor establishes invariant
  -  e.g., ArrayList size is 0, capacity is whatever initial capacity is
2.  Invariant assumed true at the start of every public function
  -  e.g., ArrayList print() assumes size is number of elements, so it
     knows how many elements to print
                              5
---
Invariant Checklist
1.  Initialization/constructor establishes invariant
  -  e.g., ArrayList size is 0, capacity is whatever initial capacity is
2.  Invariant assumed true at the start of every public function
  -  e.g., ArrayList print() assumes size is number of elements, so it
     knows how many elements to print
3.  Member function may temporarily violate invariant
  -  e.g., when adding to ArrayList, size may briefly not match actual #
     elements
                              5
---
Invariant Checklist
1.  Initialization/constructor establishes invariant
  -  e.g., ArrayList size is 0, capacity is whatever initial capacity is
2.  Invariant assumed true at the start of every public function
  -  e.g., ArrayList print() assumes size is number of elements, so it
     knows how many elements to print
3.  Member function may temporarily violate invariant
  -  e.g., when adding to ArrayList, size may briefly not match actual #
     elements
4.  Member function must re-establish invariant before
    returning
  -  This allows other member functions to assume invariant
                              5
---
Private Member Variables
•  Invariants help explain why we always keep member
   variables private
•  This ensures that only our member functions can
   change member variables, not the client
   ‣ Allows us to enforce invariants on member variables
•  If client had access to member variables, they could
   (knowingly or not) violate invariants
   ‣ e.g., change capacity or size to mismatch ArrayList
                          6
---
Binary Trees
•  Previously, we saw that the minimum possible
   height of a binary tree of size n is O(log n)
                            A
                    B             C
               D       E      F       G
                           7
---
Binary Trees: Efficient Access?
•  This means, in a minimum-height binary tree, we can
   get from the root to any node in O(log n) steps
   ‣ This is much faster than O(n) steps oﬀered by lists!
                   log(n) steps     n steps
        n=1            1              1
        n=10           4              10
       n=100           7             100
       n=1000         10             1000
     n=1000000        20           1000000
                         8
---
Binary Trees: Efficient Access?
•  Sounds great. But if we want to access a particular
   element, how do we know where to find it in the tree?
•  The tree traversals we saw previously all visit every
   node in the tree
   ‣ This is O(n)
                            9
---
Binary Search Trees
•  Key idea: We will use the structure of a binary tree to
   capture information about the data in the tree
   ‣ This info will help us eﬃciently find elements
• A binary search tree (BST) is a special kind of binary
   tree that allows us to eﬃciently search for data
•  It is built on the BST invariant
                           10
---
BST Invariant
• The BST invariant is a condition that must be true
   of every node in a BST
•  Invariant: For a given node n with key k,
   ‣  All nodes with keys less than k are in n’s left subtree
   ‣  All nodes with keys greater than k are in n’s right subtree
               42                        Remember:
                                    The BST invariant is
       17            84            true of every node in
  …         …     …      …                the BST.
                            11
---
What about duplicates?
• We have a few choices. We could:
   ‣  Refuse to have them (like in a set)
   ‣  Store all duplicates within a node (e.g., node could contain a list
      of all values with a certain key)
   ‣  Each node stores count of # duplicates
   ‣  Adjust invariant so that duplicates fall in left (or right) subtree
•  All of these are reasonable. Depends on implementation!
•  For now, we’ll assume no duplicates
                              12
---
Is this a BST?
                              BST?
                            13
---
Is this a BST?
                                    42
                         17                 84
                                   14
---
Is this a BST?
                      42
                17         84
                    Yes!
          17 < 42 and 17 in left subtree,
         84 < 42 and 84 in right subtree
                      14
---
Is this a BST?
                                  42
                                   15
---
Is this a BST?
                       42
                      Yes!
           BST invariant holds when the
               subtrees are empty
                        15
---
Is this a BST?
                                  39
                            75         42
                                  40         56
                                   16
---
Is this a BST?
                         39
                     75      42
                         40       56
                         No!
              75 > 39, but 75 is in 39’s
                     left subtree
                          16
---
Is this a BST?
                                  39
                            1          42
                                  40         56
                                   17
---
Is this a BST?
                                  39
                            1          42
                                  40         56
                                 Yes!
                      BST invariant holds
                                   17
---
Is this a BST?
                               2
                                     4
                                          8
                                                16
                                   18
---
Is this a BST?
                        2
                            4
                                8
                                    16
                         Yes!
                 BST invariant holds
                          18
---
Is this a BST?
                                   35
                         17                57
                   12         28       40        84
                1        45
                                   19
---
Is this a BST?
                            35
                    17            57
               12       28     40      84
             1      45
                          No!
          45 is greater than both 17 and 35,
             but it’s in their left subtrees.
            This violates the BST invariant!
                            19
---
Is this a BST?
                                   35
                         17                57
                   12         28       40        84
                1        15        30
                                   20
---
Is this a BST?
                                   35
                         17                57
                   12         28       40        84
                1        15        30
                                 No!
               Not a tree: 30 has two parents
                                   20
---
BST: Implementation
•  Recall: BSTs are used to implement the finite map ADT
   ‣  Because they can eﬃciently search for elements
•  Finite maps typically store (key, value) pairs
   ‣  Use key for lookup, value is actual data of interest
•  For now, we’ll focus only on storing keys
   ‣  We can think of the key as both key and value
•  Adding values is an easy extension
   ‣  Just need to store them in BST nodes
   ‣  They can store whatever you want: student record, flight info, …
                             21
---
 BST Implementation
class BST
{
public:
    BST();
    ~BST();
    ...
private:
    struct BSTNode {        As with linked lists, we keep
        int      key;
        BSTNode *left;          a private node struct,
    };  BSTNode *right;         and keep track of root
    BSTNode *root;             (instead of front) node
    ...
};
                           22
---
Wrapper & Helper Functions
•  Recall from linked lists: we often use public wrapper
   functions and private helper functions
   ‣  The private helper can take more arguments
   ‣  Especially useful for implementing recursive operations
                            23
---
 Wrapper & Helper Functions
 • Example from linked lists: print
         // Prints list starting at front
         void LinkedList::print() {
 public      return print(front);
         }
         // Prints list starting at given nodep
         void LinkedList::print(Node *nodep) {
             if (nodep == nullptr)
                 return;
private      else
                 cout << nodep->data << " “;
                 return print(nodep->next);
         }
                       24
---
Wrapper & Helper Functions
•  This way, client can call list.print() without an
   argument
•  We can use private helper to achieve modularity,
   recursion
•  We will use this pattern frequently for BSTs
                         25
---
    BST: contains
// Return true if this BST contains given key, false otherwise
 bool BST::contains(KeyType key)
{
    return contains(key, root);
}
// Return true  if BST rooted at  tree contains given key, false otherwise
bool BST::contains(KeyType key,   BSTNode *tree)
{
    if (isEmpty(tree))
        return  false;
    else  if  (tree->key == key)
        return  true;
     What should go here?
    else  if  (key < tree->key)
        return  contains(tree->left);
    else  //  key > tree->key
        return  contains(tree->right);
}
                                  26
---
    BST: contains
// Return true if this BST contains given key, false otherwise
 bool BST::contains(KeyType key)
{
    return contains(key, root);
}
// Return true  if BST rooted at  tree contains given key, false otherwise
bool BST::contains(KeyType key,   BSTNode *tree)
{
    if (isEmpty(tree))
        return  false;
    else  if  (tree->key == key)
        return  true;
    else  if  (key < tree->key)
        return  contains(key,  tree->left);
    else  //  key > tree->key
        return  contains(key,  tree->right);
}
                                  27
---
    BST: contains
// Return true if this BST contains given key, false otherwise
 bool BST::contains(KeyType key)
{
    return contains(key, root);
}
// Return true  if BST rooted at  tree contains given key, false otherwise
bool BST::contains(KeyType key,   BSTNode *tree)
{
    if (isEmpty(tree))
    elsereturn  false;                        We can take advantage
          if  (tree->key == key)             of BST invariant. Don’t
    elsereturn  true;                      need to explore whole tree!
          if  (key < tree->key)
        return  contains(key,  tree->left);
    else  //  key > tree->key
        return  contains(key,  tree->right);
}
                                  27
---
BST: contains
•  Is 16 in this tree?
                               35
                     17                57
               12         28       40        84
            1       16
                                   28
---
BST: contains
•  Is 16 in this tree?
                                             16 < 35, so explore left
                               35
                     17                57
               12         28       40        84
            1       16
                                   28
---
BST: contains
•  Is 16 in this tree?
                               35
                     17                57
               12         28       40        84
            1       16
                                   29
---
BST: contains
•  Is 16 in this tree?
                                             16 < 17, so explore left
                               35
                     17                57
               12         28       40        84
            1       16
                                   29
---
BST: contains
•  Is 16 in this tree?
                               35
                     17                57
               12         28       40        84
            1       16
                                   30
---
BST: contains
•  Is 16 in this tree?
                                            16 > 12, so explore right
                               35
                     17                57
               12         28       40        84
            1       16
                                   30
---
BST: contains
•  Is 16 in this tree?
                                                    return true!
                               35
                     17                57
               12         28       40        84
            1       16
                                   31
---
contains: Complexity?
•  For tree of size n, what is the time complexity of BST
   contains?
                     32
---
contains: Complexity?
•  For tree of size n, what is the time complexity of BST
   contains?
•  If the BST is balanced: O(log n)
   ‣  Every step in tree cuts the search space in half. For n, this is at
      most log(n) steps.
   ‣  Can also think of it as: height of tree is O(log(n)), at most have
      to take height-of-tree steps
                           32
---
contains: Complexity?
•  For tree of size n, what is the time complexity of BST
   contains?
•  If the BST is balanced: O(log n)
   ‣  Every step in tree cuts the search space in half. For n, this is at
      most log(n) steps.
   ‣  Can also think of it as: height of tree is O(log(n)), at most have
      to take height-of-tree steps
•  In general, BST may not be balanced. So overall: O(n)
   ‣  Same as linked list. Potentially need to visit every element!
                           32
---
contains: Complexity?
•  For tree of size n, what is the time complexity of BST
   contains?
•  If the BST is balanced: O(log n)
   ‣  Every step in tree cuts the search space in half. For n, this is at
      most log(n) steps.
   ‣  Can also think of it as: height of tree is O(log(n)), at most have
      to take height-of-tree steps
•  In general, BST may not be balanced. So overall: O(n)
   ‣  Same as linked list. Potentially need to visit every element!
•  If we know tree height, we can say: O(height)
                           32
---
  BST: minimum
// Return minimum key in this BST.
// Returns INT_MAX if tree is empty.
int BST::min() {
    return min(root);
}
// Return minimum key in BST rooted at given tree.
// Returns INT_MAX if tree is empty.
int BST::min(BSTNode *tree) {
    if (tree == nullptr)
        return INT_MAX;
    else if (tree->left == nullptr)
    What should go here?
        return tree->key;
    else
        return min(tree->left);
}
                            33
---
  BST: minimum
// Return minimum key in this BST.
// Returns INT_MAX if tree is empty.
int BST::min() {
    return min(root);
}
// Return minimum key in BST rooted at given tree.
// Returns INT_MAX if tree is empty.
int BST::min(BSTNode *tree) {
    if (tree == nullptr)
        return INT_MAX;
    else if (tree->left == nullptr)
        return tree->key;
    else
        return min(tree->left);
}
                            34
---
  BST: minimum
// Return minimum key in this BST.
// Returns INT_MAX if tree is empty.
int BST::min() {
    return min(root);
}
// Return minimum key in BST rooted at given tree.
// Returns INT_MAX if tree is empty.
int BST::min(BSTNode *tree) {
    if (tree == nullptr)
        return INT_MAX;               BST invariant means
    else if (tree->left == nullptr)    min will always be
    elsereturn tree->key;              left-most element
        return min(tree->left);
}
                            34
---
min: Complexity?
• Same as contains:
   ‣  O(log n) for balanced BST
   ‣  O(n) for general BST
                            35
---
BST: insert
•  Ideally, insertion will construct balanced BST
   ‣ We’ll see how to do this soon
•  For now, let’s implement “naive” BST insertion, with the
   only goal of maintaining BST invariant
                           36
---
BST: insert
• Cases:
   ‣  Tree is empty: Make new node, set it as root
   ‣  If item < key, insert left
   ‣  If item > key, insert right
• Remember: for now we are ignoring duplicates
                            37
---
BST: insert
•  Helpful visualization site: https://www.cs.usfca.edu/
   ~galles/visualization/BST.html
   ‣ Let’s try some insertions
                            38
---
  BST: insert implementation
  •  Once again, we’ll use a public wrapper function
     ‣  Passes the root to a private helper function
     ‣  Private function returns pointer to root of tree with new key
/*      inserted
 * public version of Insert
 * inserts key into the tree starting at the current root
 */
 void BST::unbalancedInsert(KeyType key)
 {
     root = unbalancedInsert(root, key);
 }
                            39
---
  BST: insert implementation
  •  Once again, we’ll use a public wrapper function
     ‣  Passes the root to a private helper function
     ‣  Private function returns pointer to root of tree with new key
/*      inserted
 * public version of Insert
 * inserts key into the tree starting at the current root
 */
 void BST::unbalancedInsert(KeyType key)
 {
     root = unbalancedInsert(root, key);
 }
                 Are there any cases
              where root will change?
                            39
---
     BST: insert implementation
     •  Private helper function:
 /*
 *  Given   the root  of  a  tree,
 *  return  pointer   to  root of tree with key inserted
 *  Note:   ALWAYS  adds  a  leaf
 */
BST::BSTNode *BST::unbalancedInsert(BSTNode *tree,  KeyType key) {
  if (isEmpty(tree))      {
      return newBSTNode(key);
  }   else  if  (key  < tree->key) {
        tree->left    = unbalancedInsert(tree->left, key);
        return  tree;
 } else {
       tree->right    = unbalancedInsert(tree->right, key);
       return   tree;
  }
}
                                40
---
     BST: insert implementation
     •  Private helper function:
 /*
 *  Given   the root  of  a  tree,
 *  return  pointer   to  root of tree with key inserted
 *  Note:   ALWAYS  adds  a  leaf
 */
BST::BSTNode *BST::unbalancedInsert(BSTNode *tree,  KeyType key) {
  if (isEmpty(tree))      {
      return newBSTNode(key);
  }   else  if  (key  < tree->key) {
        tree->left    = unbalancedInsert(tree->left, key);
        return  tree;
 } else {
       tree->right    = unbalancedInsert(tree->right, key);
  }    return   tree;        Notice: We update tree->left or
}                            tree->right with the updated root
                                of the corresponding subtree
                                40
---
BST: insert complexity
•  Need to:
    1.  Find correct spot in tree to insert.
    2.  Create a new node and return pointer.
                                  41
---
BST: insert complexity
• Need to:
   1.  Find correct spot in tree to insert.
   2.  Create a new node and return pointer.
•  Step #2 is constant time (O(1))
                               41
---
BST: insert complexity
•  Need to:
     1.  Find correct spot in tree to insert.
     2.  Create a new node and return pointer.
•   Step #2 is constant time (O(1))
•   Step #1 is like contains and min:
   ‣  O(log(n)) for a well-balanced BST
   ‣  O(n) in the general case
                            41
---
BST: insert complexity
•  Need to:
     1.  Find correct spot in tree to insert.
     2.  Create a new node and return pointer.
•   Step #2 is constant time (O(1))
•   Step #1 is like contains and min:
   ‣  O(log(n)) for a well-balanced BST
   ‣  O(n) in the general case
•  So, overall general case complexity: O(n)
                            41
---
BST Practice Questions
• Let’s take a look at two more:
https://docs.google.com/document/d/
1JfDIcWjV43voKA1VLNE4ttRhGrOTkgpnHHztUMgioWg/edit?usp=sharing
                               42
---
depth
int depth(BSTNode *nodep, int key):
                        43
---
depth
int  depth(BSTNode *nodep, int key):
     if (nodep->key   == key)
        return  0;
     else if (key  <  nodep->key):
        return  1  +  depth(nodep->left, key);
     else
        return  1  +  depth(nodep->right, key);
        Remember: We are assuming key exists
              in the tree rooted at nodep
                        44
---
distance
int dist(BSTNode *nodep, int low, int high):
                        45
---
distance
int  dist(BSTNode   *nodep, int  low, int high):
  if (high <    nodep->key)
     //  both high  and low are  in left subtree
     return   dist(nodep->left,  low, high);
   else  if (low >  nodep->key)
     //  both high  and low are  in right subtree
     return dist(nodep->right,   low, high);
   else
     // this is where we  “split”
     return depth(nodep,  low)+depth(nodep, high);
                        46
---
CS 15: Data Structures
 Project 2: CalcYouLater
---
Background
•  We’ll cover Reverse Polish Notation (RPN)
   ‣  Important to Project 2
• Also recommended:
   ‣  Review lecture on stacks
      -  Especially: parsing parenthesized expressions
   ‣  Review lecture on exceptions
      -  Especially: catching exceptions
                              2
---
Conventional Arithmetic Notation
                     5 - 4 + 3 * 4 / 2 * 9
                              3
---
Conventional Arithmetic Notation
                   5 - 4 + 3 * 4 / 2 * 9
•  There is some ambiguity here. We can resolve it with
   parentheses:
                 5 - (4 + 3) * (4 / (2 * 9))
                          3
---
Conventional Arithmetic Notation
                   5 - 4 + 3 * 4 / 2 * 9
•  There is some ambiguity here. We can resolve it with
   parentheses:
                 5 - (4 + 3) * (4 / (2 * 9))
•  There is still ambiguity here: Which comes first, - or *?
                           3
---
Conventional Arithmetic Notation
                     5 - 4 + 3 * 4 / 2 * 9
•  There is some ambiguity here. We can resolve it with
   parentheses:
                   5 - (4 + 3) * (4 / (2 * 9))
•  There is still ambiguity here: Which comes    first, - or *?
•  We have developed conventions to address this:
    1.  Parentheses  PEMDAS
    2.  Exponents
    3. Multiplication/Division
    4.  Addition/Subtraction
                             3
---
Conventional Arithmetic Notation
                     5 - 4 + 3 * 4 / 2 * 9
•  There is some ambiguity here. We can resolve it with
   parentheses:
                   5 - (4 + 3) * (4 / (2 * 9))
•  There is still ambiguity here: Which comes     first, - or *?
•  We have developed conventions to address this:
    1.  Parentheses  PEMDAS
    2.  Exponents
    3. Multiplication/Division  Notice: there is still ambiguity
    4.  Addition/Subtraction      between mult/div and add/sub
                              3
---
Conventional Arithmetic Notation
                    5 - 4 + 3 * 4 / 2 * 9
•  This is called infix notation: binary operators are
   placed between operands
  ‣ Binary operator: operator that acts on two operands
•  Infix notation is fundamentally ambiguous: we’ll always
   need parentheses, special rules like PEMDAS
                            4
---
Other Notations
•  There is more than one way to write arithmetic
   expressions:
•  infix: 3 + 4
   ‣  Operator goes between operands
•  prefix: + 3 4
   ‣  Operator comes before operands
•  postfix: 3 4 +
   ‣  Operator comes after operands
                             5
---
Other Notations
•  There is more than one way to write arithmetic
   expressions:
•  infix: 3 + 4
   ‣  Operator goes between operands
•  prefix: + 3 4                       Both prefix and postfix
   ‣  Operator comes before operands   notation are ambiguity-free:
•  postfix: 3 4 +                      no special rules needed,
                                       parentheses are optional
   ‣  Operator comes after operands
                             5
---
Other Notations
•  There is more than one way to write arithmetic
   expressions:
•  infix: 3 + 4
   ‣  Operator goes between operands
•  prefix: + 3 4
   ‣  Operator comes before operands
•  postfix: 3 4 +
   ‣  Operator comes after operands
                             6
---
Other Notations
•  There is more than one way to write arithmetic
   expressions:
•  infix: 3 + 4
   ‣  Operator goes between operands  Invented by Polish logician
•  prefix: + 3 4                      Jan Łukasiewicz.
                                      Sometimes called
   ‣  Operator comes before operands  Polish notation.
•  postfix: 3 4 +
   ‣  Operator comes after operands
                             6
---
Other Notations
•  There is more than one way to write arithmetic
   expressions:
•  infix: 3 + 4
   ‣  Operator goes between operands
•  prefix: + 3 4
   ‣  Operator comes before operands
•  postfix: 3 4 +
   ‣  Operator comes after operands
                             7
---
Other Notations
•  There is more than one way to write arithmetic
   expressions:
•  infix: 3 + 4
   ‣  Operator goes between operands  Invented by Polish logician
•  prefix: + 3 4                      Jan Łukasiewicz.
                                      Sometimes called
   ‣  Operator comes before operands  Polish notation.
•  postfix: 3 4 +                     Sometimes called
   ‣  Operator comes after operands   Reverse Polish notation
                                      (RPN)
                             7
---
RPN Example
What does this expression evaluate to:
4 5 6 + *
                     8
---
RPN Example
What does this expression evaluate to:
4 5 6 + *
Evaluates to 44
                     8
---
RPN Example
What does this expression evaluate to:
4 5 6 + *
Evaluates to 44
Read expression from left to right. Each time, we see an
operator evaluate it on the previous two values:
                     8
---
RPN Example
What does this expression evaluate to:
4 5 6 + *
Evaluates to 44
Read expression from left to right. Each time, we see an
operator evaluate it on the previous two values:
    1.  + acts on previous two values, 5 and 6. This gives us 11.
     ‣  Think of 11 as “replacing” 5 6 + in our expression
                             8
---
RPN Example
What does this expression evaluate to:
4 5 6 + *
Evaluates to 44
Read expression from left to right. Each time, we see an
operator evaluate it on the previous two values:
   1.   + acts on previous two values, 5 and 6. This gives us 11.
     ‣  Think of 11 as “replacing” 5 6 + in our expression
   2.   * acts on previous two values, now 11 and 4. This gives us 44.
                              8
---
RPN Example 2
What does this expression evaluate to:
5 2 * 3 + 7 +
                     9
---
RPN Example 2
What does this expression evaluate to:
5 2 * 3 + 7 +
Evaluates to 20
                     9
---
RPN Example 2
What does this expression evaluate to:
5 2 * 3 + 7 +
Evaluates to 20
          What data structure can we use to
             evaluate RPN expressions?
                     9
---
RPN and Stacks
•  Answer: a stack!
•  Stacks work well with RPN, since stacks let us access
   the most recently seen value(s)
                         10
---
RPN and Stacks
•  Answer: a stack!
•  Stacks work well with RPN, since stacks let us access
   the most recently seen value(s)
   Algorithm:
                         10
---
RPN and Stacks
•  Answer: a stack!
•  Stacks work well with RPN, since stacks let us access
   the most recently seen value(s)
    Algorithm:
    Read in input one item at a time.
                         10
---
RPN and Stacks
•  Answer: a stack!
•  Stacks work well with RPN, since stacks let us access
   the most recently seen value(s)
    Algorithm:
    Read in input one item at a time.
    Each time you see a number, push it on the stack.
                        10
---
RPN and Stacks
•  Answer: a stack!
•  Stacks work well with RPN, since stacks let us access
   the most recently seen value(s)
    Algorithm:
    Read in input one item at a time.
    Each time you see a number, push it on the stack.
    Each time you see a (binary) operator:
      • Pop two numbers from the stack
      • Apply the operator to the two numbers
      • Push the result onto the stack.
                        10
---
RPN and Stacks
•  Answer: a stack!
•  Stacks work well with RPN, since stacks let us access
   the most recently seen value(s)
    Algorithm:
    Read in input one item at a time.
    Each time you see a number, push it on the stack.
    Each time you see a (binary) operator:
      • Pop two numbers from the stack
      • Apply the operator to the two numbers
      • Push the result onto the stack.
    When you have processed the entire input, the
    value left on the stack is the result.
                         10
---
    RPN and Stacks
                 Algorithm:
                 Read in input.
                 Each time you see a number, push it on the stack.
                 Each time you see a (binary) operator:
                       •  Pop two numbers from the stack
                       •  Apply the operator to the two numbers
                       •  Push the result onto the stack.
                 When you have read the entire input, the value left
                 on the stack is the result.
Evaluate:                                                     Stack
6 5 2 3 + 8 * + 3 + *
                                      11
---
    RPN and Stacks
                 Algorithm:
                 Read in input.
                 Each time you see a number, push it on the stack.
                 Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                 When you have read the entire input, the value left
                 on the stack is the result.
Evaluate:                             push(6)                Stack
6 5 2 3 + 8 * + 3 + *
                                                               6
                                     12
---
    RPN and Stacks
                 Algorithm:
                 Read in input.
                 Each time you see a number, push it on the stack.
                 Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                 When you have read the entire input, the value left
                 on the stack is the result.
Evaluate:                             push(5)                Stack
6 5 2 3 + 8 * + 3 + *
                                                               5
                                                               6
                                     13
---
    RPN and Stacks
                 Algorithm:
                 Read in input.
                 Each time you see a number, push it on the stack.
                 Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                 When you have read the entire input, the value left
                 on the stack is the result.
Evaluate:                             push(2)                Stack
6 5 2 3 + 8 * + 3 + *
                                                               2
                                                               5
                                                               6
                                     14
---
    RPN and Stacks
                 Algorithm:
                 Read in input.
                 Each time you see a number, push it on the stack.
                 Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                 When you have read the entire input, the value left
                 on the stack is the result.
Evaluate:                             push(3)                Stack
6 5 2 3 + 8 * + 3 + *                                          3
                                                               2
                                                               5
                                                               6
                                     15
---
    RPN and Stacks
                 Algorithm:
                 Read in input.
                 Each time you see a number, push it on the stack.
                 Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                 When you have read the entire input, the value left
                 on the stack is the result.
Evaluate:                                                    Stack
6 5 2 3 + 8 * + 3 + *                                          3
                                                               2
                                                               5
                                                               6
                                     16
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                                                  Stack
6 5 2 3 + 8 * + 3 + *           op1 = pop() (= 3)             3
                                                              2
                                                              5
                                                              6
                                     17
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                                                  Stack
6 5 2 3 + 8 * + 3 + *           op1 = pop() (= 3)             3
                                op2 = pop() (=2)              2
                                                              5
                                                              6
                                     18
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                     •  Pop two numbers from the stack
                     •  Apply the operator to the two numbers
                     •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                                                 Stack
6 5 2 3 + 8 * + 3 + *          op1 = pop() (= 3)            3
                               op2 = pop() (=2)             2
                               res = 3 + 2 (= 5)            5
                                                            6
                                    19
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                     •  Pop two numbers from the stack
                     •  Apply the operator to the two numbers
                     •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                                                 Stack
6 5 2 3 + 8 * + 3 + *          op1 = pop() (= 3)
                               op2 = pop() (=2)             5
                               res = 3 + 2 (= 5)            5
                               push(res)                    6
                                    20
---
    RPN and Stacks
                 Algorithm:
                 Read in input.
                 Each time you see a number, push it on the stack.
                 Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                 When you have read the entire input, the value left
                 on the stack is the result.
Evaluate:                             push(8)                Stack
6 5 2 3 + 8 * + 3 + *                                          8
                                                               5
                                                               5
                                                               6
                                     21
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                  pop() twice (get 8 and 5)       Stack
6 5 2 3 + 8 * + 3 + *                                         8
                                                              5
                                                              5
                                                              6
                                     22
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                  pop() twice (get 8 and 5)       Stack
6 5 2 3 + 8 * + 3 + *      res = 8 * 5 = 40                   8
                                                              5
                                                              5
                                                              6
                                     23
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                  pop() twice (get 8 and 5)       Stack
6 5 2 3 + 8 * + 3 + *      res = 8 * 5 = 40
                           push(res)                         40
                                                              5
                                                              6
                                     24
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                  pop() twice (get 40 and 5)      Stack
6 5 2 3 + 8 * + 3 + *
                                                             40
                                                              5
                                                              6
                                     25
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                     •  Pop two numbers from the stack
                     •  Apply the operator to the two numbers
                     •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                 pop() twice (get 40 and 5)      Stack
6 5 2 3 + 8 * + 3 + *     res = 40 + 5 = 45                 40
                                                            5
                                                            6
                                    26
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                     •  Pop two numbers from the stack
                     •  Apply the operator to the two numbers
                     •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                 pop() twice (get 40 and 5)      Stack
6 5 2 3 + 8 * + 3 + *     res = 40 + 5 = 45
                          push(45)                          45
                                                            6
                                    27
---
    RPN and Stacks
                 Algorithm:
                 Read in input.
                 Each time you see a number, push it on the stack.
                 Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                 When you have read the entire input, the value left
                 on the stack is the result.
Evaluate:                           push(3)                  Stack
6 5 2 3 + 8 * + 3 + *
                                                               3
                                                              45
                                                               6
                                     28
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                  pop() twice (get 3 and 45)      Stack
6 5 2 3 + 8 * + 3 + *
                                                              3
                                                             45
                                                              6
                                     29
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                     •  Pop two numbers from the stack
                     •  Apply the operator to the two numbers
                     •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                 pop() twice (get 3 and 45)      Stack
6 5 2 3 + 8 * + 3 + *     res = 3 + 45 = 48                 3
                                                            45
                                                            6
                                    30
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                     •  Pop two numbers from the stack
                     •  Apply the operator to the two numbers
                     •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                 pop() twice (get 3 and 45)      Stack
6 5 2 3 + 8 * + 3 + *     res = 3 + 45 = 48
                          push(48)                          48
                                                            6
                                    31
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                  pop() twice (get 48 and 6)      Stack
6 5 2 3 + 8 * + 3 + *
                                                             48
                                                              6
                                     32
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                  pop() twice (get 48 and 6)      Stack
6 5 2 3 + 8 * + 3 + *      res = 48 * 6 = 288
                                                             48
                                                              6
                                     33
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                      •  Pop two numbers from the stack
                      •  Apply the operator to the two numbers
                      •  Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                  pop() twice (get 48 and 6)      Stack
6 5 2 3 + 8 * + 3 + *      res = 48 * 6 = 288
                           push(288)
                                                            288
                                     34
---
    RPN and Stacks
                Algorithm:
                Read in input.
                Each time you see a number, push it on the stack.
                Each time you see a (binary) operator:
                      •   Pop two numbers from the stack
                      •   Apply the operator to the two numbers
                      •   Push the result onto the stack.
                When you have read the entire input, the value left
                on the stack is the result.
Evaluate:                                                  Stack
6 5 2 3 + 8 * + 3 + *
                        When done reading input,            288
                        value left on stack is result.
                                     35
---
RPN and Stacks
•  What do we do about operations like / and -, where
   order matters?
•  For your project: Use the “deeper” item on the stack as
   the first operand
                         36
---
RPN and Stacks
•  What do we do about operations like / and -, where
   order matters?
•  For your project: Use the “deeper” item on the stack as
   the first operand
     Evaluate:                     Stack
     6 2 /
                         37
---
RPN and Stacks
•  What do we do about operations like / and -, where
   order matters?
•  For your project: Use the “deeper” item on the stack as
   the first operand
     Evaluate:       push(6)       Stack
     6 2 /
                                     6
                         38
---
RPN and Stacks
•  What do we do about operations like / and -, where
   order matters?
•  For your project: Use the “deeper” item on the stack as
   the first operand
     Evaluate:       push(2)       Stack
     6 2 /
                                     2
                                     6
                         39
---
RPN and Stacks
•  What do we do about operations like / and -, where
   order matters?
•  For your project: Use the “deeper” item on the stack as
   the first operand
     Evaluate:                     Stack
     6 2 /
                                     2
                                     6
                         40
---
RPN and Stacks
•  What do we do about operations like / and -, where
   order matters?
•  For your project: Use the “deeper” item on the stack as
   the first operand
     Evaluate:    op2 = pop() (= 2) Stack
     6 2 /
                                     2
                                     6
                         41
---
RPN and Stacks
•  What do we do about operations like / and -, where
   order matters?
•  For your project: Use the “deeper” item on the stack as
   the first operand
     Evaluate:     op2 = pop() (= 2) Stack
     6 2 /         op1 = pop() (= 6)  2
                                      6
                         42
---
RPN and Stacks
•  What do we do about operations like / and -, where
   order matters?
•  For your project: Use the “deeper” item on the stack as
   the first operand
     Evaluate:    op2 = pop() (= 2) Stack
     6 2 /        op1 = pop() (= 6)  2
                  res = op1 / op2    6
                      = 3
                         43
---
RPN and Stacks Example
Evaluate the following RPN expression. Use a stack to do
so: write items in the stack for push() operations, and
cross them out for pop() operations.
3 4  2 / 5 * + 9   2 * 3 / -
                         44
---
RPN and Stacks Example
Evaluate the following RPN expression. Use a stack to do
so: write items in the stack for push() operations, and
cross them out for pop() operations.
3 4 2 / 5 * + 9 2 * 3 / -
Answer: 7
                     45
---
RPN
• The absence of ambiguity makes RPN very appealing
   for computers!
RPN:                          infix:
3 4 2 / 5 * + 9 2 * 3 / -       3 + ((4 / 2) * 5) - ((9 * 2) / 3)
•  A number of computers, calculators have historically
   used RPN
   ‣ See, e.g., dc: A simple calculator program provided by Unix
                            46
---
JFFE
• The shunting algorithm developed by Edgar Dijkstra,
   converts expressions in infix notation to RPN
•  It uses a stack and a queue
• Can you figure it out? Try it at home!
                         47
---
Your Project
•  You will implement an RPN calculator that performs
   basic arithmetic, and more:
   ‣  Booleans and logical operations
   ‣  if statements
   ‣  Storing expressions to be executed later
   ‣  Reading from a file
   ‣  …and more!
                             48
---
                                                                 Structs
                                                                 •  Recall: structs give us a way to encapsulate data
                                                                    ‣ We can store multiple pieces of data within one structure
             CS 15: Data Structures                                                      struct Student  {
                                                                       defining a new     string  name;
                                                                     Studentstruct with   string  courses[5];
         C++ Review: Classes (and more!)                             3 member variables   float grades[5];
                                                                                         };
                                                                                         …
                                                                                         Student stu;
                                                               creating anew             stu.name = “alice”;
                                                                    variable called stu  stu.courses[0]  = “cs15”;
                                                                      of type Student    stu.grades[0] = 92.5;
                                                                                         …
                                                                                          2
Functions for structs?                                           Classes
• In addition to encapsulating data, sometimes we                • A C++ class is similar to a struct, but it can also
  want to encapsulate actions                                       contain member functions in addition to variables
  ‣ e.g., a compute_average() function for Students                 ‣ Often referred to as methods
                                                                 •  Thus, we can encapsulate functions within classes
                         3                                                                4
---
 Classes                                                                  Classes
                                                                          •  We can access member functions using ., just like
              Ignore “public” fornow, we’ll come back to it                  we do with member variables:
class   Employee                    {                                         int  main()                            employee1.cpp
public:                                                                       {
   // Member  variables                                                            Employee e1, e2;
   float base_salary;                                                              e1.base_salary     =  30000;
   int  overtime_hours;                                                            e1.overtime_hours  =  30;
   float overtime_rate;                                                            e1.overtime_rate   =  20;
   // Member  function                                                             e2.base_salary     =  40000;
   float get_income()  {                                                           e2.overtime_hours  =  0 ;
      return base_salary + (overtime_hours  *  overtime_rate);                     e2.overtime_rate   =  20;
   }
};                                                                                 cout  << "e1's  income: "  <<  e1.get_income()  <<  endl;
           We can reference member variables from withinmember functions!          cout  << "e2's  income: "  <<  e2.get_income()  <<  endl;
                                                                                   return 0;
                                                                              }
                              5                                                                          6
 Defining Member Functions                                                Interface and Implementation
 • In the example we just saw, we defined the member                      •  By separating a class’ definition from member function
    function inside the class definition                                     definitions, we separate interface and implementation
 •  Typically, we  declare  member    functions   inside a                •  Interface tells us what we can do with a class
    class, but define the function outside the class
 • We can use ::, called the scope resolution operator,                   •  Implementation has the low level details
    to tell C++ a function belongs to a class
                                                                          •  Soon: we will put these in diﬀerent files
 •  Let’s see: employee2.cpp
                              7                                                                       8
---
Terminology                                                                   Constructors
                    int  main()                                               • A constructor is a special function which is called
                    {    Employee e1, e2;                                        automatically when an instance of a class is created
                         return 0;
•                   }                                                         •  The constructor has the same name as the class
   A value created from a class is called an object
•  We say that an object is an instance of a class                            •  The constructor doesn’t return any values
•  e.g.: e1 and e2    are objects. They are instances of
   the Employee class.
                               9                                                                                        10
 Constructors                                                                 Constructors
                                                                                                  class       Employee {
                                                                                                  public:
 • The purpose of a constructor is to           initialize the                                         //      Member variables
                                                                                                       float  base_salary;
    member variables of an object                                                                      int    overtime_hours;
                                                                                                       float  overtime_rate;
                                                                                                       // Member      functions
 •                                                                                                     float  get_income();
    For example, we may want every newly created                                                       void      give_raise(float  raise);
    Employee to start with the same salary, # overtime                                                 //      Constructor
    hours, and overtime rate                                                       Constructor    };   Employee();
                                                                                  has same name   //  Constructor       Definition
                                                                               as class,          //  Start all      employees at  $30,000 salary,
                                                                                 no return type!  //  with      0 overtime  hours and
                                                                                                  //  an      overtime  rate of $20/hr.
                                                                                                  Employee::Employee()
                                                                                                  {
                                                                                                       base_salary          = 30000;
                                                                                                       overtime_hours       = 0;
                                                                                                       overtime_rate        = 20;
                              11                                                                  }                     12
---
Constructors                                                             Review: Stack vs. Heap Memory
• Now when we create an Employee            instance, the                             int  main()
                                                                                      {
   constructor will be called to initialize its fields            creates an Employee      Employee e1;
                                                                      on the stack         Employee *pe2 = new Employee;
• We create an Employee       instance when:                                               return 0;           creates an Employee
   ‣  We call Employee  e1;                                                           }          In Memory:       onthe heap
   ‣  We call Employee  *pe2 = new  Employee;
                                                                             e1 base_salary …
•  Let’s try it out: employee3.cpp                                     main           …                           base_salary …
                                                                                                                        …
                                                                             pe2  0x7ffec…
                                                                              stack                                   heap
                             13                                                                      14
Review: Recycling Memory                                                 Review: Recycling Memory
              int  main()                                                             int  main()
              {                                                                       {
                   Employee  e1;                                                           Employee e1;
                   Employee  *pe2 = new Employee;                                          Employee *pe2 = new Employee;
                   return 0;                                                               return 0;
              }                                                                       }
  Question: When is stack memory (e.g., e1) recycled?                         Question: When is heap memory recycled?
  Answer: Automatically, when a function returns.                         Answer: We need to do   it explicitly! By calling delete
                                                                                       on a heap memory address.
                             15                                                                      16
---
Review: Recycling Memory                                         Overloading
            int  main()                                          • Sometimes   we   give a  function more  than  one
            {
                 Employee  e1;                                     definition. This is called overloading.
                 Employee  *pe2 = new Employee;
                 …
                 delete  pe2;
            }    return  0;                                            Say a function foo has two definitions.
                                                                           When we call foo, how do we know
     Question: When is heap memory recycled?                                 which definition to use?
 Answer: We need to do   it explicitly! By using delete
             on a heap memory address.
                           17                                                             18
Overloading                                                      Overloading the Constructor
• Sometimes   we   give  a function more  than  one              •  We often define multiple constructors for a class
• definition. This is called overloading.                        •  e.g., we can define two Employee constructors:
  The diﬀerent function definitions must either:                    ‣  A default constructor, creates employee with default settings
  ‣  Take a diﬀerent number of inputs                               ‣  A constructor for starting an employee at a diﬀerent salary
  ‣  Take inputs of diﬀerent types
• When we call the function, we know which                       •  Let’s see: employee4.cpp
  definition to use based on the number/types of the
  given arguments in the call
                           19                                                             20
---
Public/Private Members                                                Public/Private Members
• We make member functions/variables public or private:               •  Private member variables/functions can only be
            class Employee {                                             accessed from within the class’ own member functions
            public:                                                   •  Public member variables/functions can be accessed
                // Member functions                                      from outside member functions, too
                float get_income();
                float give_raise(float raise);                        •  This gives us safer encapsulation
                // Constructors
                Employee();                                              ‣  Only provide the outside world what it needs
                Employee(float salary);
            private:                                                     ‣  Don’t let outside functions change values in unexpected ways
                // Member variables
                float base_salary;
                int   overtime_hours;
                float overtime_rate;
            };
                           21                                                                    22
Getters/Setters                                                       Getters/Setters
• CS 15 Rule: you must keep all member variables of a                 •  Let’s try it: employee5.cpp
  class private
• If you want to let the outside world access those                   •  Try accessing   private  member    variables/functions
                                                                         from main to see what happens
  variables, define public getter and setter functions
  ‣  Getter functions return the value of a member variable
  ‣  Setter functions update the value of a member variable
     -  We can enforce invariants before we update the variables
        -  e.g., salary cannot be negative
                           23                                                                    24
---
  The Truth                                                           But…
  • structs and classes are nearly identical                          •     …traditionally, we use structs when we only have
     ‣  structs can also have member functions, public/private              member variables
        variables, etc.
  • The only diﬀerence:                                               •     We use classes when we have member functions
     ‣  By default, struct members are public
     ‣  By default, class members are private
                            25                                                                   26
  Destructor                                                          Destructor
• A destructor is another special function that is called             •     For a given class called A, the destructor’s name
  automatically whenever either:                                      •     will always be ~A
    1.   A stack value goes out of scope (e.g., at the end of a function)   Like the constructor, the destructor doesn’t return
                                                                            anything
    2.   We call delete on a value                                    •     A destructor also takes no arguments
•  The purpose of a destructor is to recycle any heap
   memory stored in an object’s member variables
                            27                                                                   28
---
Interface vs. Implementation                                                     Client
•  Recall: We separate the class definition from the definitions                 •  We call the code that actually uses a class the client
•  of its member functions                                                          ‣  Client can use the public functions specified in the interface
   We call the class definition an interface                                        ‣  Client uses the implementation code, but it doesn’t need to
   ‣  It tells us what we can do with a class                                          worry about the low-level details of the code
      - i.e., which member functions we can call
   ‣  It does not contain any implementation details
•  We call the member function definitions the implementation
   ‣  Low-level details on how functions actually work
                                29                                                                               30
Using Different Files                                                            Using Different Files
• Until now, we have kept everything in the same file                            •  In C++, we typically separate code into three kinds
• This can get messy                                                                of files:
•  It is also bad for reusability                                                   ‣  Interface files
   ‣  What if we want multiple programs to use our Employee class?                  ‣  Implementation files
      - We could copy/paste… but this is repetitive, and bad practice               ‣  Client files: the code that uses the above, and implements
                                                                                       a specific application
                                31                                                                               32
---
Header Files                                                          Implementation File
• A header file contains a class interface                            • We   store the  actual  implementation   of  a class’
   ‣  Naming convention: classname.h                                     functions in a separate file
• The header file must be include-d in any clients/                   •  ‣  Naming convention: classname.cpp
   implementations that use the class                                    This file must include the relevant interface files
   ‣  Including tells the compiler what operations actually exist        ‣  e.g., #include “Employee.h”
• Example: Employee.h                                                 • Example: Employee.cpp
   ‣  Also need “include guards”: ifndef/define/endif
                           33                                                                    34
Compiling the Implementation                                          Client File(s)
• We   compile  the  implementation   file by  itself by              •  These are any code  files that actually use a class
   adding a -c to the compile command                                    ‣ Could even be the header/implementation files of other classes!
• ‣ clang++ -Wall   -Wextra   -c Employee.cpp                         •  They also must include    the corresponding header file
  The -c tells the compiler: compile the given file, but              • Example: EmployeeClient.cpp
  do not create an executable file
   ‣ We can’t create an executable without a main function!
    - Nowhere for the program to start running
• The output: an object file called Employee.o
   ‣ We can use this file for any of Employee’s clients!
• Let’s try it
                           35                                                                    36
---
Compiling the Client                                                     Compiling the Client
• We also compile client   files using the -c flag:                      •  We also compile client files using the -c flag:
   ‣ clang++ -Wall    -Wextra  -c EmployeeClient.cpp                        ‣ clang++  -Wall  -Wextra -c   EmployeeClient.cpp
                                                                         • We now have two object files corresponding to the
                                                                            implementation and client…
                                                                            ‣  Still no executable file
                                                                         •  Notice: we never actually “gave” the client code the
                                                                            implementation
                                                                            ‣  We only told the client about the interface
                                                                            ‣  But it relies on the implementation…
                            37                                                                       38
Linking                                                                  Recap
• We need to connect client and implementation code                      • Employee interface goes in header file Employee.h
• This process is called linking                                         • Employee implementation goes in Employee.cpp
   ‣  We link together the client and implementation files                  ‣  includes header file
• We use -o to name the resulting executable     file                    •  ‣  Compile with clang++ -Wall -Wextra -c Employee.cpp
   ‣  Add “-o NAME” gives your executable file the name NAME                Employee client goes in separate file, EmployeeClient.cpp
clang++ -Wall -Wextra -o EmployeeProgram EmployeeClient.o Point.o           ‣  includes header file
   ‣  Creates a final executable file called EmployeeProgram             •  ‣  Compile with clang++ -Wall -Wextra -c EmployeeClient.cpp
   ‣  We can run it with ./EmployeeProgram                                  Finally, link Employee.o and EmployeeClient.o:
                                                                         clang++ -Wall -Wextra -o EmployeeClient EmployeeClient.o Employee.o
                            39                                                                       40
---
Separating Interface/Implementation                                           Separating Interface/Implementation
• Why do we separate interface/implementation?                                •  Another reason: separating interface/implementation
    ‣  Some other languages keep them together                                •  is also an important design principle
    ‣  In fact, in C++ we could keep them together                               The   interface   serves   as   an   abstraction    barrier
       - But this would go against convention                                    between client and implementation
• One reason: $
    ‣  If a company developed the code for some library, they may
       want to keep that implementation private
    ‣  Instead, provide just the interface saying what clients can do,
       and the .o file which contains the compiled implementation
                                                                                   Client                Interface              Implementation
                              41                                                                            42
 Separating Interface/Implementation                                          Separating Interface/Implementation
 •  The interface is like a contract                                          • Implementation can change, and client doesn’t need to
    ‣  It tells the client what operations it can perform                       ‣  e.g., we can make implementation faster, but client stays same
    ‣  It tells the implementation what operations it must provide
       Client             Interface               Implementation                   Client                Interface              Implementation
                              43                                                                            44
---
Separating Interface/Implementation                                   Warning!
•  Client may find better implementation for same interface           •  Using -o  always  names the compiled file using the
   ‣ Can switch to new implementation without changing client code       name immediately following the -o
                                                                      •  What’s wrong with the following line?
                                                                        clang++ -Wall -Wextra -o PointClient.cpp Point.cpp
     Client            Interface             Implementation
                           45                                                                    46
Warning!                                                              Makefiles
•  Using -o  always  names the compiled     file using the            •  Soon, we will learn about Makefiles
•  name immediately following the -o                                     ‣  A way to automate the compilation & linking process
   What’s wrong with the following line?                              •  For now, you must know how separate compilation
 clang++ -Wall -Wextra -o EmployeeClient.cpp Employee.cpp                and linking works!
                                                                         ‣  This will help you write Makefiles in the future
•  This will actually create a new executable   file called
   EmployeeClient.cpp!
•  It will overwrite the file EmployeeClient.cpp. You will
   lose your work this way.
•  Solution: Always use a fresh, unused name following -o
                           47                                                                    48
---
 CS 15: Data Structures
Computational Complexity
---
ArrayLists vs. Linked Lists
•  Review: which data structure is faster for the following
   operations?
                       Operation               AL or LL?
                    Insertion at Front
                    Removal at Front
                 Accessing Element at a
                      Given Index
                Finding if an element is
                      in the list
                                       2
---
ArrayLists vs. Linked Lists
•  Review: which data structure is faster for the following
   operations?
                       Operation               AL or LL?
                    Insertion at Front        Linked List
                    Removal at Front
                 Accessing Element at a
                      Given Index
                Finding if an element is
                      in the list
                                       3
---
ArrayLists vs. Linked Lists
•  Review: which data structure is faster for the following
   operations?
                       Operation               AL or LL?
                    Insertion at Front        Linked List
                    Removal at Front          Linked List
                 Accessing Element at a
                      Given Index
                Finding if an element is
                      in the list
                                       4
---
ArrayLists vs. Linked Lists
•  Review: which data structure is faster for the following
   operations?
                       Operation               AL or LL?
                    Insertion at Front        Linked List
                    Removal at Front          Linked List
                 Accessing Element at a        ArrayList
                      Given Index
                Finding if an element is
                      in the list
                                       5
---
ArrayLists vs. Linked Lists
•  Review: which data structure is faster for the following
   operations?
                       Operation               AL or LL?
                    Insertion at Front        Linked List
                    Removal at Front          Linked List
                 Accessing Element at a        ArrayList
                      Given Index
                Finding if an element is         Either
                      in the list
                                       6
---
Talking About Time
•  Until now, we have been imprecise in discussing
   how long a function/program/algorithm takes
   ‣ Using descriptions like “fast,” “slow,” “expense,” “cheap”
• We want a way to precisely describe a program’s
   time and space performance
   ‣ Time complexity: how long it takes a program to run
   ‣ Space complexity: how much space a program uses
                         7
---
Computational Complexity
• Computational complexity formally models the
   resource requirements of an algorithm (time, space,
   etc.) in terms of input size
•  Complexity analysis is a crucial skill developed in CS 15
   ‣  Allows us to precisely compare data structures and their
      associated operations
   ‣  Also important for job interviews!
                           8
---
Computational Complexity
•  In CS 15, we typically measure input size as “number
   of elements” in a data structure
•  Today, we’ll focus on measuring time…
                         9
---
How to Measure Time?
• Want a measurement that is independent of
  processor, memory, compiler, etc.
• Should be the inherent complexity of the program/
  algorithm
• Can’t just measure # seconds…
                        10
---
Measuring Time
•  We measure a program’s time complexity in terms of
   the number of elementary operations it runs
   ‣  Variable Declarations (int x;)
   ‣  Assignment of primitives (x = 10;)
   ‣  Comparison of primitives (x < y;)
   ‣  Other primitive operations (x + y;)
   ‣ …
                         11
---
Measuring Time
•  We measure a program’s time complexity in terms of
   the number of elementary operations it runs
   ‣  Variable Declarations (int x;)
   ‣  Assignment of primitives (x = 10;)
   ‣  Comparison of primitives (x < y;)
   ‣  Other primitive operations (x + y;)
   ‣ …
•  Note: under the hood, some of these operations may
   take longer than others
   ‣  We don’t care about these differences
   ‣  Only care that they are all constant time operations
                            12
---
Examples: Measuring Time
•  Let’s measure # operations for three example functions
•  Note: These are wacky, not-very-useful functions
   ‣ Only using them to demonstrate measuring time
                          13
---
Example #1
int  func1(int n)              num_operations = 0
{
     int x;
     int y  =  n - 1;
     x = n  +  1;
     x++;
     y++;
     int z  =  x - y;
     return z;
}
                     14
---
Example #1
int  func1(int n)              num_operations = 1
{
     int x;     +1 operation!
     int y  =  n - 1;
     x = n  +  1;
     x++;
     y++;
     int z  =  x - y;
     return z;
}
                     15
---
Example #1
int  func1(int n)               num_operations = 2
{
     int x;
     int y  =  n - 1;  is this 1 operation? 2? 3?
     x = n  +  1;   We’ll see soon that we don’t
     x++;      care about constant-time differences…
     y++;          For now, we’ll count it as 1:  +1 operation!
     int z  =  x - y;
     return z;
}
                     16
---
Example #1
int  func1(int n)              num_operations = 3
{
     int x;
     int y  =  n - 1;
     x = n  +  1;  +1 operation!
     x++;
     y++;
     int z  =  x - y;
     return z;
}
                     17
---
Example #1
int  func1(int n)              num_operations = 4
{
     int x;
     int y  =  n - 1;
     x = n  +  1;
     x++;   +1 operation!
     y++;
     int z  =  x - y;
     return z;
}
                     18
---
Example #1
int  func1(int n)              num_operations = 5
{
     int x;
     int y  =  n - 1;
     x = n  +  1;
     x++;
     y++;   +1 operation!
     int z  =  x - y;
     return z;
}
                     19
---
Example #1
int  func1(int n)              num_operations = 6
{
     int x;
     int y  =  n - 1;
     x = n  +  1;
     x++;
     y++;
     int z  =  x - y;  +1 operation!
     return z;
}
                     20
---
Example #1
int  func1(int n)              num_operations = 7
{
     int x;
     int y  =  n - 1;
     x = n  +  1;
     x++;
     y++;
     int z  =  x - y;
     return z;   +1 operation!
}
                     21
---
Example #1
int  func1(int n)              num_operations = 7
{
     int x;
     int y  =  n - 1;  Total: 7 operations
     x = n  +  1;
     x++;
     y++;
     int z  =  x - y;
     return z;
}
                     22
---
  Example #2
                                 num_operations = 0
int func2(int n)
{
    int x  =  0;
    for (int  i   = 1;  i <= n; i++) {
        int   z  = i *  i;
        x  =  x  + z;
    }
    return x;
}
                        23
---
  Example #2
                                 num_operations = 1
int func2(int n)
{
    int x  =  0;  +1 operation!
    for (int  i   = 1;  i <= n; i++) {
        int   z  = i *  i;
        x  =  x  + z;
    }
    return x;
}
                        24
---
  Example #2
                                 num_operations = 1
int func2(int n)
{     These are technically operations… for simplicity, we’ll ignore them
    int x  =  0;
    for (int  i   = 1;  i <= n; i++) {
        int   z  = i *  i;
        x  =  x  + z;
    }
    return x;
}
                        25
---
  Example #2
                                 num_operations = 1
int func2(int n)
{
    int x  =  0;
    for (int  i   = 1;  i <= n; i++) {
        int   z  = i *  i; inside of loop has 2 operations…
        x  =  x  + z;     How many times are they executed?
    }
    return x;
}
                        26
---
  Example #2
                                 num_operations = 2n + 1
int func2(int n)
{
    int x  =  0;
    for (int  i   = 1;  i <= n; i++) {
        int   z  = i *  i;  inside of loop has 2 operations…
        x  =  x  + z;    n How many times are they executed?
    }                     times each, for a total of 2n operations
    return x;                     +2n operations!
}
                        27
---
  Example #2
                                 num_operations = 2n + 2
int func2(int n)
{
    int x  =  0;
    for (int  i   = 1;  i <= n; i++) {
        int   z  = i *  i;
        x  =  x  + z;
    }
    return x;     +1 operation!
}
                        28
---
  Example #2
                                 num_operations = 2n + 2
int func2(int n)
{
    int x  =  0;
    for (int  i   = 1;  i <= n; i++) {
        int   z  = i *  i;
    }   x  =  x  + z;        Total: 2n + 2 operations
    return x;
}                       interesting: we now have a time complexity
                                that depends on the input…
                        29
---
  Example #3
                                   num_operations = 0
int func3(int n)
{
    for (int i = 0;   i < n; i++) {
        for  (int j = 0; j < n; j++) {
             cout <<  "hello!\n";
        }
    }
}
                       30
---
  Example #3
                                   num_operations = 0
int func3(int n)
{
    for (int i = 0;   i < n; i++) {
        for  (int j = 0; j < n; j++) {
             cout <<  "hello!\n";
        }
}   }               How  1 operation here
                       many times is it executed?
                       31
---
  Example #3
                                   num_operations = 0
int func3(int n)
{
    for (int i = 0;   i < n; i++) {
        for  (int j = 0; j < n; j++) {
             cout <<  "hello!\n";
        }
    }
}                               inner loop runs n times…
                       32
---
  Example #3
                                   num_operations = 0
int func3(int n)
{
    for (int i = 0;   i < n; i++) {
        for  (int j = 0; j < n; j++) {
             cout <<  "hello!\n";
        }
    }
}                               inner loop runs n times…
                          each time that the outer loop is run
                       33
---
  Example #3
                                    num_operations = 0
int func3(int n)
{
    for (int i = 0;   i < n; i++) {
        for  (int j = 0; j < n; j++) {
             cout <<  "hello!\n";
        }
    }
}                               inner loop runs n times…
                           each time that the outer loop is run
      (n outer loop runs) * (n inner loop runs for each outer loop run)
                       34
---
  Example #3
                                   num_operations = n²
int func3(int n)
{
    for (int i = 0;   i < n; i++) {
        for  (int j = 0; j < n; j++) {
             cout <<  "hello!\n";
        }
    }
}                               inner loop runs n times…
                           each time that the outer loop is run
      (n outer loop runs) * (n inner loop runs for each outer loop run)
                    +n² operations!
                       35
---
  Example #3
                                   num_operations = n²
int func3(int n)
{
    for (int i = 0;   i < n; i++) {
        for  (int j = 0; j < n; j++) {
             cout <<  "hello!\n";
        }
    }
}                 Total: n² operations
---
Comparing Times
• Which is fastest?
  func1: 7 ops   func2: 2n + 2 ops  func3: n² ops
                       37
---
     Comparing Times
     • Which is fastest? It depends on n!
         func1: 7 ops       func2:   2n + 2 ops      func3:    n² ops
n=1           7                        4                       1
n=2           7                        6                        4
n=3           7                        8                        9
n=4           7                        10                      16
                                  …
n=100         7                       202                    10,000
n=1000        7                       2,002                 1,000,000
n=10000       7                      20,002                100,000,000
                                    38
---
Comparing Times
                 n²       2n + 2
                                               7
                              39
---
Asymptotic Analysis
•  We’re not interested in performance for small inputs
   ‣  Generally, the differences are negligible
•  Rather, we care what happens as the input size grows
   ‣  This is called asymptotic analysis
                            40
---
Asymptotic Analysis
•  Moreover, we don’t really even care about the specific
   number of operations (i.e., 7 vs. 10 vs. 100 vs. …)
•  Rather, we care about how the number of operations
   grows as the input size gets larger
                         41
---
Asymptotic Analysis
•  Moreover, we don’t really even care about the specific
   number of operations (i.e., 7 vs. 10 vs. 100 vs. …)
•  Rather, we care about how the number of operations
   grows as the input size gets larger
   ‣  e.g., not important what the exact # of operations were for 7 vs.
      2n+2 vs. n²
   ‣  What’s important: n² grows much faster than 2n+2 which
      grows much faster than 7
                          42
---
Big O Notation
•  We achieve asymptotic analysis using Big O Notation:
   a technique for describing the upper bound of a
   function as it approaches infinity.
                         43
---
Big O Notation
Formally: Let f(n) and g(n) be functions from non-
negative integers to real numbers. We say f(n) is O(g(n))
(pronounced “f(n) is Big O of g(n)” or “f(n) is order g(n)”)
if there exists a real constant c>0 and an integer
constant n₀≥1 such that f(n)≤ c×g(n) for all n≥n₀.
    In other words: c*g(n) is an upper bound on f(n)
                      from n₀ on.
                          44
---
  Big O Notation: Example
  Formally: Let f(n) and g(n) be functions from non-
  negative integers to real numbers. We say f(n) is O(g(n))
  (pronounced “f(n) is Big O of g(n)” or “f(n) is order g(n)”)
  if there exists a real constant c>0 and an integer
  constant n₀≥1 such that f(n)≤ c×g(n) for all n≥n₀.
                                          3n    2n+2
  2n+2 is O(n). Why?
  Let c=3 and n₀=2.
2n + 2 ≤ 3n for all n≥n₀
---
Big O Notation: Example
•  In fact any linear function f(n) is O(n)
   ‣  f(n) = 2n+2
   ‣  f(n) = 0.5n
   ‣  f(n) = 100000000n + 100000000
   ‣ …
•  For linear functions f(n), we can always  find a c and
   n₀ such that f(n)≤ c×n for all n≥n₀
                            46
---
Big O Notation: Example
• Is n² also O(n)?
                          47
---
Big O Notation: Example
•  Is n² also O(n)?
• No! n₂ will always surpass any linear function eventually
   ‣ i.e., there is no c and n₀ such that n²≤c×n for all n≥n₀
                           48
---
Big O Notation: Example
•  Rather, n² is O(n²)
   ‣  Easy: Let c=1 and n₀=1
•  In fact any quadratic function is O(n²)
   ‣  f(n) = n²
   ‣  f(n) = 2n² + 100n + 14
   ‣ …
                             49
---
Big O Notation: Example
•  What is f(n) = 7?
•  It is O(1)!
   ‣ Let c be anything ≥ 7, n₀ be 1
                            50
---
Big O Notation: Example
•  What is f(n) = 7?
•  It is O(1)!
   ‣  Let c be anything ≥ 7, n₀ be 1
•  f(n)=7 is also O(n) and O(n²)
   ‣  Remember: Big O is an upper bound!
   ‣  But, we are usually interested in the “tightest” upper bound
   ‣  So, we’ll stick with O(1)
                            51
---
Big O Notation: In Practice
•  In practice, we use Big O to identify the complexity
   class of a function/program/algorithm based on the
   shape of the curve of its performance vs. input size
•  Complexity classes:
   ‣  O(1): constant
   ‣  O(n): linear
   ‣  O(n²): quadratic
   ‣ …
                           52
---
Complexity Classes
•  From asymptotically smallest to largest:
   ‣ O(1): constant
                           53
---
Complexity Classes
•  From asymptotically smallest to largest:
   ‣  O(1): constant
   ‣  O(log n): logarithmic
                            54
---
Complexity Classes
•  From asymptotically smallest to largest:
   ‣  O(1): constant
   ‣  O(log n): logarithmic
   ‣  O(n): linear
                            55
---
Complexity Classes
•  From asymptotically smallest to largest:
   ‣  O(1): constant
   ‣  O(log n): logarithmic
   ‣  O(n): linear
   ‣  O(n²): quadratic
   ‣  O(nᵏ): polynomial
                            56
---
Complexity Classes
•  From asymptotically smallest to largest:
   ‣  O(1): constant
   ‣  O(log n): logarithmic
   ‣  O(n): linear
   ‣  O(n²): quadratic
   ‣  O(nᵏ): polynomial
   ‣  O(2ⁿ): exponential
                            57
---
The Trick to Using Big O
• Just throw out all constants and find the “biggest factor”
2n +  2 is O(n)
10⁵n +   999 is O(n)
20n³  +  5n² + 50*log(n) is O(n³)
…any polynomial will always be O(largest power of n)
                         58
---
Example #1
Describe the complexity using Big O notation.
int example_function(int n)
{
    int  x = 0;
    for  (int  i = 0; i < n; i++) {
         x +=  i;
    }
    return x;
}
                  Answer: O(n)
                       59
---
Example #2
Describe the complexity using Big O notation.
int example_function(int n)
{
    int  x = 0;
    for  (int i =  0; i < n; i++) {
         for (int  j = 0; j < n; j++) {
            x  +=  i;
         }
    }
    return x;
}                  Answer: O(n²)
                       60
---
  Example #3
  Describe the complexity using Big O notation.
   int example_function(int n) {
 O(1)  int  x = 0;
       for  (int  i =  0; i < n; i++) {
            for (int   j = 0; j < n; j++) {
               x   +=  i;                 O(n²)
            }
       }
O(1)   x *= x;
       for  (int  i =  0; i < n; i++) {
       }    x +=  i;                      O(n)
O(1)   return x;
   }        Answer: O(n²)+O(n)+3*O(1) is O(n²)!
                         61
---
Example #4
Describe the complexity using Big O notation.
int example_function(int n) {
    int  x = 0;
    for  (int  j = 0; j < 10000; j++) {
         x +=  j;
    }
                       this loop runs 10,000 times,
    return 0;            regardless of what n is
}
                  Answer: O(1)
                       62
---
 Example #5
 Describe the complexity using Big O notation.
int example_function(int n)
{
    int  x = 0;
    if (n % 2  ==  0) {
         for (int  i = 0; i < n; i++) {
         }  x  +=  i;    The function of the
         return x;     number of operations for
    } else {       this case looks something like:
         return 0;     num_ops(n) = 2 if n is odd
    }                              n+2 if n is even
}
                        63
---
 Example #5
 Describe the complexity using Big O notation.
int example_function(int n)
{
    int  x = 0;
    if (n % 2  ==  0) {
         for (int  i = 0; i < n; i++) {
         }  x  +=  i;  Since Big O gives an upper bound,
         return x; we   unless otherwise specified,
    } else {          use Big O to measure the worst-case.
         return 0;  So, we consider only the complexity
    }                     when the loop does run.
}                          Answer: O(n)
                        64
---
 Example #5
 Describe the complexity using Big O notation.
int example_function(int n)
{
    int  x = 0;
    if (n % 2  ==  0) {
         for (int  i = 0; i < n; i++) {
            x  +=  i;
         }                  Note: sometimes we will
         return x;            separately consider
    } else {               best/average/worst case
    }    return 0;           But complexities.
}                             wewhen unspecified,
                                 use worst case.
                        65
---
 Example #6
 Describe the complexity using Big O notation.
int example_function(int n)
{   int  result = 0;     How many times does this loop run?
    while (n > 1)   {
         result +=  1;
         n = n / 2;
    }
    return result;
}
                        66
---
Logarithm Review
We want to know:     (((n / 2) / 2) / …) /2
                How many times can we divide
                 by 2 before getting to 1?
Equivalently:  n = 1
              2x
              What is x?
Equivalently:  2x = n
              What is x?
                Answer: x = log₂(n)
                           67
---
Logarithm Review
•  Logarithms (especially base 2 logarithms) appear
   frequently in complexity analysis!
•  In particular, we often see this pattern of “cutting in
   half” as many times as possible
•  Use Wikipedia for a quick logarithm review:
   ‣  https://en.wikipedia.org/wiki/Logarithm
                          68
---
 Example #6
 Describe the complexity using Big O notation.
int example_function(int  n)
{                              Answer: O(log n)
    int  result = 0;
    while (n > 1)   {   Aside: for any two integers
         result +=  1;   x and y, we can show that
         n = n / 2;
    }                 logₓ(n) and logy(n) differ by a
    return result;       constant factor. But Big O
}                       notation ignores constants!
                          So we just say O(log n).
                        69
---
Big O Notation
• Are we dropping too much information?
   ‣ e.g., we drop all constants and “smaller factors” in a function
• For some purposes, you may want to pay attention
   to the dropped constants/factors
   ‣  Especially when comparing two different operations that have
      the same Big O complexity
•  But in general, Big O is a remarkably effective
   approximation of actual runtime performance
                           70
---
ArrayLists vs. Linked Lists
Using Big O, give the runtime complexity of each operation, for a list
of size n.
You may ignore any potential “expand and copies” for the ArrayList.
                                    ArrayList     w/Linked List
                                                     back pointer
                  insert at front
                  insert at back
                 get kᵗʰ element
                 check if given
               element is in list
                                        71
---
ArrayLists vs. Linked Lists
Using Big O, give the runtime complexity of each operation, for a list
of size n.
You may ignore any potential “expand and copies” for the ArrayList.
                                     ArrayList     w/Linked List
                                                      back pointer
                  insert at front       O(n)            O(1)
                  insert at back
                  get kᵗʰ element
                  check if given
                element is in list
                                         72
---
ArrayLists vs. Linked Lists
Using Big O, give the runtime complexity of each operation, for a list
of size n.
You may ignore any potential “expand and copies” for the ArrayList.
                                      ArrayList      w/Linked List
                                                        back pointer
                   insert at front       O(n)              O(1)
                   insert at back        O(1)              O(1)
                  get kᵗʰ element
                  check if given
                element is in list
                                          73
---
ArrayLists vs. Linked Lists
Using Big O, give the runtime complexity of each operation, for a list
of size n.
You may ignore any potential “expand and copies” for the ArrayList.
                                      ArrayList      w/Linked List
                                                        back pointer
                   insert at front       O(n)              O(1)
                   insert at back        O(1)              O(1)
                  get kᵗʰ element        O(1)          O(n) (or O(k))
                  check if given
                element is in list
                                          74
---
ArrayLists vs. Linked Lists
Using Big O, give the runtime complexity of each operation, for a list
of size n.
You may ignore any potential “expand and copies” for the ArrayList.
                                      ArrayList      w/Linked List
                                                        back pointer
                   insert at front       O(n)              O(1)
                   insert at back        O(1)              O(1)
                  get kᵗʰ element        O(1)          O(n) (or O(k))
                  check if given         O(n)              O(n)
                element is in list
                                          75
---
ArrayLists vs. Linked Lists
Side Note: We said to ignore “expand and copy” time of
ArrayList.
In CS 160, you will use an amortized analysis to show
that, over the long run, the ArrayList insertions average
out to O(1), despite “expand and copies.”
                          76
---
Other Measurements
• Big O establishes upper bounds
• Big Ω establishes lower bounds
• Big ϴ establishes tight bounds: both upper and
  lower bounds
                        77
---
CS 15: Data Structures
  Dijkstra’s Algorithm
---
Previously…
•  We saw two traversals for unweighted graphs:
   ‣   DFS
   ‣   BFS
       -  Useful for finding shortest paths in unweighted graphs
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       2
---
Weighted Graphs
• There are many applications where we may want the
   shortest/cheapest paths in a weighted graph
• New problem: rather than minimizing number of edges
   traversed, minimize weights of edges traversed
                         v₁     2       v₂
                   4         1      3         10
               v₃       2        v₄       2       v₅
                   5        8        4       6
                         v₆      1      v₇
                                 3
---
Example: Map Applications
• Map apps (e.g., Google Maps) often find shortest paths
• Nodes are addresses, edges are roads/paths
• Weights could be many things:
   ‣  Distance
   ‣  Estimated time
   ‣  Tolls              v₁     2       v₂
   ‣ …         v₃  4    2    1   v₄  3    2   10  v₅
                   5        8        4       6
                         v₆      1      v₇
                                 4
---
Example: Flight Itineraries
• Generating a proposed flight itinerary
•  Nodes are airports/cities, edges are flight paths
• Weights: flight costs or times
                         v₁     2       v₂
                   4         1      3         10
               v₃       2        v₄       2       v₅
                   5        8        4       6
                         v₆      1      v₇
                                 5
---
Example: Routing
•  Routing: selecting a path for traﬃc in a network
   ‣ Could be telephone network, internet…
• Nodes: servers/network nodes
•  Edges: wired or wireless connections
• Weights: could be bandwidth, physical distance…
                         v₁     2       v₂
                   4         1      3         10
               v₃       2        v₄       2       v₅
                   5        8        4       6
                         v₆      1      v₇
                                 6
---
Shortest Paths
•  We’ll learn about Dijkstra’s algorithm, a well known
   algorithm for   finding the shortest (i.e., lowest cost) paths
   in a weighted graph
   ‣ Developed by Edsger Dijkstra in 1956
                         v₁     2       v₂
                   4         1      3         10
               v₃       2        v₄       2       v₅
                   5        8        4       6
                         v₆      1      v₇
                                 7
---
Edsger Dĳkstra
•  A pioneering computer scientist
   ‣  From the Netherlands, but spent most of his career at UT Austin
•  Made pioneering contributions in a number of areas:
   ‣  Operating systems
   ‣  Concurrency
   ‣  Programming language research and development
   ‣  Formal verification
   ‣  Compiler construction
   ‣  …
   ‣  Graph algorithms!
                             8
---
    Edsger Dĳkstra
    • The most quotable computer scientist:
      “Program testing can be used to show the presence of bugs,
                  but never to show their absence.”
  “Besides a mathematical inclination, an exceptionally good mastery of
  one's native tongue is the most vital asset of a competent programmer.”
“Simplicity is a great virtue but it requires hard work to achieve it and
education to appreciate it. And to make matters worse: complexity sells
better. The computing industry is not the only one that has discovered that
sore truth: so has the academic world. If you deliver a lecture that is crystal
clear from the beginning to end, your audience feels cheated and mutters
while leaving the lecture hall ‘That was all rather trivial, wasn't it?’”
                                    9
---
Shortest Paths
•  Notice: with weights, the lowest cost path may not be
   the one with the fewest edges
   ‣  v₂->v₅ only uses one edge, total cost = 10
   ‣  v₂->v₄->v₅ uses two edges, total cost = 5
                        v₁      2      v₂
                  4         1       3        10
              v₃       2        v₄       2       v₅
                  5         8        4      6
                        v₆      1       v₇
                                 10
---
Dĳkstra’s Algorithm vs. BFS
• Similar to BFS:
                 11
---
Dĳkstra’s Algorithm vs. BFS
•  Similar to BFS:
   ‣  Given starting node, Dijkstra’s algorithm finds shortest path to all
      other nodes
                            11
---
Dĳkstra’s Algorithm vs. BFS
•  Similar to BFS:
   ‣  Given starting node, Dijkstra’s algorithm finds shortest path to all
      other nodes
   ‣  Initialize starting node’s distance to 0, all other node distances
      to infinity
                             11
---
Dĳkstra’s Algorithm vs. BFS
•  Similar to BFS:
   ‣  Given starting node, Dijkstra’s algorithm finds shortest path to all
      other nodes
   ‣  Initialize starting node’s distance to 0, all other node distances
      to infinity
   ‣  Iteratively pick a new “unknown” node, update distances, mark
      it “known”
                              11
---
Dĳkstra’s Algorithm vs. BFS
•  Similar to BFS:
   ‣  Given starting node, Dijkstra’s algorithm finds shortest path to all
      other nodes
   ‣  Initialize starting node’s distance to 0, all other node distances
      to infinity
   ‣  Iteratively pick a new “unknown” node, update distances, mark
      it “known”
•  Key diﬀerences:
                            11
---
Dĳkstra’s Algorithm vs. BFS
•  Similar to BFS:
   ‣  Given starting node, Dijkstra’s algorithm finds shortest path to all
      other nodes
   ‣  Initialize starting node’s distance to 0, all other node distances
      to infinity
   ‣  Iteratively pick a new “unknown” node, update distances, mark
      it “known”
•  Key diﬀerences:
   ‣  At each iteration, Dijkstra’s algorithm picks the unknown node
      with the shortest current distance
   ‣  Shortest current distance gets updated as we go
                            11
---
Dĳkstra’s Algorithm
1.  Set starting node’s dist to 0, all other dists to infinity
2.  Mark all nodes “unknown”
3.  Repeat until all nodes are “known”:
   1.  Choose the “unknown” node n with the smallest dist
   2.  For all neighbors v of n, update v’s dist, only if the new dist is
       smaller than the old dist
   3.  Mark n as “known”
                              12
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                            Starting node: v₂
   Node    dist  known
    1      inf     F
    2       0      F
    3      inf     F
    4      inf     F
    5      inf     F
    6      inf     F
    7      inf     F
                                       13
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                 Pick the unknown node with the
   Node    dist  known               smallest distance. Easy: v₂!
    1      inf     F
    2       0      F
    3      inf     F
    4      inf     F
    5      inf     F
    6      inf     F
    7      inf     F
                                       14
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                            Look at neighbors of v₂.
                                               Update distances if
   Node    dist  known                        they are smaller than
    1      inf     F                            current distances.
    2       0      F
    3      inf     F
    4      inf     F
    5      inf     F
    6      inf     F
    7      inf     F
                                       15
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                            Look at neighbors of v₂.
                                               Update distances if
   Node    dist  known                        they are smaller than
    1      inf     F                            current distances.
    2       0      F
    3      inf     F                  dist(v₄) = dist(v₂) + edge_weight(v₂, v₄)
    4      inf     F                           = 0 + 3
    5      inf     F                           = 3
    6      inf     F
    7      inf     F
                                       16
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
          3 < inf! update distance          Look at neighbors of v₂.
                                               Update distances if
   Node    dist  known                        they are smaller than
    1      inf     F                            current distances.
    2       0      F
    3      inf     F                  dist(v₄) = dist(v₂) + edge_weight(v₂, v₄)
    4       3      F                           = 0 + 3
    5      inf     F                           = 3
    6      inf     F
    7      inf     F
                                       17
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
          10 < inf! update distance         Look at neighbors of v₂.
                                               Update distances if
   Node    dist  known                        they are smaller than
    1      inf     F                            current distances.
    2       0      F
    3      inf     F                  dist(v₅) = dist(v₂) + edge_weight(v₂, v₅)
    4       3      F                           = 0 + 10
    5      10      F                           = 10
    6      inf     F
    7      inf     F
                                       18
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                              Mark v₂ as “known.”
                                                 This means we’ll
   Node    dist  known                          never have to visit
    1      inf     F                                  v₂ again.
    2       0      T
    3      inf     F
    4       3      F
    5      10      F
    6      inf     F
    7      inf     F
                                       19
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                        Repeat: Choose the unknown
   Node    dist  known                   node with the smallest dist.
    1      inf     F                                This time: v₄
    2       0      T
    3      inf     F
    4       3      F
    5      10      F
    6      inf     F
    7      inf     F
                                       20
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                Question: is it possible we ever
                               find a shorter path to v₄ than the
                                  one we’ve already seen?
   Node    dist  known
    1      inf     F
    2       0      T
    3      inf     F
    4       3      F
    5      10      F
    6      inf     F
    7      inf     F
                                       21
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                Question: is it possible we ever
                               find a shorter path to v₄ than the
                                  one we’ve already seen?
   Node    dist  known       Answer: Assuming positive edges, no!
    1      inf     F         All other paths out of v₂ are
    2       0      T
    3      inf     F         longer than 3. No way we get to v₄ through
    4       3      F         a shorter route.
    5      10      F
    6      inf     F
    7      inf     F
                                       22
---
    Dĳkstra’s Algorithm: First Look
                               v₁      2        v₂
                         4         1        3         10
                    v₃        2         v₄       2         v₅
This is why we           5         8         4       6
    pick the       always      v        1       v
               current          6                7
  minimum dist. It is           Question: is it possible we ever
   guaranteed to be            find a shorter path to v₄ than the
  the shortest route!              one we’ve already seen?
      Node    dist known       Answer: Assuming positive edges, no!
       1      inf    F         All other paths out of v₂ are
       2       0     T
       3      inf    F         longer than 3. No way we get to v₄ through
       4      3      F         a shorter route.
       5      10     F
       6      inf    F
       7      inf    F
                                        23
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                                Current node: v₄.
   Node    dist  known
    1      inf     F
    2       0      T
    3      inf     F
    4       3      F
    5      10      F
    6      inf     F
    7      inf     F
                                       24
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                                Update any neighbor’s
                                               dist that is smaller than
   Node    dist  known                                  current dist
    1      inf     F
    2       0      T
    3      inf     F
    4       3      F
    5      10      F
    6      inf     F
    7      inf     F
                                       25
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                                Update any neighbor’s
                                               dist that is smaller than
   Node   dist   known                                  current dist
    1     inf      F
    2      0       T
    3      5       F
    4      3       F
    5      5       F
    6      11      F
    7       7      F
                                       26
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
Notice: v₅’s dist was        v₆        1        v₇
  updated because we                            Update any neighbor’s
found a shorter route
                                               dist that is smaller than
   Node   dist   known                                  current dist
    1     inf      F
    2      0       T
    3      5       F
    4      3       F
    5      5       F
    6      11      F
    7       7      F
                                       27
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                               Mark v₄ as known
   Node   dist   known
    1     inf      F
    2      0       T
    3      5       F
    4      3       T
    5      5       F
    6      11      F
    7       7      F
                                       28
---
Dĳkstra’s Algorithm: First Look
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                        Repeat: Choose the unknown
   Node   dist   known                   node with the smallest dist.
    1     inf      F                       Arbitrarily breaking tie: v₃
    2      0       T
    3      5       F
    4      3       T
    5      5       F
    6      11      F
    7       7      F
                                       29
---
Dĳkstra’s Algorithm: First Look
                           v₁       2       v₂
                     4          1       3          10
                 v₃        2        v₄        2        v₅
                     5         8         4        6
                           v₆       1        v₇
                                     Repeat: Choose the unknown
  Node   dist  known                  node with the smallest dist.
   1     inf     F                      Arbitrarily breaking tie: v₃
   2      0      T
   3      5      F                    etc. Continue until all nodes
   4      3      T
   5      5      F                               are visited!
   6      11     F
   7      7      F
                                    30
---
Dĳkstra’s Algorithm
•  Dijkstra’s algorithm is a greedy algorithm: when you
   have a choice, pick the option that looks best right
   now, without worrying about the future
   ‣ i.e., pick the locally optimal option
                           31
---
Dĳkstra’s Algorithm
•  Limitation: notice Dijkstra’s algorithm will only work
   when weights are positive. Why?
                        32
---
Dĳkstra’s Algorithm
•  Limitation: notice Dijkstra’s algorithm will only work
   when weights are positive. Why?
•  If there are negative weights, the current shortest path
   may not be the best: it could get shorter by traversing a
   negative weighted edge
   ‣ See Bellman-Ford algorithm for an example of how to handle this
                         32
---
Dĳkstra’s Algorithm
•  Limitation: notice Dijkstra’s algorithm will only work
   when weights are positive. Why?
•  If there are negative weights, the current shortest path
   may not be the best: it could get shorter by traversing a
   negative weighted edge
   ‣ See Bellman-Ford algorithm for an example of how to handle this
•  Notice: No algorithm can work for a graph with negative
   cycles. Why?
                         32
---
Dĳkstra’s Algorithm
•  Limitation: notice Dijkstra’s algorithm will only work
   when weights are positive. Why?
•  If there are negative weights, the current shortest path
   may not be the best: it could get shorter by traversing a
   negative weighted edge
   ‣ See Bellman-Ford algorithm for an example of how to handle this
•  Notice: No algorithm can work for a graph with negative
   cycles. Why?
•  With negative cycles, there is no shortest path
   ‣ You can always follow the cycle again to get a shorter path
                          32
---
Full Example
•  We saw a partial example of Dijkstra’s algorithm
•  Typically, when we run the algorithm by hand, we will
   use a table:
   Node    Known     Prev     Dist     v =      v =      v =      …
    1
    2
    3
    4
    5
    6
    7
                                       33
---
Full Example
•  We saw a partial example of Dijkstra’s algorithm
•  Typically, when we run the algorithm by hand, we will
   use a table:
 Node #
   Node    Known     Prev     Dist     v =      v =      v =      …
    1
    2
    3
    4
    5
    6
    7
                                       34
---
 Full Example
 •  We saw a partial example of Dijkstra’s algorithm
 •  Typically, when we run the algorithm by hand, we will
    use a table:
    bool indicating whether
     node has been visited
(initially: False everywhere)
    Node   Known    Prev    Dist    v =     v =    v =      …
     1
     2
     3
     4
     5
     6
     7
                                   35
---
Full Example
•  We saw a partial example of Dijkstra’s algorithm
•  Typically, when we run the algorithm by hand, we will
   use a table:
        previous/predecessor node
     in shortest path. Just like BFS!
   Node   Known    Prev    Dist    v =     v =     v =      …
    1
    2
    3
    4
    5
    6
    7
                                   36
---
Full Example
•  We saw a partial example of Dijkstra’s algorithm
•  Typically, when we run the algorithm by hand, we will
   use a table:
                current shortest distances
     (initially: 0 for start node, inf for the rest)
   Node   Known    Prev    Dist    v =     v =     v =     …
    1
    2
    3
    4
    5
    6
    7
                                   37
---
Full Example
•  We saw a partial example of Dijkstra’s algorithm
•  Typically, when we run the algorithm by hand, we will
   use a table:
                              Top row contains node # chosen
                          for current iteration. Column entries
                       contain any distances updated this iteration
   Node  Known   Prev    Dist    v =    v =    v =     …
    1
    2
    3
    4
    5
    6
    7
                                38
---
Full Example
•  We saw a partial example of Dijkstra’s algorithm
•  Typically, when we run the algorithm by hand, we will
   use a table:
             You must know how to     fill out this table!
   Node   Known    Prev    Dist    v =     v =     v =     …
    1
    2
    3
    4
    5
    6
    7
                                   39
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
   Node  Known    Prev    Dist    v =    v =     v =    v =     v =    v =     v =
    1      F
    2      F
    3      F
    4      F
    5      F
    6      F
    7      F
                                       40
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                  Starting node: v₁
                (update initial dists)
   Node  Known    Prev    Dist    v =    v =     v =    v =     v =    v =     v =
    1      F               0
    2      F              inf
    3      F              inf
    4      F              inf
    5      F              inf
    6      F              inf
    7      F              inf
                                       41
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
    Pick the unknown node with the smallest dist: v₁
   Node  Known    Prev    Dist   v = 1   v =     v =    v =     v =    v =     v =
    1      F               0
    2      F              inf
    3      F              inf
    4      F              inf
    5      F              inf
    6      F              inf
    7      F              inf
                                       42
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
   Update dists, prev for neighbors of v₁
   Node  Known    Prev    Dist   v = 1   v =     v =    v =     v =    v =     v =
    1      F               0
    2      F              inf
    3      F              inf
    4      F              inf
    5      F              inf
    6      F              inf
    7      F              inf
                                       43
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
   Update dists, prev for neighbors of v₁
   Node  Known    Prev    Dist   v = 1   v =     v =    v =     v =    v =     v =
    1      F               0
    2      F       1       2      2
    3      F              inf
    4      F       1       1      1
    5      F              inf
    6      F              inf
    7      F              inf
                                       44
---
    Full Example
                                 v₁       2        v₂
                           4          1        3          10
                      v₃         2         v₄        2         v₅
                           5          8         4        6
                                 v₆        1        v₇
Update “known” of v₁ to true
       Node  Known    Prev    Dist   v = 1   v =     v =    v =     v =    v =     v =
        1      F               0
        2      F       1       2      2
        3      F              inf
        4      F       1       1      1
        5      F              inf
        6      F              inf
        7      F              inf
                                           45
---
    Full Example
                                 v₁       2        v₂
                           4          1        3          10
                      v₃         2         v₄        2         v₅
                           5          8         4        6
                                 v₆        1        v₇
Update “known” of v₁ to true
       Node  Known    Prev    Dist   v = 1   v =     v =    v =     v =    v =     v =
        1     F T              0
        2      F       1       2      2
        3      F              inf
        4      F       1       1      1
        5      F              inf
        6      F              inf
        7      F              inf
                                           46
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
               Pick unknown node with shortest distance: v₄
   Node  Known    Prev    Dist   v = 1  v = 4    v =    v =     v =    v =     v =
    1     F T              0
    2      F       1       2      2
    3      F              inf
    4      F       1       1      1
    5      F              inf
    6      F              inf
    7      F              inf
                                       47
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
     Update dists, prev for neighbors of v₄
   Node  Known    Prev    Dist   v = 1  v = 4    v =    v =     v =    v =     v =
    1     F T              0
    2      F       1       2      2
    3      F              inf
    4      F       1       1      1
    5      F              inf
    6      F              inf
    7      F              inf
                                       48
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
     Update dists, prev for neighbors of v₄
   Node  Known    Prev   Dist    v = 1  v = 4    v =    v =     v =    v =     v =
    1     F T             0
    2      F       1      2       2
    3      F       4      3               3
    4      F       1      1       1
    5      F       4      3               3
    6      F       4      9               9
    7      F       4      5               5
                                       49
---
    Full Example
                                 v₁       2        v₂
                           4          1        3          10
                      v₃         2         v₄        2         v₅
                           5          8         4        6
                                 v₆        1        v₇
Update “known” of v₄ to true
       Node  Known    Prev   Dist    v = 1  v = 4    v =    v =     v =    v =     v =
        1     F T             0
        2      F       1      2       2
        3      F       4      3               3
        4     F T      1      1       1
        5      F       4      3               3
        6      F       4      9               9
        7      F       4      5               5
                                           50
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                   Pick min. unknown node: v₂
   Node  Known    Prev   Dist    v = 1  v = 4   v = 2   v =     v =    v =     v =
    1     F T             0
    2      F       1      2       2
    3      F       4      3               3
    4     F T      1      1       1
    5      F       4      3               3
    6      F       4      9               9
    7      F       4      5               5
                                       51
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
     Update dists, prev for neighbors of v₂
   Node  Known    Prev   Dist    v = 1  v = 4   v = 2   v =     v =    v =     v =
    1     F T             0
    2      F       1      2       2
    3      F       4      3               3
    4     F T      1      1       1
    5      F       4      3               3
    6      F       4      9               9
    7      F       4      5               5
                                       52
---
 Full Example
                              v₁       2        v₂
                        4          1        3          10
                   v₃         2         v₄        2         v₅
                        5          8         4        6
                                              v₆  1  v₇
                        Neighbors of v₂: v₄ (which is already known),
and v₅ (which has a shorter distance than 12).
          Nothing to update in this case!
    Node  Known    Prev   Dist    v = 1  v = 4   v = 2   v =     v =    v =     v =
     1     F T             0
     2      F       1      2       2
     3      F       4      3               3
     4     F T      1      1       1
     5      F       4      3               3
     6      F       4      9               9
     7      F       4      5               5
                                        53
---
   Full Example
                                v₁       2        v₂
                          4          1        3          10
                     v₃         2         v₄        2         v₅
                          5          8         4        6
                                v₆        1        v₇
Update “known” of v₂ to true
      Node  Known    Prev   Dist    v = 1  v = 4   v = 2   v =     v =    v =     v =
       1     F T             0
       2     F T      1      2       2
       3      F       4      3               3
       4     F T      1      1       1
       5      F       4      3               3
       6      F       4      9               9
       7      F       4      5               5
                                          54
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                           Pick min. unknown node: v₃
                                                (arbitrarily break tie)
   Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3    v =    v =     v =
    1     F T             0
    2     F T      1      2       2
    3      F       4      3               3
    4     F T      1      1       1
    5      F       4      3               3
    6      F       4      9               9
    7      F       4      5               5
                                       55
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
            Update dists, prev for neighbors of v₃
   Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3    v =    v =     v =
    1     F T             0
    2     F T      1      2       2
    3      F       4      3               3
    4     F T      1      1       1
    5      F       4      3               3
    6      F       4      9               9
    7      F       4      5               5
                                       56
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                             Notice: we found a shorter
                                             route for v₆, so we mark its
                                               new dist, update its Prev
   Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3    v =    v =     v =
    1     F T             0
    2     F T      1      2       2
    3      F       4      3               3
    4     F T      1      1       1
    5      F       4      3               3
    6      F      4 3     8               9              8
    7      F       4      5               5
                                       57
---
   Full Example
                                v₁       2        v₂
                          4          1        3          10
                     v₃         2         v₄        2         v₅
                          5          8         4        6
                                v₆        1        v₇
Update “known” of v₃ to true
      Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3    v =    v =     v =
       1     F T             0
       2     F T      1      2       2
       3     F T      4      3               3
       4     F T      1      1       1
       5      F       4      3               3
       6      F      4 3     8               9              8
       7      F       4      5               5
                                          58
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                             Pick min. unknown node: v₅
   Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3   v = 5   v =     v =
    1     F T             0
    2     F T      1      2       2
    3     F T      4      3               3
    4     F T      1      1       1
    5      F       4      3               3
    6      F      4 3     8               9              8
    7      F       4      5               5
                                       59
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                 Update dists, prev for neighbors of v₅
                              (nothing changes)
   Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3   v = 5   v =     v =
    1     F T             0
    2     F T      1      2       2
    3     F T      4      3               3
    4     F T      1      1       1
    5      F       4      3               3
    6      F      4 3     8               9              8
    7      F       4      5               5
                                       60
---
   Full Example
                                v₁       2        v₂
                          4          1        3          10
                     v₃         2         v₄        2         v₅
                          5          8         4        6
                                v₆        1        v₇
Update “known” of v₅ to true
      Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3   v = 5   v =     v =
       1     F T             0
       2     F T      1      2       2
       3     F T      4      3               3
       4     F T      1      1       1
       5     F T      4      3               3
       6      F      4 3     8               9              8
       7      F       4      5               5
                                          61
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                             Pick min. unknown node: v₇
   Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3   v = 5   v = 7   v =
    1     F T             0
    2     F T      1      2       2
    3     F T      4      3               3
    4     F T      1      1       1
    5     F T      4      3               3
    6      F      4 3     8               9              8
    7      F       4      5               5
                                       62
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                    Update dists, prev for neighbors of v₇
   Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3   v = 5   v = 7   v =
    1     F T             0
    2     F T      1      2       2
    3     F T      4      3               3
    4     F T      1      1       1
    5     F T      4      3               3
    6      F      4 3     8               9              8
    7      F       4      5               5
                                       63
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                             Notice: we found a shorter
                                             route for v₆, so we mark its
                                               new dist, update its Prev
   Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3   v = 5   v = 7   v =
    1     F T             0
    2     F T      1      2       2
    3     F T      4      3               3
    4     F T      1      1       1
    5     F T      4      3               3
    6      F     4 3 7    6               9              8              6
    7      F       4      5               5
                                       64
---
   Full Example
                                v₁       2        v₂
                          4          1        3          10
                     v₃         2         v₄        2         v₅
                          5          8         4        6
                                v₆        1        v₇
Update “known” of v₇ to true
      Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3   v = 5   v = 7   v =
       1     F T             0
       2     F T      1      2       2
       3     F T      4      3               3
       4     F T      1      1       1
       5     F T      4      3               3
       6      F     4 3 7    6               9              8              6
       7     F T      4      5               5
                                          65
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
                                             Pick min. unknown node: v₆
   Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3   v = 5   v = 7  v = 6
    1     F T             0
    2     F T      1      2       2
    3     F T      4      3               3
    4     F T      1      1       1
    5     F T      4      3               3
    6      F     4 3 7    6               9              8              6
    7     F T      4      5               5
                                       66
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
  We will never need to update dists for the last node.
                  Update “known” of v₆ to true.
   Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3   v = 5   v = 7  v = 6
    1     F T             0
    2     F T      1      2       2
    3     F T      4      3               3
    4     F T      1      1       1
    5     F T      4      3               3
    6     F T    4 3 7    6               9              8              6
    7     F T      4      5               5
                                       67
---
Full Example
                             v₁       2        v₂
                       4          1        3          10
                  v₃         2         v₄        2         v₅
                       5          8         4        6
                             v₆        1        v₇
     Final table state:
   Node  Known    Prev   Dist    v = 1  v = 4   v = 2  v = 3   v = 5   v = 7  v = 6
    1     F T             0
    2     F T      1      2       2
    3     F T      4      3               3
    4     F T      1      1       1
    5     F T      4      3               3
    6     F T    4 3 7    6               9              8              6
    7     F T      4      5               5
                                       68
---
Implementing Dĳkstra’s Algorithm
•  Each time we select the next vertex, we want the one
   with minimum distance
•  What data structure do we know that eﬃciently selects
   minimum values?
                        69
---
Implementing Dĳkstra’s Algorithm
•  Each time we select the next vertex, we want the one
   with minimum distance
•  What data structure do we know that eﬃciently selects
   minimum values?
         Answer: Priority Queues/Heaps!
            -Extracting minimum takes O(log n)
                         69
---
Dĳkstra Pseudocode
                70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph, source):
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph, source):
    dist[source] ← 0                       // Initialization
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph, source):
    dist[source] ← 0                       // Initialization
    create vertex priority queue Q
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph, source):
    dist[source] ← 0                       // Initialization
    create vertex priority queue Q
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,  source):
    dist[source] ← 0                       // Initialization
    create vertex priority queue Q
    for each vertex v in  Graph:
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       // Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
             dist[v] ← INFINITY            //  Unknown distance from source to v
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
         Q.add_with_priority(v, dist[v])
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
         Q.add_with_priority(v, dist[v])
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
         Q.add_with_priority(v, dist[v])
    while Q is not empty:                  //  The main loop
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
         Q.add_with_priority(v, dist[v])
    while Q is not empty:                  //  The main loop
         u ← Q.extract_min()               //  Remove and return best vertex
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
         Q.add_with_priority(v,  dist[v])
    while Q is  not empty:                 //  The main loop
         u ← Q.extract_min()               //  Remove and return best vertex
         for each neighbor v of  u still in Q:
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
         Q.add_with_priority(v,   dist[v])
    while Q is  not empty:                 //  The main loop
         u ← Q.extract_min()               //  Remove and return best vertex
         for each neighbor  v of  u still in Q:
             alt ← dist[u]  + length(u, v)
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:                //  The main loop
         u ← Q.extract_min()               //  Remove and return best vertex
         for each  neighbor  v of  u still in Q:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:                //  The main loop
         u ← Q.extract_min()               //  Remove and return best vertex
         for each  neighbor  v of  u still in Q:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]
                  dist[v] ←  alt
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:                //  The main loop
         u ← Q.extract_min()               //  Remove and return best vertex
         for each  neighbor  v of  u still in Q:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]
                  dist[v] ←  alt
                  prev[v] ←  u
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:                //  The main loop
         u ← Q.extract_min()               //  Remove and return best vertex
         for each  neighbor  v of  u still in Q:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:                //  The main loop
         u ← Q.extract_min()               //  Remove and return best vertex
         for each  neighbor  v of  u still in Q:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)
                                       70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:                //  The main loop
         u ← Q.extract_min()               //  Remove and return best vertex
         for each  neighbor  v of  u still in Q:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)
    return dist, prev                  70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Pseudocode
function Dijkstra(Graph,   source):
    dist[source] ← 0                       //  Initialization
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY          //  Unknown distance from source to v
              prev[v]  ← UNDEFINED         //  Predecessor of v
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:                //  The main loop
         u ← Q.extract_min()               //  Remove and return best vertex
         for each  neighbor  v of  u still in Q:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)
    return dist, prev                  70  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Time Complexity
function Dijkstra(Graph,   source):
    dist[source] ← 0
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY
              prev[v]  ← UNDEFINED
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:
         u ← Q.extract_min()
         for each  neighbor  v of  u:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)
    return dist, prev                  71  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Time Complexity
function Dijkstra(Graph,   source):
    dist[source] ← 0                 O(1)
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY
              prev[v]  ← UNDEFINED
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:
         u ← Q.extract_min()
         for each  neighbor  v of  u:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)
    return dist, prev                  71  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Time Complexity
function Dijkstra(Graph,   source):
    dist[source] ← 0                 O(1)
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY  O(1)
              prev[v]  ← UNDEFINED
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:
         u ← Q.extract_min()
         for each  neighbor  v of  u:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)
    return dist, prev                  71  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Time Complexity
function Dijkstra(Graph,   source):
    dist[source] ← 0                 O(1)
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY  O(1)
              prev[v]  ← UNDEFINED
         Q.add_with_priority(v,    dist[v])  O(log |V|)
    while Q is   not empty:
         u ← Q.extract_min()
         for each  neighbor  v of  u:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)
    return dist, prev                  71  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Time Complexity
function Dijkstra(Graph,   source):
    dist[source] ← 0                 O(1)
    create   vertex priority queue Q
    for  each vertex v in  Graph:
         if  v ≠ source
              dist[v]  ← INFINITY  O(1)              O(|V| log |V|)
              prev[v]  ← UNDEFINED
         Q.add_with_priority(v,    dist[v])  O(log |V|)
    while Q is   not empty:
         u ← Q.extract_min()
         for each  neighbor  v of  u:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)
    return dist, prev                  71  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Time Complexity
function Dijkstra(Graph,   source):
    dist[source] ← 0
    create   vertex priority queue Q
    for  each vertex v in  Graph:       O(|V| log |V|)
         if  v ≠ source
              dist[v]  ← INFINITY
              prev[v]  ← UNDEFINED
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:
         u ← Q.extract_min()
         for each  neighbor  v of  u:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)
    return dist, prev                  72  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Time Complexity
function Dijkstra(Graph,   source):
    dist[source] ← 0
    create   vertex priority queue Q
    for  each vertex v in  Graph:       O(|V| log |V|)
         if  v ≠ source
              dist[v]  ← INFINITY
              prev[v]  ← UNDEFINED
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:
         u ← Q.extract_min()
         for each  neighbor  v of  u:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]           O(1)
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)
    return dist, prev                  72  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Time Complexity
function Dijkstra(Graph,   source):
    dist[source] ← 0
    create   vertex priority queue Q
    for  each vertex v in  Graph:       O(|V| log |V|)
         if  v ≠ source
              dist[v]  ← INFINITY
              prev[v]  ← UNDEFINED
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:
         u ← Q.extract_min()
         for each  neighbor  v of  u:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]           O(1)
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)  O(log |V|)
    return dist, prev                  72  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Time Complexity
function Dijkstra(Graph,   source):
    dist[source] ← 0
    create   vertex priority queue Q
    for  each vertex v in  Graph:       O(|V| log |V|)
         if  v ≠ source
              dist[v]  ← INFINITY
              prev[v]  ← UNDEFINED
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:                Combined with the outer loop,
         u ← Q.extract_min()             this loop runs total O(|E|) times
         for each  neighbor  v of  u:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]           O(1)
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)  O(log |V|)
    return dist, prev                  72  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Time Complexity
function Dijkstra(Graph,   source):
    dist[source] ← 0
    create   vertex priority queue Q
    for  each vertex v in  Graph:       O(|V| log |V|)
         if  v ≠ source
              dist[v]  ← INFINITY
              prev[v]  ← UNDEFINED
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:
         u ← Q.extract_min()
         for each  neighbor  v of  u:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]           O(1)           O(|E| log |V|)
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)  O(log |V|)
    return dist, prev                  73  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Time Complexity
function Dijkstra(Graph,   source):
    dist[source] ← 0
    create   vertex priority queue Q
    for  each vertex v in  Graph:       O(|V| log |V|)
         if  v ≠ source
              dist[v]  ← INFINITY
              prev[v]  ← UNDEFINED
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:  O(|V| log |V|)
         u ← Q.extract_min()
         for each  neighbor  v of  u:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]                          O(|E| log |V|)
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)
    return dist, prev                  73  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
     Dĳkstra Time Complexity
function Dijkstra(Graph,   source):
    dist[source] ← 0
    create   vertex priority queue Q
    for  each vertex v in  Graph:       O(|V| log |V|)
         if  v ≠ source
              dist[v]  ← INFINITY
              prev[v]  ← UNDEFINED         Total: O(log(|V|) * (|V| + |E|))
         Q.add_with_priority(v,    dist[v])
    while Q is   not empty:  O(|V| log |V|)
         u ← Q.extract_min()
         for each  neighbor  v of  u:
              alt ← dist[u]  + length(u, v)
              if alt < dist[v]                          O(|E| log |V|)
                  dist[v] ←  alt
                  prev[v] ←  u
                Q.decrease_priority(v, alt)
    return dist, prev                  73  Taken from https://en.wikipedia.org/wiki/Dijkstra's_algorithm
---
Dĳkstra Time Complexity
•  Total time complexity: O(log(|V|) * (|V| + |E|))
   ‣ This assumes we use an adjacency list
•  With adjacency matrix: O(|V|² + log(|V|)*|E|)
                            74
---
Exercise (from previous exam)
                                Perform Dijkstra’s algorithm starting at
                                vertex 1. For ties, choose the node with
                                the smaller number.
                                Use the same style of table as before!
                                 Node  Known    Prev    Dist   v =     v =     …
                                  1
                                  2
                                  3
                                  4
                                  5
                                  6
                                  7
                                       75
---
Exercise (from previous exam)
 Node   Known   Prev   Dist   v = 1   v =     v =    v =    v =    v =     v =
  1       F           0
  2       F           inf
  3       F           inf
  4       F           inf
  5       F           inf
  6       F           inf
  7       F           inf              76
---
Exercise (from previous exam)
                           Final table state:
 Node  Known    Prev   Dist   v = 1  v = 6   v = 2  v = 7  v = 3   v = 4  v = 5
  1     F T             0
  2     F T      1      20     20
  3     F T     6 7     25            30             25
  4     F T     6 3     28            35                    28
  5     F T     6 4     32            40                            32
  6     F T      1      10     10
  7     F T     1 2     23     25      77     23
---
CS 15: Data Structures
      Exceptions
---
Exceptions
• When programming, an exception is like an error: it is
   an indicator that something has gone wrong
•  In C++ (and other languages) we throw exceptions
   ‣  Sometimes called “raising” an exception
•  When an exception is thrown, either:
   ‣  the program terminates with an error message, or
   ‣  we handle or catch the exception, and the program continues
                             2
---
Kinds of Exceptions
•  If we #include the C++ library stdexcept, we get
   access to many kinds of common exceptions:
   ‣  runtime_error
   ‣  range_error
   ‣  system_error
   ‣ …
                             3
---
Kinds of Exceptions
•  If we #include the C++ library stdexcept, we get
   access to many kinds of common exceptions:
   ‣  runtime_error
   ‣  range_error
   ‣  system_error
   ‣ …
•  Today we’ll use range_error as an example
•  For your HW you’ll also use runtime_errors, but
   using them follows identical steps
                           3
---
    Throwing an Exception
    • When we throw an exception, we typically provide
       an associated error message:
int attempt_access(int arr[],    int size, int index)
{
     if (index  < 0 or index >=  size)
         throw  range_error("Oh no! Given index was out of range.\n");
     return arr[index];
}
   •  Once we throw an exception, if we do not have any
      special handling for it, the program will terminate
                                    4
---
Handling Exceptions
•  In C++, we handle exceptions using try…catch…
   statements:
    try  {
     …some code     you want  to run
         which may  throw an  exception…
    }
    catch(type_of_exc) {
     …code to execute in      the case that
      a type_of_exc exception occurs…
    }
                    5
---
 Handling Exceptions
int second_attempt_access(int arr[], int   size,  int index)
{
    try  {
         int result = attempt_access(arr,  size,  index);
         cout <<  "Successfully accessed  element!" << endl;
         return  result;
    }
    catch (range_error) {
         cout <<  "Terrible! Got a range  error! "
             <<   "Going to return 0 by default." << endl;
         return  0;
    }
}
                            6
---
 Handling Exceptions
int second_attempt_access(int arr[], int   size,  int index)
{
    try  {
         int result = attempt_access(arr,  size,  index);
         cout <<  "Successfully accessed  element!" << endl;
         return  result;
    }
    catch (range_error) {
         cout <<  "Terrible! Got a range  error! "
             <<   "Going to return 0 by default." << endl;
         return  0;
    }
}
•  By catching a range_error exception, our program can
   continue running even though an exception was thrown
                            6
---
Handling Exceptions
•  Sometimes we want to catch an exception, but also
   read the error message associated with it
•  We can do this using a const reference along with the
   C++ what()  method
                        7
---
   Catch and Print Exception
int third_attempt_access(int arr[], int size, int index)
{
    try  {
         int result = attempt_access(arr, size, index);
         cout <<  "Successfully accessed element!"   << endl;
         return result;
    }
    catch (const   range_error  &e) {
         cout <<  "We just got  the following error  message:\n";
         cout <<  e.what();
         return 0;
    }
}
                                8
---
Exceptions
• Let’s take a look at the full example: exceptions.cpp
                        9
---
CS 15: Data Structures
 A Quick Intro to File I/O
---
Streams
• A stream is a   flow of characters from one place to
   another
   ‣  Input stream: used for reading in data
   ‣  Output stream: used for outputting data
• We’re already familiar with some common ones
   ‣  Input stream: cin
   ‣  Output streams: cout, cerr
                             2
---
File Streams
•  Today we’ll look at file streams, which allow us to
   read from and write to files
•  Their use is very similar to cin/cout/cerr
                           3
---
File Streams
• The C++ fstream library provides three classes for file
   streams:
   ‣ ifstream: Stream class for reading from files
   ‣ ofstream: Stream class for writing to files
   ‣ fstream: Stream class for both reading from and writing to  files
                                4
---
File Stream
•  We declare variables of these types just like any
   other type of variable:
            int num;
            ifstream  instream;
            ofstream  outstream;
                      5
---
Opening Files
•  We just declared variables that hold stream objects, but
   we need to connect those streams to actual files
•  We do this by calling the open function, with the
   filename, on the stream objects:
      ifstream  instream;
      ofstream  outstream;
      …
      instream.open(“input_filename”)
      outstream.open(“output_filename”)
                        6
---
Using is_open
•  After opening a  file, you should always check if it was
   opened properly using the is_open() function
• Common reasons a file may not be open:
   ‣  Given input file name does not exist
      - Note: for output files, if file doesn’t exist, it will be created
   ‣  You don’t have permission to open file
• We check is_open for both input and output files
                              7
---
Using is_open
  ifstream instream;
  ofstream outstream;
  …
  instream.open(“input_filename”);
  if (not instream.is_open()) {
      cerr << “Unable to open input file.”;
      exit(EXIT_FAILURE);
  }
  outstream.open(“output_filename”);
  if (not outstream.is_open()) {
      cerr << “Unable to open output file.”;
      exit(EXIT_FAILURE);
  }
                      8
---
Using is_open
•  Notice: there is a lot of repetition
•  We can factor out code into a single function that:
   ‣  Opens a file (input or output)
   ‣  Checks that the file is open, exits program if not
                              9
---
    Opening and Checking Files
int main()                       By using a template, we can
{                                write a single function that
    ifstream instream;          works for both ifstreams and
    ofstream outstream;                   ofstreams
    ...
    open_or_die(instream, "input.txt");
    open_or_die(outstream, “output.txt");
    … use files …
}
template<typename streamtype>
void open_or_die(streamtype &stream, string file_name)
{
    stream.open(file_name);
    if (not stream.is_open()) {
        cerr << "Unable to open: " << file_name << endl;
        exit(EXIT_FAILURE);
    }
}                             10
---
Closing Files
•  After we are done with a file stream, we should always
   close it using the close() function:
   ‣ instream.close()
   ‣ oustream.close()
•  This lets the operating system know you’re done with
   the stream, performs any remaining writes, and frees
   memory associated with stream
                        11
---
Using File Streams
• Once a file stream is open, we use it just like we use
  cin, cout
  ‣  outstream << x << y; writes x then y to the file
     represented by outstream
  ‣  instream >> x >> y; reads one word at a time from
     instream, writes the first one to x and the second one to y
  ‣  getline(instream, string_var); reads an entire line
     from instream, stores the result in string_var
                        12
---
 Using File Streams
 •  Say we wish to read all the lines from a file, one at a
    time:
ifstream instream;
open_or_die(instream, "input.txt")
string   current_line;
while(getline(instream, current_line)) {
     //  Reads lines one at  a time,
     //  until entire file  has been  read
     //  Most recently read  line is  stored in current_line
     ...  use current_line  ...
}
                            13
---
 More Stream Operations
• instream.eof()
   ‣  Checks whether the last performed operation encountered “end
      of file”
   ‣  cin can encounter “end of file” too: user types CTRL+d
• getline(instream,           var).fail()
   ‣  Returns true if getline operation fails for any reason
      - e.g., attempted to read past end of input
• (instream       >> x).fail()
   ‣  Returns true if >> operation fails for any reason
      - e.g., attempted to read past end of input, or read data of wrong type
---
Optional Inputs/Outputs
•  Often times, we want to have a choice:
   ‣  Read input from file or from cin
   ‣  Write output to file or to cout
•  We want to do this without repeating code
   ‣  i.e., have the same code for input/output, regardless of where
      the input/output is from
                               15
---
istream and ostream
•  We can do this using the istream and ostream classes
•  istream: a general class for input streams
   ‣  Both cin and input file streams are kinds of istreams
•  ostream: a general class for output streams
   ‣  cout, cerr, and output file streams are kinds of ostreams
•  Technically:
   ‣  istream is a parent class of ifstream, and ostream is a parent
      class of ofstream
   ‣  You don’t need to worry about this in CS 15
                              16
---
istream and ostream
•  We can write a function that accepts both file streams
   and cin/cout:
                          17
---
    istream and ostream
int  main()                                             Note: istream and
{    ...                                               ostream parameters
     ifstream instream;                                   must always be
     ofstream outstream;                              reference parameters
     if (using_cin_and_cout) {
        example_fun(cin, cout);
     }
     else {
        open_or_die(instream,  "input.txt");
        open_or_die(outstream, "output.txt");
        example_fun(instream,  outstream);
     }
     return 0;
}
void example_fun(istream &input,    ostream &output)
{
     string var;
     // Reading  from input (works  for file or cin!)
     input >> var;
     // Writing  to output (works for  file or cout!)
     output << var;
}
                                         18
---
Input and Output Streams
•  istream and ostream allow us to write modular code
•  Let’s take a look at a complete example: isprime.cpp
                        19
---
CS 15: Data Structures
   Graph Traversals
---
Graphs
•  Recall: Previously we saw graphs
   ‣ A data structure composed of vertices connected by edges
                          2
---
Undirected Graphs
• Graphs can be undirected: edges do not have direction
                        3
---
Directed Graphs
• Graphs can be directed: edges have a direction
                        4
---
Unweighted Graphs
• Graphs can be unweighted: no value associated with
  each edge
                        5
---
Weighted Graphs
• Graphs can be weighted: a value is associated with
  each edge
  ‣  Could be a numerical weight, or could be a non-numerical label
                       4           0
                        15       10
                  -4      24            9
                              11
                                6
---
       Adjacency Matrix
       • Graphs can be represented using an adjacency matrix
                                                      1       14       2
                                                 5         29    42         16
                                            3       100        4        7         5
                                                  5      99         17        76
                            To                        6       82       7
                1    2    3   4     5   6     7
           1    -1  14    5   29   -1   -1   -1
           2    -1   -1   -1  42   16   -1   -1
           3    -1   -1   -1  -1   -1   5    -1
From       4    -1   -1  100  -1   -1   99   17
           5    -1   -1   -1   7   -1   -1   76
           6    -1   -1   -1  -1   -1   -1   -1
           7    -1   -1   -1  -1   -1   82   -1
                                          7
---
Adjacency List
•  Graphs can be represented using an adjacency list
    1   2, 3, 4                             1                2
    2  4, 5
    3  6                          3                  4                  5
    4   3, 6, 7
    5  4, 7
    6 6                                     6                7
    7
                                   8
---
Today
•  Today, we’ll focus on directed, unweighted graphs
   ‣   Notice: an undirected graph can be treated as a directed
       graph, where each edge points in both directions
• We’ll begin exploring some common graph questions
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       9
---
   Practice Question
   You are given a directed graph G, and a particular starting vertex v
   within the graph. Come up with a procedure to determine whether or
   not G is a valid tree rooted at v.
   For example, given Graph A and starting vertex 1, your procedure
   should return true. Given A and 4, your procedure should return
   false. Given either of graphs B or C and any starting node, your
   procedure should return false.
   You should use pseudocode or plain English.
Graph A                   Graph B                  Graph C
  1         3                     1    3                   1
         5     4               2          4             2          4
    2         6                    5                         5
                                   10
---
    Practice Question
    In a valid tree:
      •  There is one root node, which has no parent
      •  All other nodes have exactly one parent
      •  Taken together, these mean a tree is a graph where:
           ‣  There are no cycles
           ‣  All nodes are connected
    That is, a tree is a connected, acyclic graph.
Graph A                  Graph B                 Graph C
   1         3                   1    3                  1
         5     4              2         4             2         4
     2        6                   5                       5
                                  11
---
Practice Question
Key idea: Keep track of which vertices have been seen.
Initially, just the starting vertex has been seen.
Beginning at the starting vertex, traverse the graph. Mark
vertices as “seen” as they are visited.
If we ever re-visit an already seen vertex (i.e., graph has a
cycle), return false.
After the graph has been traversed, if any vertices are still
unseen, return false.
Otherwise, return true.
                           12
---
Practice Question
Key idea: Keep track of which vertices have been seen.
Initially, just the starting vertex has been seen.
Beginning at the starting vertex, traverse the graph. Mark
vertices as “seen” as they are visited.
If we ever re-visit an already seen vertex (graph has a
cycle), return false.
After the graph has been traversed, if any vertices are still
unseen, return false.      Today, we will study
Otherwise, return true.        approaches
                            to graph traversals
                         13
---
Common Questions
•  Is there a path between two given nodes?
•  What is the shortest path between two nodes?
   ‣   Because graph is unweighted, “shortest” == “fewest edges”
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       14
---
Shortest Path
•  Given a graph, a start node (e.g., v₃), and a destination
   node (e.g., v₄), how do we             find the shortest path
   between the nodes?
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       15
---
Shortest Path
•  High-level idea:
   ‣   Check if start node == destination node. If so, we’re done.
   ‣   Otherwise, visit all neighbors of the start node. If these include
       the destination, we’re done.
   ‣   Otherwise, visit all neighbors of nodes from the previous step. If
       these include the destination, we’re done.
   ‣ …                       v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       16
---
Shortest Path
•  Start at v₃
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       17
---
Shortest Path
•  Visit nodes at distance 1 from v₃
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       18
---
Shortest Path
•  Visit nodes at distance 2 from v₃
• Found v₄! Shortest path has distance 2.
•  What is the name of this kind of traversal?
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       19
---
Breadth First Search
• We just performed a breadth first traversal or
  breadth  first search (BFS)
  ‣  Visit all nodes at distance 0, then distance 1, then …
• We have seen BFS along with depth first search
  (DFS) before: trees!
                            20
---
Review: Tree Traversals
•  Using BFS, in what order will the nodes of the tree
   below be visited?
                            A
                    B             C
               D       E      F       G
                          21
---
Review: Tree Traversals
•  Using BFS, in what order will the nodes of the tree
   below be visited?
   ‣ Answer: A, B, C, D, E, F, G
   ‣ Recall: on trees, a BFS is often called a level-order traversal
                            A
                    B             C
               D       E      F       G
                          22
---
Review: Tree Traversals
• We saw three different types of DFS for trees:
   ‣ in-order, pre-order, post-order traversals
•  Key difference with BFS: first we go as deep in the tree
   as possible, before backtracking and visiting new nodes
                            A
                    B             C
                D       E     F       G
                           23
---
Review: Tree Traversals
•  Using in-order traversal, in what order are the nodes
   below visited?
                            A
                    B             C
               D       E      F       G
                          24
---
Review: Tree Traversals
•  Using in-order traversal, in what order are the nodes
   below visited?
   ‣ Answer: D, B, E, A, F, C, G
                            A
                    B             C
               D       E      F       G
                          25
---
    Tree vs. Graph Traversals
    •  What are some relevant differences when traversing a
       graph (rather than a tree)?
                  A                                    v₁                v₂
       B                   C                v₃                   v₄                  v₅
D           E         F          G                     v₆                 v₇
                                           26
---
   Tree vs. Graph Traversals
   •  What are some relevant differences when traversing a
      graph (rather than a tree)?
       1.  Unlike the root of a tree, there is no “starting point” in a graph.
           Need to be given a designated start.
       2.  Graphs can have cycles, trees cannot.
                A                               v₁               v₂
      B                 C              v₃                v₄                v₅
D         E        F         G                   v₆              v₇
                                     27
---
Handling Cycles
•  Why are cycles an issue?
   ‣   Could result in infinite paths, e.g.: v₃, v₁, v₄, v₃, v₁, v₄, v₃, …
•  Need to keep track of already visited nodes, avoid
   visiting them again
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       28
---
Breadth First Search
•  Notice: if we perform a complete BFS on a graph, then
   we find the shortest path from the start node to all
   other nodes in the graph
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       29
---
     Breadth First Search
     •  We will maintain a table with two columns:
        ‣  visited: keeps track of whether a node has been visited (true) or
           not (false). Initially, only start node has been visited.
        ‣  dist: Maintains the distance to each node. Initially, all distances
           are infinity, except start node’s distance, which is 0
           v₁              v₂                              v  visited dist
                                                           1    F     inf
v₃                 v₄                 v₅                   2    F     inf
                                                           3    T      0
                                                           4    F     inf
                                                           5    F     inf
           v₆               v₇                             6    F     inf
                                                           7    F     inf
                                        30
---
     Breadth First Search
     • When programming, how do we store the table?
        ‣  Could maintain two vectors for “visited” and “dist”
        ‣  Alternatively: Have “visited” and “dist”   fields in Node struct
           - Need to clear these fields for each new BFS!  struct Node {
                                                             ElementType    data;
                                                             bool   visited;
                                                             int  dist;
           v₁              v₂                            };v  visited dist
                                                           1    F     inf
v₃                 v₄                 v₅                   2    F     inf
                                                           3    T      0
                                                           4    F     inf
                                                           5    F     inf
           v₆               v₇                             6    F     inf
                                                           7    F     inf
                                        31
---
    Breadth First Search
    •  We will also maintain a queue of the nodes to visit next
       ‣   Just like BFS for trees
           v₁                v₂                                v   visited dist
                                                               1     F     inf
v₃                  v₄                   v₅                    2     F     inf
                                                               3     T      0
                                                               4     F     inf
                                                               5     F     inf
           v₆                v₇                                6     F     inf
                                                               7     F     inf
                                           32
---
     Breadth First Search
     1.  Explore v₃                      curr_dist = 0
        ‣ For all unvisited neighbors:Queue = 1, 6
          ‣  Set to visited, and update distance to curr_dist+1
          ‣  Add neighbor to queue
                                  Next up is next node in queue…
           v₁              v₂                              v  visited dist
                                                           1    T      1
v₃                 v₄                 v₅                   2    F     inf
                                                           3    T      0
                                                           4    F     inf
                                                           5    F     inf
           v₆               v₇                             6    T      1
                                                           7    F     inf
                                        33
---
     Breadth First Search
     2.  Explore v₁                      curr_dist = 1
        ‣ For all unvisited neighbors:Queue = 6, 2, 4
          ‣  Set to visited, and update distance to curr_dist+1
          ‣  Add neighbor to queue
           v₁              v₂                              v  visited dist
                                                           1    T      1
v₃                 v₄                 v₅                   2    T      2
                                                           3    T      0
                                                           4    T      2
                                                           5    F     inf
           v₆               v₇                             6    T      1
                                                           7    F     inf
                                        34
---
     Breadth First Search
     3.  Explore v₆                      curr_dist = 1
        ‣ For all unvisited neighbors:Queue = 2, 4
          ‣  Set to visited, and update distance to curr_dist+1
          ‣  Add neighbor to queue
           v₁              v₂                              v  visited dist
                                                           1    T      1
v₃                 v₄                 v₅                   2    T      2
                                                           3    T      0
                                                           4    T      2
                                                           5    F     inf
           v₆               v₇                             6    T      1
                                                           7    F     inf
                                        35
---
     Breadth First Search
     4.  Explore v₂                      curr_dist = 2
        ‣ For all unvisited neighbors:Queue = 4, 5
          ‣  Set to visited, and update distance to curr_dist+1
          ‣  Add neighbor to queue
           v₁              v₂                              v  visited dist
                                                           1    T      1
v₃                 v₄                 v₅                   2    T      2
                                                           3    T      0
                                                           4    T      2
                                                           5    T      3
           v₆               v₇                             6    T      1
                                                           7    F     inf
                                        36
---
     Breadth First Search
     4.  Explore v₄                      curr_dist = 2
        ‣ For all unvisited neighbors:Queue = 5, 7
          ‣  Set to visited, and update distance to curr_dist+1
          ‣  Add neighbor to queue
           v₁              v₂                              v  visited dist
                                                           1    T      1
v₃                 v₄                 v₅                   2    T      2
                                                           3    T      0
                                                           4    T      2
                                                           5    T      3
           v₆               v₇                             6    T      1
                                                           7    T      3
                                        37
---
     Breadth First Search
     4.  Explore v₅                      curr_dist = 3
        ‣ For all unvisited neighbors:Queue = 7
          ‣  Set to visited, and update distance to curr_dist+1
          ‣  Add neighbor to queue
           v₁              v₂                              v  visited dist
                                                           1    T      1
v₃                 v₄                 v₅                   2    T      2
                                                           3    T      0
                                                           4    T      2
                                                           5    T      3
           v₆               v₇                             6    T      1
                                                           7    T      3
                                        38
---
     Breadth First Search
     4.  Explore v₇                      curr_dist = 3
        ‣ For all unvisited neighbors:Queue =
          ‣  Set to visited, and update distance to curr_dist+1
          ‣  Add neighbor to queue               Queue is now empty.
                                                     We’re done!
           v₁              v₂                              v  visited dist
                                                          1     T      1
v₃                 v₄                 v₅                  2     T      2
                                                          3     T      0
                                                          4     T      2
                                                          5     T      3
           v₆               v₇                            6     T      1
                                                          7     T      3
                                        39
---
     Breadth First Search
     •  Question: What would happen if a node was
        unreachable from the start node?
           v₁              v₂                              v  visited dist
                                                           1    T      1
v₃                 v₄                 v₅                   2    T      2
                                                           3    T      0
                                                           4    T      2
                                                           5    T      3
           v₆               v₇                             6    T      1
                                                           7    T      3
                                        40
---
     Breadth First Search
     •  Question: What would happen if a node was
        unreachable from the start node?
        • Answer: distance would by infinity, visited would be false
           v₁              v₂                              v  visited dist
                                                           1    T      1
v₃                 v₄                 v₅                   2    T      2
                                                           3    T      0
                                                           4    T      2
                                                           5    T      3
           v₆               v₇                             6    T      1
                                                           7    T      3
                                        41
---
     Breadth First Search
     •  We have the shortest distances from v₃ to all other
        nodes. What if we want the path?
           v₁              v₂                              v  visited dist
                                                           1    T      1
v₃                 v₄                 v₅                   2    T      2
                                                           3    T      0
                                                           4    T      2
                                                           5    T      3
           v₆               v₇                             6    T      1
                                                           7    T      3
                                        42
---
     Breadth First Search
     •  We have the shortest distances from v₃ to all other
        nodes. What if we want the path?
     •  Solution: Add a “predecessor” column to the table.
        Then, when a node is added to the queue, note its
        predecessor.
           v₁              v₂                              v  visited dist
                                                           1    T      1
v₃                 v₄                 v₅                   2    T      2
                                                           3    T      0
                                                           4    T      2
                                                           5    T      3
           v₆               v₇                             6    T      1
                                                           7    T      3
                                        43
---
    Breadth First Search
    •   Predecessor of starting node is some sentinel value
       ‣  Examples: nullptr, -1, …
       ‣  Depends on application
           v₁                v₂                                v  visited   dist pred
                                                               1     F     inf
v₃                  v₄                   v₅                    2     F     inf
                                                               3     T      0     null
                                                               4     F     inf
                                                               5     F     inf
           v₆                v₇                                6     F     inf
                                                               7     F     inf
                                           44
---
     Breadth First Search
     1.  Explore v₃                      curr_dist = 0
        ‣ For all unvisited neighbors:Queue = 1, 6
          ‣  Update predecessor to v₃
          ‣  Set to visited, and update distance to curr_dist+1
          ‣  Add neighbor to queue
           v₁              v₂                              v visited  dist pred
                                                           1    T      1    3
v₃                 v₄                 v₅                   2    F     inf
                                                           3    T      0    null
                                                           4    F     inf
                                                           5    F     inf
           v₆               v₇                             6    T      1     3
                                                           7    F     inf
                                        45
---
     Breadth First Search
     2.  Explore v₁                      curr_dist = 1
        ‣ For all unvisited neighbors:Queue = 6, 2, 4
          ‣  Update predecessor to v₁
          ‣  Set to visited, and update distance to curr_dist+1
          ‣  Add neighbor to queue
           v₁              v₂                              v visited  dist pred
                                                           1    T      1    3
v₃                 v₄                 v₅                   2    T      2    1
                                                           3    T      0   null
                                                           4    T      2    1
                                                           5    F     inf
           v₆               v₇                             6    T      1     3
                                                           7    F     inf
                                        46
---
     Breadth First Search
           v₁              v₂                             Final table:
                                                           v visited  dist pred
                                                           1    T      1    3
v₃                 v₄                 v₅                   2    T      2    1
                                                           3    T      0   null
                                                           4    T      2    1
                                                           5    T      3    2
           v₆               v₇                             6    T      1    3
                                                           7    T      3    4
                                        47
---
     Breadth First Search
     •  If we want the path to a particular destination, we read
        the predecessors in reverse, starting at destination
           v₁              v₂                             Final table:
                                                           v visited  dist pred
                                                           1    T      1    3
v₃                 v₄                 v₅                   2    T      2    1
                                                           3    T      0   null
                                                           4    T      2    1
                                                           5    T      3    2
           v₆               v₇                             6    T      1    3
                                                           7    T      3    4
                                        48
---
     Breadth First Search
      e.g., what is the shortest path from v₃ to v₇?
                         7’s predecessor: 4
                         4’s predecessor: 1
                         1’s predecessor: 3
                         Final path: 3, 1, 4, 7
           v₁              v₂                             Final table:
                                                           v visited  dist pred
                                                           1    T      1    3
v₃                 v₄                 v₅                   2    T      2    1
                                                           3    T      0   null
                                                           4    T      2    1
                                                           5    T      3    2
           v₆               v₇                             6    T      1    3
                                                           7    T      3    4
                                        49
---
Breadth First Search
•  Notice: keeping track of distance during BFS is optional
   ‣  May not be interested in distance
   ‣  Or, if we are, it can be reconstructed by following the
      predecessors
                            50
---
BFS Pseudocode
bfs(Vertex start):
    for  each Vertex   v:
         v.pred = nullptr;    O(|V|)
         v.visited  =  false;
    Queue<Vertex>   q;
    start.visited   =  true;  O(1)
    q.enqueue(start);
    while(not q.isEmpty()): Loop runs O(|V|) times
       Vertex  current  =  q.dequeue(); O(1)
       for  each neighbor  n of current:
          if n is unvisited:  Loop runs O(eadj) times,
            n.visited   =  true;where eadj is # edges
            n.pred  =  current;adjacent to current node
            q.enqueue(n);
O(|V|) * (O(1) + O(eadj)) = O(|V|) + O(|V|)*O(eadj) = O(|V| + |E|)
                       51
---
BFS Pseudocode
bfs(Vertex start):
    for  each Vertex   v:
         v.pred = nullptr;    O(|V|)
         v.visited  =  false;
    Queue<Vertex>   q;
    start.visited   =  true;  O(1)
    q.enqueue(start);                  O(|V|+|E|)
    while(not q.isEmpty()):
       Vertex  current  = q.dequeue();
       for  each neighbor        n of current:
          if n is unvisited:
            n.visited   =       true;
            n.pred  =        current;
            q.enqueue(n);
       O(|V|+|E|) + O(1) +₅₂ O(|V|) = O(|V|+|E|)
---
BFS Time Complexity
•  Total time complexity is O(|V| + |E|)
•  But notice: this is only if we can get constant time
   access to the list of neighbors of a node
•  i.e., O(|V| + |E|) is the complexity when using an
   adjacency list
•  When using an adjacency matrix, it takes O(|V|) time to
   access all the neighbors of a node
   ‣ Need to iterate over all |V| entries in row of matrix
•  Thus, when using an adjacency matrix, the complexity
   is O(|V|²)
                           53
---
     BFS Pseudocode
                                   Compare
                             with BFS for trees.
                                *Very* similar!
graph_bfs(Vertex   start):               tree_bfs(root):
    for  each Vertex v:                    queue<Node>   q;
         v.pred =  nullptr;
         v.visited =  false;               q.enqueue(root);
    Queue<Vertex> q;                       while(!q.isEmpty()):
    start.visited =   true;                   curr = q.top();
    q.enqueue(start);                         if (curr  != nullptr)
    while(not q.isEmpty()):                      visit  curr;
         Vertex current = q.dequeue();           q.enqueue(curr->left)
         for  each neighbor n of current:        q.enqueue(curr->right)
              n.visited = true;               q.dequeue()
              n.pred = current;
              q.enqueue(n);
                                      54
---
Depth First Search
•  Unlike BFS, DFS traversal moves as deep into a graph
   as possible, then backtracks and explores new paths
•  Like BFS, DFS has to keep track of visited nodes
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       55
---
Depth First Search
•  Let’s try on the below graph.
   ‣   Start node: v₃
   ‣   Whenever we have a choice between nodes, choose the node
       with the smaller number
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       56
---
Depth First Search
•  Let’s try on the below graph.
   ‣   Start node: v₃
   ‣   Whenever we have a choice between nodes, choose the node
       with the smaller number
   Order of nodes visited: 3
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       57
---
Depth First Search
•  Let’s try on the below graph.
   ‣   Start node: v₃
   ‣   Whenever we have a choice between nodes, choose the node
       with the smaller number
   Order of nodes visited: 3, 1
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       58
---
Depth First Search
•  Let’s try on the below graph.
   ‣   Start node: v₃
   ‣   Whenever we have a choice between nodes, choose the node
       with the smaller number
   Order of nodes visited: 3, 1, 2
                             v₁                v₂
                  v₃                   v₄                  v₅
                             v₆                 v₇
                                       59
---
Depth First Search
•  Let’s try on the below graph.
   ‣  Start node: v₃
   ‣  Whenever we have a choice between nodes, choose the node
      with the smaller number
  Order of nodes visited: 3, 1, 2, 4
                        v₁             v₂
               v₃               v₄               v₅
                        v₆              v₇
                                60
---
Depth First Search
•  Let’s try on the below graph.
   ‣  Start node: v₃
   ‣  Whenever we have a choice between nodes, choose the node
      with the smaller number
                                                5 is a dead-end!
  Order of nodes visited: 3, 1, 2, 4, 5   Back track to last node with
                                         unvisited neighbor, continue.
                        v₁             v₂
               v₃              v₄               v₅
                        v₆             v₇
                               61
---
Depth First Search
•  Let’s try on the below graph.
   ‣  Start node: v₃
   ‣  Whenever we have a choice between nodes, choose the node
      with the smaller number
  Order of nodes visited: 3, 1, 2, 4, 5, 6
                       v₁             v₂
              v₃               v₄               v₅
                        v₆             v₇
                               62
---
Depth First Search
•  Let’s try on the below graph.
   ‣  Start node: v₃
   ‣  Whenever we have a choice between nodes, choose the node
      with the smaller number
  Order of nodes visited: 3, 1, 2, 4, 5, 6, 7
                       v₁             v₂
              v₃               v₄               v₅
                        v₆             v₇
                               63
---
Depth First Search
•  Let’s try on the below graph.
   ‣  Start node: v₃
   ‣  Whenever we have a choice between nodes, choose the node
      with the smaller number
  Order of nodes visited: 3, 1, 2, 4, 5, 6, 7        Done!
                       v₁             v₂
              v₃               v₄               v₅
                        v₆             v₇
                               64
---
Using DFS
•  Unlike BFS, DFS is not used to find shortest paths
   ‣ Can be done, but implementation is clunky, inefficient
•  When exploring paths deep in the graph, DFS can be useful
•  We’ve seen one example: solving mazes!
   ‣  Go as deep as you can, backtrack when
      you hit a wall
•  Another example: exploring chess trees:
                           65
---
DFS Pseudocode
dfs(Vertex start):
    for each Vertex v:
       v.visited = false;
    dfs_helper(start);
dfs_helper(Verted current):
    current.visited = true;
    …do  whatever you want with current…
    for  each neighbor n of current:
         if not n.visited:
            dfs_helper(n);
                     66
---
DFS Time Complexity
•  Similar to BFS:
   ‣  O(|V| + |E|) when using adjacency list
   ‣  O(|V|²) when using adjacency matrix
                            67
---
Practice Problem
Given the graph below, provide the visiting order of a
BFS and a DFS traversal, both starting at node 1. If
you ever have a choice of which node to visit next,
choose the lower-numbered node.
                               1
                                                   4
              3
                             2
         5            6                         7
                                        8
                                   68
---
   Practice Problem
                                  1                                    = seen
                                                       4
                 3
                                2
             5            6                         7
                                           8
BFS: 1                                      Queue:
                                      69
---
   Practice Problem
                                  1
                                                       4
                 3
                                2
             5            6                         7
                                           8
BFS: 1                                      Queue: 2, 3
                                      70
---
   Practice Problem
                                  1
                                                       4
                 3
                                2
             5            6                         7
                                           8
BFS: 1, 2                                   Queue: 3, 6, 7
                                      71
---
   Practice Problem
                                  1
                                                       4
                 3
                                2
             5            6                         7
                                           8
BFS: 1, 2, 3                                Queue: 6, 7
                                      72
---
  Practice Problem
                             1
                                              4
              3
                           2
          5           6                     7
                                     8
BFS: 1, 2, 3, 6                      Queue: 7, 5
                                73
---
  Practice Problem
                             1
                                              4
              3
                           2
          5           6                     7
                                     8
BFS: 1, 2, 3, 6, 7                   Queue: 5, 4, 8
                                74
---
  Practice Problem
                             1
                                              4
              3
                           2
          5           6                     7
                                     8
BFS: 1, 2, 3, 6, 7, 5                Queue: 4, 8
                                75
---
  Practice Problem
                             1
                                              4
              3
                           2
          5           6                     7
                                     8
BFS: 1, 2, 3, 6, 7, 5, 4             Queue: 8
                                76
---
  Practice Problem
                             1
                                              4
              3
                           2
          5           6                     7
                                     8
BFS: 1, 2, 3, 6, 7, 5, 4, 8
                                77
---
  Practice Problem
                             1
                                              4
              3
                           2
          5           6                     7
                                     8
BFS: 1, 2, 3, 6, 7, 5, 4, 8
DFS: 1
                                78
---
  Practice Problem
                             1
                                              4
              3
                           2
          5           6                     7
                                     8
BFS: 1, 2, 3, 6, 7, 5, 4, 8
DFS: 1, 2
                                79
---
  Practice Problem
                             1
                                              4
              3
                           2
          5           6                     7
                                     8
BFS: 1, 2, 3, 6, 7, 5, 4, 8
DFS: 1, 2, 3
                                80
---
  Practice Problem
                             1
                                              4
              3
                           2
          5           6                     7
                                     8
BFS: 1, 2, 3, 6, 7, 5, 4, 8
DFS: 1, 2, 3, 6
                                81
---
  Practice Problem
                             1
                                              4
              3
                           2
          5           6                     7
                                     8
BFS: 1, 2, 3, 6, 7, 5, 4, 8
DFS: 1, 2, 3, 6, 5
                                82
---
  Practice Problem
                             1
                                              4
              3
                           2
          5           6                     7
                                     8
BFS: 1, 2, 3, 6, 7, 5, 4, 8
DFS: 1, 2, 3, 6, 5, 8
                                83
---
  Practice Problem
                             1
                                              4
              3
                           2
          5           6                     7
                                     8
BFS: 1, 2, 3, 6, 7, 5, 4, 8
DFS: 1, 2, 3, 6, 5, 8, 7
                                84
---
  Practice Problem
                             1
                                              4
              3
                           2
          5           6                     7
                                     8
BFS: 1, 2, 3, 6, 7, 5, 4, 8
DFS: 1, 2, 3, 6, 5, 8, 7, 4
                                85
---
CS 15: Data Structures
 Introduction to Graphs
---
  What Graphs Are Not
In CS, “graph” has
a different meaning
                           2
---
Linked Data Structures
•  We’ve seen two kinds of linked data structures:
   ‣ Linked Lists
   ‣ Trees
                             3
---
Linked Data Structures
•  Linked data structures consist of nodes and edges
•  Similarly, a graph is a data structure with:
   ‣  A set of vertices (also called nodes)
   ‣  A set of edges between vertices (also called arcs)
•  Unlike linked lists or trees, edges in a graph can occur
   between any two nodes
                             4
---
Graphs
                  This is a graph
                        5
---
Graphs
                  This is a graph
                        6
---
Graphs
     This is also a graph! Notice:
       • No imposed structure (root, children, etc.)
       •  Cycles are allowed
       •  Vertices can point to themselves
       • Some vertices may not be connected to
          any others
                           7
---
Graphs
•  A graph is a set of vertices and edges, where edges are
   allowed to connect any two vertices
• What can we use them for?
   ‣  It turns out, a lot
   ‣  Any time we want to model entities and their relationships, or
      states and transitions between them
                             8
---
Example: Social Media
• e.g., representing Facebook users and their friends
                        9
---
Example: Websites and Links
•  Websites as vertices, links as edges
   ‣  Google actually uses a website’s # of incoming links in its
      search ranking algorithm
                            w₂
                  w₁                 w₃
                            w₅
                                               w₇
                  w₆                 w₄
                            10
---
Undersea Internet Cables
• 99% of transoceanic data traﬃc is transmitted through
  undersea cables
                        11
---
Example: Maps
•  Cities/States/Countries as vertices
   ‣  Common question: Shortest distance between cities?
      - This is done when creating a flight itinerary (might need connections!)
                              12
---
Example: Control Flow Graphs
•  Control flow graph: pieces of code as vertices,
   transitions as edges
   ‣  Useful in building debuggers, compilers, …
      - Are all parts of program reachable? Have I tested all parts of program?
                              13
---
Types of Graphs
• A graph can be directed or undirected
•  Directed: every edge has a direction associated with it
•  Undirected: edges have no direction
   ‣ They simply represent connections between vertices
                         14
---
Directed Graph
•  Edges have direction
   ‣ One node “points to” another node
                           w₂
                  w₁                 w₃
                           w₅
                  w₆                 w₄
                            15
---
Undirected Graph
•  Edges do not have direction
                              u₅
              u₂                           u₃
               u₁
                                             u₄
                                 16
                                 16
---
Types of Graph
• A graph can be weighted or unweighted
• Weighted: Each edge has an associated value or weight
• Unweighted: Edges do not have an associated value
                        17
---
Weighted Graph
              18
---
Unweighted Graph
                              u₅
              u₂                           u₃
               u₁
                                             u₄
                                 19
---
Types of Graph
•  Note: instead of a numeric weight, an edge may instead
   have a label
   ‣  e.g., for a graph representing a city map, edges could be
      labelled with street names
                          20
---
  Depicting Graphs
  •  Layout of graph doesn’t matter
     ‣ What matters is the vertices, edges in the graph
                   These graphs are             w₆
         w₂        exactly the same
w₁       w₅       w₃            w₄
w₆                w₄
                                                        w₁
                                    w₅          w₂
                            21            w₃
---
Graphs: Formal Definition
A graph is a pair G = (V, E) where
     V = { v₁, …, vₙ } (a set of vertices)
     E = { (vₓ, vy) | vₓ, vy ∈ V } (a set of pairs of vertices)
                For weighted
             graphs, this may be
              a triplet (vₓ, vy, w)
                              22
---
Graphs: Formal Definition
A graph is a pair G = (V, E) where
    V = { v₁, …, vₙ } (a set of vertices)
    E = { (vₓ, vy) | vₓ, vy ∈ V } (a set of pairs of vertices)
  For directed graphs, we interpret this as
           an edge from vₓ to vy.
                           23
---
Graphs: Formal Definition
A graph is a pair G = (V, E) where
    V = { v₁, …, vₙ } (a set of vertices)
    E = { (vₓ, vy) | vₓ, vy ∈ V } (a set of pairs of vertices)
    For undirected graphs, we
        interpret this as an
     edge between vₓ and   vy.
 Alternatively, we may require that
(vₓ, vy) ∈ E if and only if (vy, vₓ) ∈ E
                            24
---
Graph Practice Question
In a point-based, 2 player, win by 2 game, there are five
states the game can be in at the end:
  ‣  Player 1 wins
  ‣  Player 2 wins
  ‣  Tie
  ‣  Player 1 has 1 point advantage
  ‣  Player 2 has 1 point advantage
Draw a directed, labelled graph representing the possible end
states of the game, and the transitions between them. Graph
vertices represent game states, and edges should be labeled
with either “Player 1 scores” or “Player 2 scores.”
                              25
---
   Graph Practice
                    Advantage Player 1
    Player 1 scores                           Player 1 scores
                         Player 2 scores               Player 1 Wins
    Tie
                Player 2 scores
                                                       Player 2 Wins
Player 1 scores    Advantage Player 2           Player 2 scores
                                    26
---
Common Graph Questions
•  Given two vertices A and B, find a path from A to B
•  Find the shortest path between two vertices
   (unweighted graph)
•  Find the lowest cost path between two vertices
   (weighted graph)
• But first: how do we represent a graph?
                         27
---
Representing Vertices
•  Application-specific, but generally we can use a struct
•  e.g., say the vertices in our graph are cities:
              struct CityNode {
                  string name;
                  float lat, long;
              };
                       28
---
Representing Vertices
•  Application-specific, but generally we can use a struct
•  e.g., say the vertices in our graph are cities:
               struct CityNode    {
                    string  name;
                    float  lat,  long;
               };
•  Need to keep track of the group of vertices in our graph
   ‣ Could use a list, vector, set, hash, …
            vector<CityNode> vertices;
        Notice: there is no single node we keep track
         of, unlike trees (root) or linked lists (front)
                          29
---
Representing Edges
•  Want to represent adjacency in our graph: which pairs
   of vertices in our graph are connected by an edge?
   ‣  If directed graph: What direction does each edge point in?
   ‣  If weighted: What is the value of each edge weight?
   ‣  If labeled: What is the label of each edge?
                            30
---
Representing Edges
• There are two common ways for representing a graph:
  ‣ Adjacency matrix
  ‣ Adjacency list
• These diﬀer primarily in how they represent edges
                        31
---
Adjacency Matrix
• An adjacency matrix is a matrix of size |V| x |V| (where
   |V| is the number of vertices)
• Each entry  (i, j) in the matrix represents an edge (or
   lack thereof)
•  Note: to use an adjacency matrix, each vertex must
   have an associated number
   ‣  If vertices are stored in a vector, could use the vertex index
      - Ignoring adding/removing of vertices, for now
                            32
---
Adjacency Matrix
•  For a directed, unweighted graph, we can use a
   matrix where:
   ‣  Rows represent the “from” vertex
   ‣  Columns represent the “to” vertex
   ‣  Entries are booleans: true if an edge exists, false otherwise
                            33
---
Adjacency Matrix
                          1                2
                3                  4                  5
                           6                7
                                  To
                       1    2    3    4    5    6   7
                  1
                  2
                  3
       From       4
                  5
                  6
                  7
                                   34
---
Adjacency Matrix
                          1                2
                3                  4                  5
                           6                7
                                  To
                       1    2    3    4    5    6   7
                  1    F    T    T    T    F    F   F
                  2
       From       3                      Each entry is True if edge
                  4                       exists, False otherwise
                  5
                  6
                  7
                                   35
---
Adjacency Matrix
                          1                2
                3                  4                  5
                           6                7
                                  To
                       1    2    3    4    5    6   7
                  1    F    T    T    T    F    F   F
                  2    F    F    F    T    T    F   F
                  3
       From       4
                  5
                  6
                  7
                                   36
---
Adjacency Matrix
                         1              2
               3                 4                5
                         6               7
                                To
                     1    2    3   4    5   6    7
                 1   F    T    T   T    F   F    F
                 2   F    F    F   T    T   F    F
                 3   F    F    F   F    F   T    F
       From      4
                 5
                 6
                 7
                                 37
---
Adjacency Matrix
                         1              2
               3                 4                5
                         6               7
                                To
                     1    2    3   4    5   6    7
                 1   F    T    T   T    F   F    F
                 2   F    F    F   T    T   F    F
                 3   F    F    F   F    F   T    F
       From      4   F    F    T   F    F   T    T
                 5   F    F    F   T    F   F    T
                 6   F    F    F   F    F   F    F
                 7   F    F    F   F    F   T    F
                                 38
---
Weighted Adjacency Matrix
•  If edges are weighted or labelled, then we can store the
   weight/label as the matrix entry
•  Need a special “sentinel” for all non-edges
   ‣  We’ll use -1 in our example
   ‣  Be careful: -1 only works if negative numbers aren’t allowed as
      weights
                            39
---
Adjacency Matrix
                          1       14       2
                     5          29    42         16
                3        100       4         7        5
                      5       99        17        76
                           6       82       7
                                  To
                       1    2   3    4     5   6    7
                  1   -1   14   5    29   -1   -1   -1
                  2   -1   -1   -1   42   16   -1   -1
                  3   -1   -1   -1   -1   -1   5    -1
       From       4   -1   -1  100   -1   -1   99   17
                  5   -1   -1   -1    7   -1   -1   76
                  6   -1   -1   -1   -1   -1   -1   -1
                  7   -1   -1   -1   -1   -1   82   -1
                                   40
---
Undirected Graphs
•  For an undirected graph, the adjacency matrix will be
   similar—but we don’t interpret rows/columns as from/to
•  What will the adjacency matrix for an undirected graph
   look like?
                          1                2
                3                  4                  5
                           6                7
                                   41
---
Undirected Graphs
•  What will the adjacency matrix for an undirected graph
   look like?
                          1                2
                3                  4                  5
                           6                7
                                   42
---
Undirected Graphs
•  What will the adjacency matrix for an undirected graph
   look like?
•  It will be symmetric:
   ‣  The entry for (i, j) is the same as the entry for (j, i)
   ‣  Upper-right triangle of matrix will mirror lower-left triangle
                          1                2
                3                  4                  5
                           6                7
                                   43
---
Undirected Graphs
                         1              2
               3                 4                5
                                                         Some
                                                   implementations
                         6               7           will just store
                                                   upper triangle of
                                                         matrix
                     1    2    3   4    5   6    7
                 1   F    T    T   T    F   F    F
                 2   T    F    F   T    T   F    F
                 3   T    F    F   T    F   T    F
                 4   T    T    T   F    T   T    T
                 5   F    T    F   T    F   F    T
                 6   F    F    T   T    F   F    T
                 7   F    F    F   T    T   T    F
                                 44
---
Adjacency Matrix Analysis
                       1    2    3    4    5    6   7
                  1
                  2
                  3
                  4
                  5
                  6
                  7
•  In terms of |V| (# vertices) and |E| (# edges):
   ‣  Given vertices vi and vj, how long does it take to look up an
      edge between the vertices (or lack thereof)?
         Answer: O(1) (assuming matrix is 2D array
                            or ArrayList)
                                   45
---
  Adjacency Matrix Analysis
                      1   2   3    4   5   6    7
                  1
                  2
                  3
                  4
                  5
                  6
                  7
  •  In terms of |V| (# vertices) and |E| (# edges):
     ‣ What is the space complexity of an adjacency matrix?
                         Answer: O(|V|²)
   Not great! If there actually are close to |V|² edges this is
okay, but frequently graphs are sparse: relatively few edges
                                46
---
Adjacency Matrix Analysis
                   1   2   3    4   5   6   7
               1
               2
               3
               4
               5
               6
               7
•  In terms of |V| (# vertices) and |E| (# edges):
   ‣ How long to iterate over all edges in graph?
                      Answer: O(|V|²)
  Also not great! Have to iterate over all matrix entries,
whether or not there is an edge. Bad for sparse graphs.
                             47
---
Adjacency Matrix Arithmetic
• One benefit of an adjacency matrix: they can be easily
   used for many arithmetic computations
•  See, e.g.: Floyd-Warshall algorithm
   ‣  Used for finding shortest paths in a directed, weighted graph
   ‣  Relies on matrix multiplication
                            48
---
Representing Edges
• There are two common ways for representing a graph:
  ‣ Adjacency matrix
  ‣ Adjacency list
• These diﬀer primarily in how they represent edges
                        49
---
Adjacency Lists
•  In an adjacency list, for each vertex, we maintain a
   collection of vertices that are adjacent to it
   ‣  Actually, could be any kind of collection: ArrayList, linked list,
      set, BST, hash…
                            50
---
Adjacency Lists
                      1             2
             3               4               5
                      6             7
                 1   2, 3, 4
                 2  4, 5          Notice: We only need to
                 3 6                store existing edges,
                 4   3, 6, 7        don’t need space for
                 5  4, 7             non-existing edges!
                 6
                 7 6
                             51
---
Adjacency Lists
•  Note:
   ‣  Adjacency list can be stored in a separate data structure, or it
      can be stored in vertices themselves
   ‣  For weighted/labelled edges, need some way of storing weight/
      label
      - e.g., could use Edge struct which stores vertex and weight/label
                               52
---
Adjacency List Analysis
•  In terms of |V| (# vertices) and |E| (# edges):
   ‣ What is the space complexity?
        O(|V|) lists + O(|E|) edges across all lists =
                        O(|V| + |E|)
           Much better than adjacency matrix
            when |E| is much smaller than |V|²
                            53
---
Adjacency List Analysis
•  In terms of |V| (# vertices) and |E| (# edges):
   ‣ How long to iterate over all edges?
                  Answer: O(|V| + |E|)
         Need to check O(|V|) lists, and in total
               iterate over O(|E|) edges.
        Unlike adjacency matrix, we can access
                    just the edges.
                          54
---
Adjacency List Analysis
•  In terms of |V| (# vertices) and |E| (# edges):
   ‣  Given vertices vi and vj, how long does it take to look up an
      edge between the vertices (or lack thereof)?
        If edges are stored in lists: O(|V|)
          •   Need to iterate over all of a vertex’s
              neighbors, and a vertex is potentially
              connected to all |V| other vertices
       Can we do better? Depends on the data structure!
          •  If edges are stored in BST, could be O(log |V|)
          •  If edges are stored in a hash, could be O(1)
                             55
---
Practice Questions
1.    Would you use the adjacency list structure or the adjacency matrix
      structure in each of the following cases? Justify your choice.
     a.  The graph has 10,000 vertices and 20,000 edges.
     b.  The graph has 10,000 vertices and 90,000,000 edges.
     c.  You need to answer the query areAdjacent(v1, v2) as fast as possible.
2.  Draw an adjacency list and adjacency matrix representation of the
    following directed graph:
                                         2
                              1                      3
                                         5
                              6                      4
                                   56
---
 Practice Question #2
Adjacency Matrix                               Adjacency List
       1     2    3    4    5    6                 1  2
  1    F     T    F    F    F    F                 2  4
  2    F     F    F    T    F    F
  3    F     T    F    F    F    F                 3  2
  4    T     F    F    F    F    T                 4  1, 6
  5    T     F    T    F    F    F                 5  1, 3
  6    T     F    F    F    T    F                 6  1, 5
                              2
                   1                     3
                              5
                   6                     4
                                  57
---
CS 15: Data Structures
       Hashes
---
Key-Value Pairs
• We have studied finite maps, an ADT for storing key-
   value pairs
   ‣  Other names: associative array, maps, dictionaries, key-value
      store…
•  Idea:
   ‣  The key is like the name/label of the data you want to store
   ‣  The value is the actual content you want to store
                             2
---
Key-Value Examples
•  Dictionaries
   ‣  Key is word, value is definition
•  Contact list
   ‣  Key is name, value is phone/email/address
•  Hospital records
   ‣  Key is wristband number, value is patient info
• …
                             3
---
Key-Value Pairs
•  Notice: value can be arbitrarily complex
   ‣ e.g., value is often aggregate rather than a single piece of data
                           Index of Book:
                             ‣  Key is topic name
                             ‣  Value is list of page ranges
                             4
---
Common Operations for Maps
•  Insertion:
   ‣  Given (key, value) pair, store it in the finite map
•  Find:
   ‣  Given key, return associated value
• Removal:
   ‣  Given key, remove associated value from the finite map
•  Typically some others too:
   ‣  hasKey(k), isEmpty(), size()…
                              5
---
Common Operations for Maps
Most languages store/retrieve elements in a map using
[], just like with arrays.
Unordered maps in C++:
    unordered_map<string,  string> dictionary;
    dictionary[“hello”] =  “a common greeting”;
    cout << dictionary[“hello”];
    …
                      6
---
Implementing Finite Maps
We have seen a few data structures we can use:
•  Linked lists
•  ArrayLists
•  (Balanced) Binary Search Trees
• Heaps?       No! Heaps only give access to min (or max)
               data. Finite maps give access to any data
               given a key.
                          7
---
Time Complexity Comparison
•  What are the complexities, for a           finite map of size
   n, of the following operations?
       Implementation    Insertion       Find         Removal
         Linked List
          ArrayList
          Sorted AL
        Balanced BST
                                   8
---
Time Complexity Comparison
       Implementation    Insertion        Find          Removal
         Linked List       O(1)           O(n)            O(n)
          ArrayList
          Sorted AL
        Balanced BST
                                    9
---
Time Complexity Comparison
       Implementation     Insertion        Find         Removal
         Linked List        O(1)           O(n)           O(n)
          ArrayList         O(1)           O(n)           O(n)
          Sorted AL
        Balanced BST
                                     10
---
Time Complexity Comparison
       Implementation     Insertion        Find         Removal
         Linked List        O(1)           O(n)           O(n)
          ArrayList         O(1)           O(n)           O(n)
          Sorted AL         O(n)         O(log n)         O(n)
        Balanced BST
                                     11
---
Time Complexity Comparison
                These are the worst and average
                          case complexities
       Implementation     Insertion        Find         Removal
         Linked List        O(1)           O(n)           O(n)
          ArrayList         O(1)           O(n)           O(n)
          Sorted AL         O(n)         O(log n)         O(n)
        Balanced BST      O(log n)       O(log n)        O(log n)
                                     12
---
   Time Complexity Comparison
Today we will study hashes, a popular data structure for
implementing finite maps.
          Implementation     Insertion        Find         Removal
            Linked List        O(1)           O(n)           O(n)
             ArrayList         O(1)           O(n)           O(n)
             Sorted AL         O(n)         O(log n)         O(n)
           Balanced BST      O(log n)       O(log n)        O(log n)
                                        13
---
    Time Complexity Comparison
 Today we will study hashes, a popular data structure for
 implementing finite maps.
           Implementation     Insertion        Find         Removal
             Linked List        O(1)           O(n)           O(n)
              ArrayList         O(1)           O(n)           O(n)
              Sorted AL         O(n)         O(log n)         O(n)
            Balanced BST      O(log n)       O(log n)        O(log n)
🎉             Hashes           O(1)           O(1)           O(1)           🎉
            (average case)
                                         14
---
Hashes
 Credit: Ellis Brown
                               15
---
Hashes in Languages
                      Name                             System
            Content-addressable memory         hardware
            Dictionary                         Python
            Hash table                         Haskell, SML, Racket
            Hash map                           Rust
            Hash                               Ruby
            Table                              Lua
            Map                                C++, Erlang, Elixir
            Object                             Javascript
            Array                              PHP
                                    16
---
Implementing Finite Maps
• Side note: many languages provide both hash-based
   and BST-based finite map implementations
   ‣ e.g., C++: ordered map uses BST, unordered map uses hash
•  Key diﬀerence: BSTs store keys of comparable (using
   > and <) types
                         17
---
Integer Keys
•  For integer keys, we already know a data structure that
   provides constant time access: arrays/ArrayLists!
   ‣ If we know the index of the element in advance
• We will use this insight to build hashes
                            18
---
Integer Keys
•  Example problem: Given an integer in the range [1,12],
   return the name of the corresponding month.
                         19
---
Integer Keys
•  Example problem: Given an integer in the range [1,12],
   return the name of the corresponding month.
•  Solution: Use an array of size 12 that stores month
   names
   ‣ Key: month #, Value: month name
          1  2   3   4  5   6  7   8   9  10 11  12
         “Jan” “Feb” “Mar” “Apr” “May” “Jun”  “Jul”  “Aug” “Sep” “Oct” “Nov” “Dec”
   (could have 0 slot be empty, or could start from 0
    and subtract 1 from given key in order to index)
                             20
---
Integer Keys
•  Example problem: given an age, determine Tufts
   students who have that age.
•  Notice: Ages will fall in a certain range
   ‣  e.g., something like [16, 100]
   ‣  Keys can be integers in this range
•  Each key should be associated with a single value
   ‣  So, to represent a group of students, use a list
      Use: 20 ↦ {“Alice”, “Bob”, “Carol”}
      Not: 20 ↦ “Alice”, 20 ↦ “Bob”, 20 ↦ “Carol”
                         21
---
Integer Keys
•  Example problem: given an age, determine Tufts
   students who have that age.
•  Solution: Use an array where index corresponds to
   age, elements are lists of people of that age
   ‣  Key: age, Value: list of people of that age
          16    17   18   19   20   …     39  100
         {“Mo”, …} {“Bob”,  {…}  {…}  {…}  {…}  {…}
                      …}
           Strategy: Start at 0th index of array,
               subtract 16 from given keys
                             22
---
When can we get O(1) access?
•  When keys are integers in a reasonable range
   ‣  Integer keys serve as array index
   ‣  Reasonable range means a reasonable array size
             What  if keys are non-integers?
        e.g., keys are names, values are phone #’s
                           23
---
Non-Integer Keys
•  Non-integer keys must be converted into integers
• A hash function maps a key (whatever that is in your
   application) to an integer deterministically, i.e., it will
   always give the same answer for a given key.
   ‣ Hash functions should run in O(1) time
• There are good/bad choices for hash functions—but
   first let’s see an example
                          24
---
2-letter Word Dictionary
•  Map 2-letter words to definitions
   ‣  Keys: 2-letter words (strings)
   ‣  Values: Definitions (strings)
             “go” ↦ “leave, depart”
             “ox” ↦ “bovine frequently used in agriculture”
             “at” ↦ “in, on, or near”
             “hi” ↦ “a common greeting”
             …
What hash function can we use to map keys to ints?
                              25
---
  2-letter Word Dictionary
  •  How many possible 2-letter combinations are there?
     ‣  Answer: 26 * 26 = 676
  •  How to map 2-letter words to indices in range [0,676)?
     ‣  Answer: Treat each character as a base 26 number, then
        convert it to a base 10 number
a  b  c  d  e f  g  h i  j  k l  m  n  o  p  q  r  s   t  u  v  w  x  y  z
0  1  2  3  4 5  6  7 8  9 10 11 12 13 14 15 16 17 18  19 20 21 22 23 24 25
                  hash(ɑβ)     = 26¹*ɑ     +  26⁰*β
          e.g., hash(ox)      =  26*14    + 1*23       = 387
                                   26
---
2-letter Word Dictionary
•  With an array of size 676 and our hash function, we can
   have O(1) access to any 2-letter word’s definition!
•  Let’s see a simple implementation: dict.cpp
                          27
---
Hashes
•  The 2-letter dictionary is an example of the hash data
   structure
   ‣ Also called a hash table, hash map, …
•  Keys are run through a hash function that produces an
   integer
•  Integer used as index into an array/ArrayList, where
   values are stored
•  In a hash, the slots of the array/ArrayList are called
   buckets
   ‣ Or sometimes, just slots
                           28
---
      Problem
      •  Can we extend this hash function to work for all
         words?
              Word                       Letters
       Longest chemical name            189,819
            Longest word in a major        45
                   dictionary
   Supercalifragilisticexpialidocious      34        https://youtu.be/fHxO0UdpoxM
         Longest word in Shakespeare’s     27
                     works
Longest English Word:
https://en.wikipedia.org/wiki/Longest_word_in_English
                                         29
---
    Problem
    •  Can we extend this hash function to work for all
       words?
           Word                 Letters
     Longest chemical name      189,819
          Longest word in a major     45
                 dictionary
  Supercalifragilisticexpialidocious  34
       Longest word in Shakespeare’s  27
                   works
26³⁴ = 1285564381113498051199127603629788201662311038976
     Too big for an array size! Also, English has ~700k words,
     so we only need an extremely small fraction of this space.
                                30
---
Compression Function
•  Generally, a hash function produces an integer without
   regard for range
• We can use a compression function to put integer in a
   specific range [0..arraySize)
• Common choice for compression function: modulus
    int  bucketFor(KeyType key, int arraySize)
    {
         return hash(key) % arraySize;
    }
• x%y always returns an int in the range [0, y-1]
                       31
---
Example
•  Keys: Integers
•  Hash table size: 10                                    0
• hashBucket(key) = 2*key % 10                            1
•  Insert: 7, 18, 41, 35                                  2
                                                          3
                                                          4
                                                          5
                                                          6
                                                          7
                                                          8
                                                          9
                                   32
---
Example
•  Keys: Integers
•  Hash table size: 10                                    0
• hashBucket(key) = 2*key % 10                            1
•  Insert: 7, 18, 41, 35                                  2
                                                          3
                                                          4          7
                                                          5
                                                          6
                                                          7
                                                          8
                                                          9
                                   33
---
Example
•  Keys: Integers
•  Hash table size: 10                                    0
• hashBucket(key) = 2*key % 10                            1
•  Insert: 7, 18, 41, 35                                  2
                                                          3
                                                          4          7
                                                          5
                                                          6          18
                                                          7
                                                          8
                                                          9
                                   34
---
Example
•  Keys: Integers
•  Hash table size: 10                                    0
• hashBucket(key) = 2*key % 10                            1
•  Insert: 7, 18, 41, 35                                  2          41
                                                          3
                                                          4          7
                                                          5
                                                          6          18
                                                          7
                                                          8
                                                          9
                                   35
---
Example
•  Keys: Integers
•  Hash table size: 10                                    0          35
• hashBucket(key) = 2*key % 10                            1
•  Insert: 7, 18, 41, 35                                  2          41
                                                          3
•  What if we try to insert 13?                           4          7
                                                          5
                                                          6          18
                                                          7
                                                          8
                                                          9
                                   36
---
Example
•  Keys: Integers
•  Hash table size: 10                                    0          35
• hashBucket(key) = 2*key % 10                            1
•  Insert: 7, 18, 41, 35                                  2          41
                                                          3
•  What if we try to insert 13?                           4          7
                                                          5
                                                          6          18 13
                                                          7
                                                          8
                                                          9
                                   37
---
Problem: Collisions
•  Well-known challenge: What if two diﬀerent keys hash
   to the same bucket in an array?
   ‣  Either: the hash function produces the same output for two
      diﬀerent inputs, or the compression function does
•  This is called a collision
                           38
---
Problem: Collisions
•  Collisions are inevitable
• How should we handle them?
   ‣  Client wants to store/retrieve two diﬀerent (key, value) pairs, but
      hash/compression functions put them in the same bucket
                             39
---
Example
• How should we handle collisions?
                                                          0          35
                                                          1
                                                          2          41
                                                          3
                                                          4          7
                                                          5
                                                          6          18 13
                                                          7
                                                          8
                                                          9
                                   40
---
Approaches to Collisions
1.  To the extent possible: avoid them!
   •  Pick a good hash function (one that rarely produces collisions)
   •  Pick an appropriate table size
2.  Handle them when they arise
   •  Have a way to store, distinguish diﬀerent (key, value) pairs
                                41
---
Picking a Good Hash Function
•  Want to minimize collisions
•  What is the worst possible hash function?
•  Answer: one that returns a constant
   ‣ e.g., f(k) = 1
•  Best possible hash function: every input is mapped to
   a diﬀerent output, i.e., if x ≠ y then f(x) ≠ f(y)
   ‣  We saw one already: our two letter dictionary hash!
   ‣  This is called a perfect hash function
                            42
---
Picking a Good Hash Function
•  Example: Place Tufts student records into a hash,
   where the key is the student’s birthday?
•  A few choices for hash function:
    1.  Use the decade of their birth (20s, 10s, 00s, 90s, 80s…)
    2.  Use the month of their birth (Jan, Feb, March, …)
    3.  Use the day-of-month of their birth (1, 2, 3, …, 31)
         This choice would result in the fewest collisions
                                43
---
A good hash function is…
•  fast
•  deterministic
•  assigns diﬀerent keys to same buckets with extremely
   low probability
•  spreads out keys well (close keys get mapped to far
   apart values)
       Designing a good hash function uses
         complex math, beyond the scope
                   of this class.
          Luckily, most languages provide
              built-in hash functions!
                        44
---
SHA-256 Hash Function
•  A popular choice of hash function, especially in
   cryptography, is SHA-256. Here is a diagram:
                         45
---
Approaches to Collisions
1.  To the extent possible: avoid them!
   •  Pick good hash function (one that rarely produces collisions)
   •  Pick an appropriate table size (we’ll talk about this soon)
2.  Handle them when they arise
   •  Have a way to store, distinguish diﬀerent (key, value) pairs
                                46
---
Handling Collisions
• Two common approaches:
  1.  Chaining: put a list in each hash bucket
  2.  Open addressing: Use spare space in table (array)
      Note: In both of these cases, we will have
        to store keys and values together:
      struct KeyValue   {
          KeyType  key;
          ValueType value;
      };
        Otherwise, we would lose track of
         which key goes with which value.
                        47
---
   Chaining
   • Each bucket contains a list of key-value pairs
     ‣ List representation may vary (ArrayList, Linked List, …)
insert(key,  value)
    bucket =  hash(key)  % table_size
    if (key  is in  table[bucket])
        find  key-value  object in list, update value
    else
        add  key-value object to list
   find/lookup and remove are similar
                           48
---
Chaining Exercise
Draw a hash table and add the following key value-pairs,
in order, using the chaining strategy: (“a”, 400), (“cat”, 10),
(“aardvark”, 30), (“bag”, 50), (“drum”, 99), (“car”, 0).
Use the first letter of the word as its hash, i.e.,
hash(word)=word[0]-‘a’
       Note: This is a really bad hash function!
    We’re only using it to demonstrate chaining.
                         49
---
Chaining Exercise
Draw a hash table and add the following key value-pairs,
in order, using the chaining strategy: (“a”, 400), (“cat”, 10),
(“aardvark”, 30), (“bag”, 50), (“drum”, 99), (“car”, 0).
Use the   first letter of the word as its hash, i.e.,
hash(word)=word[0]-‘a’
                 ‘a'    ‘b’   ‘c’    ‘d’
                  0      1     2      3      …
                  { }    { }    { }   { }
                                 50
---
Chaining Exercise
Draw a hash table and add the following key value-pairs,
in order, using the chaining strategy: (“a”, 400), (“cat”, 10),
(“aardvark”, 30), (“bag”, 50), (“drum”, 99), (“car”, 0).
Use the   first letter of the word as its hash, i.e.,
hash(word)=word[0]-‘a’
                 ‘a'    ‘b’   ‘c’    ‘d’
                  0      1     2      3      …
           {(“a”, 400)}  { }    { }   { }
                                 51
---
Chaining Exercise
Draw a hash table and add the following key value-pairs,
in order, using the chaining strategy: (“a”, 400), (“cat”, 10),
(“aardvark”, 30), (“bag”, 50), (“drum”, 99), (“car”, 0).
Use the   first letter of the word as its hash, i.e.,
hash(word)=word[0]-‘a’
                 ‘a'    ‘b’   ‘c’    ‘d’
                  0      1     2      3      …
           {(“a”, 400)}  { }  {(“cat”, 10)} { }
                                 52
---
  Chaining Exercise
  Draw a hash table and add the following key value-pairs,
  in order, using the chaining strategy: (“a”, 400), (“cat”, 10),
  (“aardvark”, 30), (“bag”, 50), (“drum”, 99), (“car”, 0).
  Use the   first letter of the word as its hash, i.e.,
  hash(word)=word[0]-‘a’
                   ‘a'    ‘b’   ‘c’    ‘d’
                    0      1     2      3      …
{(“a”, 400), (“aardvark”, 30)}  { }  {(“cat”, 10)} { }
                                   53
---
  Chaining Exercise
  Draw a hash table and add the following key value-pairs,
  in order, using the chaining strategy: (“a”, 400), (“cat”, 10),
  (“aardvark”, 30), (“bag”, 50), (“drum”, 99), (“car”, 0).
  Use the   first letter of the word as its hash, i.e.,
  hash(word)=word[0]-‘a’
                   ‘a'    ‘b’   ‘c’    ‘d’
                    0      1     2      3      …
{(“a”, 400), (“aardvark”, 30)}  {(“cat”, 10)} { }
                       {(“bag”, 50)}
                                   54
---
  Chaining Exercise
  Draw a hash table and add the following key value-pairs,
  in order, using the chaining strategy: (“a”, 400), (“cat”, 10),
  (“aardvark”, 30), (“bag”, 50), (“drum”, 99), (“car”, 0).
  Use the   first letter of the word as its hash, i.e.,
  hash(word)=word[0]-‘a’
                   ‘a'    ‘b’   ‘c’    ‘d’
                    0      1     2      3      …
{(“a”, 400), (“aardvark”, 30)}  {(“cat”, 10)}  {(“drum”, 99)}
                       {(“bag”, 50)}
                                   55
---
  Chaining Exercise
  Draw a hash table and add the following key value-pairs,
  in order, using the chaining strategy: (“a”, 400), (“cat”, 10),
  (“aardvark”, 30), (“bag”, 50), (“drum”, 99), (“car”, 0).
  Use the   first letter of the word as its hash, i.e.,
  hash(word)=word[0]-‘a’
                   ‘a'    ‘b’   ‘c’    ‘d’
                    0      1     2      3      …
{(“a”, 400), (“aardvark”, 30)}  {(“cat”, 10), {(“drum”, 99)}
                               (“car”, 0)}
                       {(“bag”, 50)}
                                   56
---
   Chaining Exercise
   Say we want to retrieve a value, e.g.,                    find(“car”).
      ‣  Compute bucket number: 2
      ‣  Iterate over all elements in list, compare keys with “car”
      ‣  If we find the key “car”, return associated value
                        ‘a'      ‘b’     ‘c’     ‘d’
                         0        1       2       3        …
{(“a”, 400), (“aardvark”, 30)}        {(“cat”, 10),  {(“drum”, 99)}
                                        (“car”, 0)}
                            {(“bag”, 50)}
                                           57
---
Chaining: Time Complexity
•  What is the worst case complexity for accessing
   elements?
• Answer: O(n)
   ‣  This happens for a really bad hash function, or small table size
   ‣  e.g., say hash function is f(x) = 1. Eﬀectively, the hash is a list!
•  But with a good hash function and an appropriate
   table size, average case is O(1)!
   ‣  For a hash with n elements, and an appropriate table size,
      average number of collisions is still a constant
•  In practice, hashes are very fast
   ‣  Typically faster than BSTs
                            58
---
Handling Collisions
• Two common approaches:
    1.  Chaining: put a list in each hash bucket
    2.  Open addressing: Use spare space in table (array)
                                 59
---
Open Addressing
•  High-level idea: When a collision arises, use spare
   space in the hash table
•  We’ll look at three approaches:
   ‣ Linear probing
   ‣ Quadratic probing
   ‣ Double hashing
                          60
---
Linear Probing
•  Table must have some extra space to use this approach
• insert(key, value): if bucketFor(key) is filled,
   move right and use first unfilled bucket
   ‣  Wrap around when reaching end of array
•  Note: we need a way to tell if some memory is taken
   ‣  No inherent way to do this! There is always something in memory
•  Use a struct with a filled field:
            struct   Bucket   {
                 bool filled;
                 KeyValue key_val_pair;
            };
                          61
---
Example: Linear Probing
   ‘a'    ‘b’    ‘c’     ‘d’    ‘e’    ‘f’    ‘g’    ‘h’
       Let’s use our (bad) hash function again:
                take first letter of word
                            62
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’         ‘e’        ‘f’        ‘g’        ‘h’
                                  Insert (“a”, 400)
                                              63
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’         ‘e’        ‘f’        ‘g’        ‘h’
   (“a”, 400)
                                  Insert (“a”, 400)
                                              64
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’         ‘e’        ‘f’        ‘g’        ‘h’
   (“a”, 400)
                                 Insert (“cat”, 10)
                                              65
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’         ‘e’        ‘f’        ‘g’        ‘h’
   (“a”, 400)            (“cat”, 10)
                                 Insert (“cat”, 10)
                                              66
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’         ‘e’        ‘f’        ‘g’        ‘h’
   (“a”, 400)            (“cat”, 10)
                            Insert (“aardvark”, 30)
                                              67
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’          ‘e’         ‘f’        ‘g’         ‘h’
  (“a”, 400) (“aardvark”,  (“cat”, 10)
                 30)
                             Insert (“aardvark”, 30)
                                               68
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’          ‘e’         ‘f’        ‘g’         ‘h’
  (“a”, 400) (“aardvark”,  (“cat”, 10)
                 30)
                                 Insert (“bag”, 50)
                                               69
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’          ‘e’         ‘f’        ‘g’         ‘h’
  (“a”, 400) (“aardvark”,  (“cat”, 10)  (“bag”, 50)
                 30)
                                 Insert (“bag”, 50)
                                               70
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’          ‘e’         ‘f’        ‘g’         ‘h’
  (“a”, 400) (“aardvark”,  (“cat”, 10)  (“bag”, 50)
                 30)
                                Insert (“drum”, 99)
                                               71
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’          ‘e’         ‘f’        ‘g’         ‘h’
  (“a”, 400) (“aardvark”,  (“cat”, 10)  (“bag”, 50) (“drum”, 99)
                 30)
                                Insert (“drum”, 99)
                                               72
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’          ‘e’         ‘f’        ‘g’         ‘h’
  (“a”, 400) (“aardvark”,  (“cat”, 10)  (“bag”, 50) (“drum”, 99)
                 30)
                                   Insert (“car”, 0)
                                               73
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’          ‘e’         ‘f’        ‘g’         ‘h’
  (“a”, 400) (“aardvark”,  (“cat”, 10)  (“bag”, 50) (“drum”, 99)  (“car”, 0)
                 30)
                                   Insert (“car”, 0)
                                               74
---
Example: Linear Probing
   ‘a'     ‘b’     ‘c’     ‘d’     ‘e’     ‘f’    ‘g’     ‘h’
  (“a”, 400) (“aardvark”,  (“cat”, 10)  (“bag”, 50) (“drum”, 99)  (“car”, 0)
                 30)
                      Find (“aardvark”)
                           -Go to ‘a’ bucket
                           -Move right until we find “aardvark”
                            or until we hit unfilled bucket
                      return: 30
                               75
---
Example: Linear Probing
   ‘a'     ‘b’     ‘c’     ‘d’     ‘e’     ‘f’    ‘g’     ‘h’
  (“a”, 400) (“aardvark”,  (“cat”, 10)  (“bag”, 50) (“drum”, 99)  (“car”, 0)
                 30)
                         Find (“ball”)
                            -Go to ‘b’
                            -Move right until we find “ball” or
                             until we hit unfilled bucket
                   No key “ball” in table!
                               76
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’         ‘e’        ‘f’        ‘g’        ‘h’
   (“a”, 400) (“aardvark”,  (“cat”, 10)  (“bag”, 50) (“drum”, 99)  (“car”, 0)
                  30)
                                   Remove(“cat”)
                                      -Go to ‘c’
                                      -Move right until we find “cat”
                                              77
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’         ‘e’        ‘f’        ‘g’        ‘h’
   (“a”, 400) (“aardvark”,           (“bag”, 50) (“drum”, 99)  (“car”, 0)
                  30)
                                   Remove(“cat”)
                                      -Go to ‘c’
                                      -Move right until we find “cat”
                                              78
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’         ‘e’        ‘f’        ‘g’        ‘h’
   (“a”, 400) (“aardvark”,           (“bag”, 50) (“drum”, 99)  (“car”, 0)
                  30)
                                     Find (“bag”)
                                         -Go to ‘b’
                                         -How far do we move right?
                                              79
---
Example: Linear Probing
     ‘a'        ‘b’        ‘c’         ‘d’         ‘e’        ‘f’       ‘g’        ‘h’
   (“a”, 400) (“aardvark”,          (“bag”, 50) (“drum”, 99)  (“car”, 0)
                  30)
•   When we removed “cat” we left an unfilled spot
•   When searching for “bag” if we stop searching at this
    unfilled spot, we won’t                find the key “bag”
•   But if we don’t stop at unfilled spots, we have to search
    every bucket in the hash if a key doesn’t exist!
How do we resolve this?
                                             80
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’         ‘e’        ‘f’        ‘g’        ‘h’
   (“a”, 400) (“aardvark”,           (“bag”, 50) (“drum”, 99)  (“car”, 0)
                  30)
A bucket can be in one of three states:
    ‣   Filled
    ‣ Unfilled, and never was filled
    ‣ Unfilled, but previously had data that was removed
                                              81
---
    Example: Linear Probing
       ‘a'   ‘b’    ‘c’    ‘d’    ‘e’   ‘f’   ‘g’    ‘h’
     (“a”, 400) (“aardvark”,  (“bag”, 50) (“drum”, 99)  (“car”, 0)
                    30)
    Let’s add a removed field to our Bucket struct:
                struct   Bucket   {
                     bool filled;
                     bool removed;
                     KeyValue key_val_pair;
                };
true when unfilled and
 value was removed,
   false otherwise            82
---
Example: Linear Probing
     ‘a'         ‘b’        ‘c’         ‘d’         ‘e’        ‘f’        ‘g’        ‘h’
   (“a”, 400)  (“aardvark”,          (“bag”, 50) (“drum”, 99)  (“car”, 0)
                 30)
                   removed = true
               (false every where else)
                                              83
---
Example: Linear Probing
   ‘a'     ‘b’    ‘c’     ‘d’     ‘e’    ‘f’     ‘g’    ‘h’
 (“a”, 400) (“aardvark”,  (“bag”, 50) (“drum”, 99)  (“car”, 0)
                30)
            removed = true
                 Find (“bag”)
                    -Go to “b”
                    -Move right until we find “bag” or until
                      we hit a non-filled, non-removed bucket
                found in bucket ‘d’!
                return: 50
                              84
---
 Example: Linear Probing
     ‘a'      ‘b’     ‘c’      ‘d’      ‘e’     ‘f’      ‘g’     ‘h’
   (“a”, 400) (“aardvark”,   (“bag”, 50) (“drum”, 99)  (“car”, 0)
                  30)
               removed = true
Insertion                               Update/Find/Remove
‣Move right until first                   ‣Move right until first
  unfilled bucket                           unremoved bucket
                                   85
---
Linear Probing
•  Notice: This is why a good hash function “spreads out”
   outputs
•  If the hash function mapped similar inputs to similar
   outputs, we would often get clusters. Bad for probing!
   ‣ Clusters mean we need to traverse more buckets
                          86
---
Quadratic Probing
•  Very similar to linear probing
•  Key diﬀerence: which bucket to look at next
•  Starting with attempt=0:
bucket to      use = bucketFor(key)   + attempt²
        e.g.,  if bucketFor(key) is 5,
        we try the buckets:
        5
        6
        9
        14
        21
        …(wrapping around when needed)
                        87
---
Quadratic Probing
•  Very similar to linear probing
•  Key diﬀerence: which bucket to look at next
•  Starting with attempt=0:
bucket to   use = bucketFor(key)      + attempt²
              Key benefit: as we get
               collisions, we move
                farther away. This
              spreads out elements,
               generally decreases
                   clustering.
                        88
---
Double Hashing
•  Use one hash function the first time
•  If you get a collision, use a second hash function
•  Still, must have a diﬀerent strategy if you get another
   collision
•  But generally, works well in practice!
                           89
---
Time Complexity
• We already saw the worst case complexity when using
   chaining: O(n)
• What is the worst case complexity when using open
   addressing?
•  For insertion: O(n)
   ‣  Worst case: traverse all elements until finding unfilled bucket
•  For lookup (update/find/removal): O(table_size)
   ‣  Worst case: need to search over all buckets in hash
•  Worst case occurs when collisions are frequent
      And yet, hashes promise O(1) on average…
                           90
---
When can we get O(1)?
•  Two important ingredients:
   ‣  Need a good hash function: elements should be spread out,
      evenly distributed across buckets
   ‣  Need an appropriate table size: a larger table reduces
      probability of collisions. Time vs. space tradeoﬀ!
                              91
---
   Load Factor
              load factor = # elements in table
                               # buckets in table
   • A measure of how full the table is
           What is the load factor of this table that
                         uses chaining?
                 ‘a'    ‘b’   ‘c’   ‘d’           ‘z’
                  0      1     2     3      …     25
{(“a”, 400), (“aardvark”, 30)}  {(“cat”, 10), {(“drum”, 99)}
                             (“car”, 0)}
                     {(“bag”, 50)}  92
---
   Load Factor
               load factor = # elements in table
                                # buckets in table
   • A measure of how full the table is
                    load factor = 6/26 ≈ 0.23
                  ‘a'    ‘b’   ‘c’   ‘d’            ‘z’
                   0      1     2     3      …      25
{(“a”, 400), (“aardvark”, 30)}  {(“cat”, 10), {(“drum”, 99)}
                              (“car”, 0)}
                      {(“bag”, 50)}  93
---
Load Factor
           load factor = # elements in table
                           # buckets in table
•  A measure of how full the table is
        What is the load factor of this table that
                 uses open addressing?
   ‘a'     ‘b’    ‘c’    ‘d’     ‘e’    ‘f’    ‘g’    ‘h’
  (“a”, 400) (“aardvark”,  (“bag”, 50) (“drum”, 99)  (“car”, 0)
                 30)
                             94
---
Load Factor
           load factor = # elements in table
                            # buckets in table
• A measure of how full the table is
                 load factor = 5/8 = 0.625
   ‘a'     ‘b’    ‘c’     ‘d’     ‘e’    ‘f’     ‘g’    ‘h’
 (“a”, 400) (“aardvark”,  (“bag”, 50) (“drum”, 99)  (“car”, 0)
                30)
                              95
---
Load Factor
         load factor = # elements in table
                       # buckets in table
• What is the maximum load factor when using open
  addressing?
                        96
---
Load Factor
         load factor = # elements in table
                       # buckets in table
• What is the maximum load factor when using open
  addressing?
• Answer: anything up to (but not including) 1
  ‣ Need open buckets to put new elements
                         97
---
Load Factor
         load factor = # elements in table
                       # buckets in table
• What is the maximum load factor when using
  chaining?
                         98
---
Load Factor
         load factor = # elements in table
                       # buckets in table
• What is the maximum load factor when using
   chaining?
•  Answer: In theory, there’s no limit!
   ‣ Just keep adding new elements to bucket lists
   ‣ But performance gets worse as load factor gets higher
                         99
---
Load Factor
•  A low load factor and a good hash function mean
   excellent performance: O(1) for all hash operations!
•  What is a good load factor?
•  Answer: systems typically keep load factor under
   around 0.7 to 0.75
   ‣  Determined empirically: experimentation shows performance
      takes a noticeable hit beyond this number
                          100
---
Load Factor
• What should we do when we hit our maximum load
   factor?
•  Answer: Increase the # of buckets!
   ‣ Similar to expansion of ArrayLists
• When we expand a hash, can we simply put elements
   back in the same buckets (like ArrayLists)?
       No! An element’s bucket # may change
             with a different table size
                        101
---
Expanding Hashes
•  bucketFor(key) = hash(key) % table_size
•  Example: Say hash(key) = 19, original table_size = 10
                                                   (k, v)
     0    1     2    3    4    5    6     7    8    9
•  Then, we double the size of the table (table_size = 20)
             Where should the key go now?
                            102
---
Expanding Hashes
•  bucketFor(key) = hash(key) % table_size
•  Example: Say hash(key) = 19, original table_size = 10
                                                   (k, v)
     0    1     2    3    4    5    6     7    8    9
•  Then, we double the size of the table (table_size = 20)
                                                            (k,v)
                                                            19
                   Answer: bucket 19
                            103
---
Rehashing
• When expanding a hash, all elements must be
  rehashed: the bucket # for each element is computed
  for the new table size
• This ensures we can find them later when we look up a
  key
                        104
---
Implementing Hashes
•  A lot like implementing ArrayLists!
•  Key diﬀerences with a hash:
   ‣  Given a key, must run it through a hash + compression function
      to compute array slot
   ‣  Must account for collisions (using chaining, probing, …)
   ‣  Expand when hitting max load factor (not max capacity)
   ‣  Rehash when expanding (instead of placing in same slot)
                              105
---
Can collisions be avoided?
•  What if we just make the table size very large?
   ‣ i.e., make the load factor very small
•  Say we are hashing random values into a table of size 1
   million. If the hash function outputs are uniformly
   distributed, about how many values do you think we
   will insert before we see a collision?
   ‣ Let’s try it out: collision_tester.cpp
                            106
---
Birthday Paradox
•  In all likelihood, there will always be collisions
•  Birthday paradox: In a group of 23 people, there is a
   greater than 50% chance that 2 people share a birthday
   ‣ For 70 people, there is a 99.9% chance
•  When hashing 2,450 values into a table of 1 million
   buckets, with a perfectly uniform distribution, there is a
   95% chance of a collision occurring
   ‣ Load factor = 0.00245
            There will always be collisions!
            Handle them well, and average
                performance is still O(1).
                            107
---
Some Notes on Hashes…
•  A hash’s keys must be immutable
   ‣ immutable == unchangeable
•  e.g., say keys are names. Later, someone changes their
   name. When we look up the new name in the hash
   table, we won’t find it!
                         108
---
Some Notes on Hashes…
•  Hashes give very good performance for insertion,
   removal, and look up. What operations are they bad at?
•  Operations that involve comparisons, e.g., findMin and
   findMax
   ‣ Better to use a heap or BST when comparisons are important
•  Operations that involve linear ordering, or front/back
   insertion
   ‣  Hashes have no notion of “order”
   ‣  Better to use stacks, queues, lists…
                            109
---
Some Notes on Hashes…
•  Outside of these cases, hashes are often the go-to
   choice when storage, retrieval is important
                          110
---
Practice Questions
1.   A majority element is an element that appears more than n/2
     times in a list of size n. Given a list of positive integers, write the
     pseudocode for the following function, which returns the
     majority element if one exists, or -1 otherwise.
int majority_element(IntList list)
2.  Given an integer list and target integer, write the pseudocode for
    the following function, which returns true when the array
    contains a pair of elements that sum to the given target, and
    false otherwise.
bool  pair_sum(IntList     list,  int  target)
             Both operations should run in O(n) time.
 You may assume you have a hasKey(k) operation available to you.
                            111
---
Practice Question #1
int majority_element(IntList list):
 Hash<int, int> counts;
 for  (int i = 0; i < list.size(); i++) {
    if counts.hasKey(list[i]):
        counts[list[i]] = counts[list[i]] + 1;
        if(counts[list[i]] > list.size()/2):
            return list[i];
    else:
        counts[list[i]] = 1;
 }
 return  -1;
                        112
---
Practice Question #2
bool pair_sum(IntList list, int target)
 //  Value could be  anything. Just using the hash to
 //  keep track of which ints we’ve seen. Could  also
 //  use a  hash-based Set.
 Hash<int, bool>     seen_ints;
 for  (int  i  = 0;  i < list.size(); i++) {
    if seen_ints.hasKey(target - list[i]):
      return   true;
    else:
      seen_ints[list[i]] = true;
 return  false;
                        113
---
        CS 15: Data Structures
Compression with the Huffman Coding Algorithm
---
Compression
• Compression is the process of reducing the number
  of bits needed to represent some data.
  ‣ A bit is a binary digit (i.e., 0 or 1)
• We use compression to:
  ‣  Reduce space needed to store data
  ‣  Increase speed of data transfers
    - Compress data, send it, then decompress
                         2
---
Data Transmission
Compression is vital to so much that we do online!
                        Streaming video, audio
                        Browsing websites
              Google, 2017: 53% of mobile site visitors leave a
              page that takes longer than three seconds to load
                         Video calling
                          3
---
Update Your Toolkit
  Compression is a useful tool to have in your toolkit!
                            4
---
Lossy vs. Lossless
                5
---
Lossy vs. Lossless
• Compression can either be lossy or lossless
                        5
---
Lossy vs. Lossless
• Compression can either be lossy or lossless
• Lossy: information is sacrificed to reduce data size
                         5
---
Lossy vs. Lossless
• Compression can either be lossy or lossless
•  Lossy: information is sacrificed to reduce data size
   ‣  Examples: MP3 for audio, JPEG for pictures, MPEG for video
   ‣  Acceptable reductions made in quality
                          5
---
Lossy vs. Lossless
•  Lossless: compresses data without sacrificing any
   information
   ‣  Typically exploits redundancy in data
   ‣  Focus of today’s lecture
                             6
---
Encoding
• Encoding is the process of converting data of one
  format into another format
   Example: Computers encode all data as binary numbers.
            How should strings be converted to 0s and 1s?
     “abracadabra”       ???
                          7
---
ASCII Encodings
• One well known encoding format is the American
   Standard Code for Information Interchange (ASCII)
   ‣  Developed in the 1960s
   ‣  Encodes 128 characters using 7 bits/character
   ‣  Modern ASCII: 8 bits/char
•  Still used today
   ‣  But newer encoding standards, like Unicode, can encode
      many more symbols
      - e.g., emojis, characters from different languages
                             8
---
ASCII Encodings
                            CHAR      BINARY
                           [space]    010 0000
                              !       010 0001
                              “       010 0010
                              …
                              0       011 0000
                              1       011 0001
                              2       011 0010
                              …
                              A       100 0001
                              B       100 0010
                              C       100 0011
                              …
                              a       110 0001
                              b       110 0010
                              c       110 0011
                              …
                                   9
---
Encoding With ASCII
• Encoding  with ASCII  is easy:  just look up  the
  encoding for each character
                   “abracadabra”
    1100001110001011100101100001
    1100011110000111001001100001
         110001011100101100001
                         10
---
Decoding With ASCII
•  Break binary encoding into 7 bit pieces, look up the
   character corresponding to that encoding
     1100001110001011100101100001
           a           b           r           a
     1100011110000111001001100001
           c           a           d           a
            110001011100101100001
                 b           r           a
                            11
---
Code Trees
We can use binary trees to represent encodings!
     Code trees:
     1.  Let some tree nodes represent characters
     2.  A character’s encoding is determined by following
         the path from the root to that character’s node
          ‣  Taking a “left turn” is read as bit ‘0’
          ‣  Taking a “right turn” is read as bit ‘1’
                                 12
---
Example: Code Tree
For example, say we have the following encodings:
                                                            a       00
Let’s build a code tree.
                                                            b       01
                                                            c       10
                                                            d       11
                                   13
---
    Example: Code Tree
    For example, say we have the following encodings:
                                                            a      00
    a’s encoding: 00
       ‣  From the root: two leftward traversals            b      01
                                                            c      10
                  0                                         d      11
      0
a
                                     14
---
    Example: Code Tree
    For example, say we have the following encodings:
                                                            a      00
    b’s encoding: 01
       ‣  From the root: left, right                        b      01
                                                            c      10
                  0                                         d      11
      0          1
a                    b
                                     15
---
    Example: Code Tree
    For example, say we have the following encodings:
                                                            a      00
    c’s encoding: 10
       ‣  From the root: right, left                        b      01
                                                            c      10
                  0            1                            d      11
      0          1              0
a                    b      c
                                     16
---
    Example: Code Tree
    For example, say we have the following encodings:
                                                            a      00
    d’s encoding: 11
       ‣  From the root: right, right                       b      01
                                                            c      10
                  0            1                            d      11
      0          1              0          1
a                    b      c                   d
                                     17
---
    Example: Code Tree
                                                            a      00
                                                            b      01
                                                            c      10
a                    b      c                   d           d      11
      We’ll see why these are useful soon!
                                     18
---
Smaller Encodings
      We used 77 bits to encode “abracadabra”.
                Can we do better?
•  Observation #1: We don’t need 7 bits/character
   ‣  ASCII uses 7 bits to represent 128 characters (2⁷ = 128)
   ‣  But we are only using 5 characters!
                         19
---
Smaller Encodings
      We used 77 bits to encode “abracadabra”.
                 Can we do better?
•  Observation #1: We don’t need 7 bits/character
   ‣  ASCII uses 7 bits to represent 128 characters (2⁷ = 128)
   ‣  But we are only using 5 characters!
                         2¹ = 2
                         2² = 4
                         2³ = 8
                         …
                          19
---
Smaller Encodings
• Idea: We could use just 3 bits/character
                             a      000
                             b      001
                             r      010
                             d      011
                             c      100
• Now, we can encode “abracadabra” with 33 bits!
   ‣ Important caveat: decoder must have access to encoding table
                                 20
---
Varying Frequencies
                  Can we do even better?
•  Observation #2: Characters occur at different frequencies
                                          char count
                                            a    5
           “abracadabra”                    b    2
                                            r    2
                                            c    1
                                            d    1
                                 21
---
Varying Frequencies in English
Character counts in Shakespeare’s Romeo and Juliet:
        12,963
              9,833  8,925
                          …   65    34
         e     t     o        q      z
                         22
---
Variable-Length Codes
   Idea: Do we really need to encode all characters
            with the same number of bits?
    ‣ That is, do we need to use a fixed-length encoding?
                           23
---
Variable-Length Codes
   Idea: Do we really need to encode all characters
            with the same number of bits?
    ‣ That is, do we need to use a fixed-length encoding?
  Answer: No! We can use variable-length code
     ‣  Fewer bits for frequently used characters
     ‣  More bits for less frequently used characters
          This is how we achieve compression with
                the Huffman coding algorithm
                            23
---
Early Example: Morse Code
• Developed for communication using the telegraph
   ‣  Encoding uses two symbols: dots and dashes
   ‣  Respectively represent short and long tone pulses
                            24
---
  Early Example: Morse Code
  • Developed for communication using the telegraph
    ‣  Encoding uses two symbols: dots and dashes
    ‣  Respectively represent short and long tone pulses
Frequently used
characters have
 shorter codes
                                24
---
Attempt #1
•  Recall the character frequencies in “abracadabra”:
   ‣  a: 5 times
   ‣  b: 2 times
   ‣  r: 2 times
   ‣  c: 1 time
   ‣  d: 1 time
                            25
---
Attempt #1
•  Recall the character frequencies in “abracadabra”:
   ‣  a: 5 times
   ‣  b: 2 times                                a       0
   ‣  r: 2 times                                b       1
   ‣  c: 1 time            Variable-Length      r      10
   ‣  d: 1 time                 Code:           d      11
                                                c     100
                                 25
---
Attempt #1: Encoding
• Encoding:
   ‣ Just look up the code for each character
                                                a       0
               “abracadabra”                    b       1
                                                r      10
             0110010001101100
                                                d      11
                                                c     100
                                 26
---
Attempt #1: Decoding
• Decoding:
              0110010001101100
                                                    a       0
                                                    b       1
                                                    r      10
                                                    d      11
                                                    c     100
                                   27
---
Attempt #1: Decoding
• Decoding:
             0110010001101100
                                               a       0
        Notice: We can’t split code into       b       1
          equal-sized chunks to decode         r      10
                                               d      11
                                               c     100
                                28
---
Attempt #1: Decoding
• Decoding:
            0110010001101100
                                            a       0
      Notice: We can’t split code into      b       1
        equal-sized chunks to decode        r      10
                                            d      11
                                            c     100
•  Let’s try reading bits one at a time, until we know
   what character we are decoding
                              29
---
Attempt #1: Decoding
• Decoding:
              0110010001101100
                                                    a       0
                                                    b       1
                                                    r      10
                                                    d      11
                                                    c     100
                                   30
---
   Attempt #1: Decoding
   • Decoding:
                0110010001101100
This is an “a”           a                         a       0
                                                   b       1
                                                   r      10
                                                   d      11
                                                   c     100
                                    31
---
Attempt #1: Decoding
• Decoding:
              0110010001101100
                                                   a       0
                        a
                                                   b       1
                                                   r      10
                                                   d      11
                                                   c      100
                                   32
---
Attempt #1: Decoding
• Decoding:
             0110010001101100
Is this a “b”?        a                         a       0
 Or the start                                   b       1
  of a “d”?
                                                r      10
                                                d      11
                                                c     100
                                 33
---
Attempt #1: Decoding
• Decoding:
             0110010001101100
Is this a “b”?        a                         a       0
 Or the start                                   b       1
  of a “d”?
                                                r      10
                                                d      11
                                                c     100
                                 33
---
Ambiguous Decoding
• This ambiguity occurs because some encodings
   form the prefix of other encodings
   ‣  e.g., b’s encoding “1” is the prefix of d’s encoding “11”
   ‣  When decoding “11”, do we decode to “b” or “d”?
                            34
---
Prefix-Free Code
• What we need is a prefix-free code
  ‣  An encoding system where no encoding      is the prefix of
     another encoding
                         a     0
                         b     10
                         r     110
                         d    1111
                         c    1110
                              35
---
Prefix-Free Code
• What we need is a prefix-free code
  ‣  An encoding system where no encoding      is the prefix of
     another encoding
                         a     0
                         b     10
                         r     110
                         d    1111
                         c    1110
                              35
---
Prefix-Free Code
• What we need is a prefix-free code
   ‣  An encoding system where no encoding    is the prefix of
      another encoding
                         a     0
                         b     10
                         r    110
                         d    1111
                         c    1110
          How do we come up with a prefix-free code?
                             35
---
Code Trees
Let’s express our faulty variable-length code as a tree.
                 0            1                           a       0
           a                       b                      b       1
                               0          1               r      10
                           r                   d          d      11
                        0                                 c     100
                      c
                                 36
---
Code Trees
Let’s express our faulty variable-length code as a tree.
                 0            1                           a       0
           a                       b                      b       1
                               0          1               r      10
                           r                   d          d      11
                        0                                 c     100
                      c
       Question: What property must be true of a code tree
                   to ensure it is prefix-free?
                                 36
---
Code Trees
Notice: a character ⍺’s code is a prefix of a character β’s
code when ⍺ occurs on the path from the root to β.
                 0            1                           a       0
           a                       b                      b       1
                               0          1               r      10
                           r                   d          d      11
                        0                                 c     100
                      c
                                 37
---
Prefix-Free Code Trees
• We want a code tree where no character occurs on
   the path from the root to any other character
•  i.e., a code tree where all characters are leaves!
                        38
---
Huffman Trees
•  We want a way to construct code trees where:
   ‣  The leaves correspond to characters
   ‣  More frequently occurring characters are closer to the root
•  Such a tree is called a Huffman tree
•  They are constructed using the Huffman coding
   algorithm
   ‣  Developed by David Huffman at MIT in 1952
      - Developed for his final paper for a course
                            39
---
Huffman Coding
• We construct a Huffman tree starting from the leaves,
   and building up to the root
   ‣ Want to start with lowest frequency characters at the bottom
•  This is called a bottom-up algorithm
                          40
---
Huffman Coding Algorithm
1.   Create a node for each character you want to encode. Each
     node should store two pieces of data:
    (1)  the character
    (2)  the count of the character’s uses
                                41
---
Huffman Coding Algorithm
1.   Create a node for each character you want to encode. Each
     node should store two pieces of data:             “abracadabra”
    (1)  the character                                   char count
    (2)  the count of the character’s uses                 a    5
                                                           b    2
                                                           r    2
                                                           c    1
                                                           d    1
  a  5         b  2        r  2        c  1         d  1
                                 42
---
Huffman Coding Algorithm
2.  Pick the two subtrees with the lowest counts, and join them
    with a parent node.
   ‣ Assign the parent node the sum of the counts of the children
  a  5         b 2         r  2        c  1        d  1
                                43
---
Huffman Coding Algorithm
2.  Pick the two subtrees with the lowest counts, and join them
    with a parent node.
   ‣ Assign the parent node the sum of the counts of the children
                     c  1        d  1
  a  5         b 2         r  2
                                44
---
Huffman Coding Algorithm
2.  Pick the two subtrees with the lowest counts, and join them
    with a parent node.
   ‣ Assign the parent node the sum of the counts of the children
                              2
                     c  1        d  1
  a  5         b 2         r  2
                                45
---
Huffman Coding Algorithm
3.  Return the new tree to the group.
                                                2
  a  5         b  2        r  2        c  1         d  1
                                 46
---
Huffman Coding Algorithm
4.  Repeat!
   ‣ Until a single tree remains.
                                                2
  a  5         b  2        r  2        c  1         d  1
                                 47
---
Huffman Coding Algorithm
                    Find two minimum subtrees
                     (break ties arbitrarily)
                                                2
  a  5         b  2        r  2        c  1         d  1
                                 48
---
Huffman Coding Algorithm
                    Find two minimum subtrees
                     (break ties arbitrarily)
               b  2        r  2                 2
  a  5                                 c  1         d  1
                                 49
---
Huffman Coding Algorithm
                   Join with parent that stores
                 the sum of the children’s counts
                        4
               b  2        r  2                 2
  a  5                                 c  1         d  1
                                 50
---
Huffman Coding Algorithm
                    Find two minimum subtrees
                       4                       2
  a  5        b  2         r 2         c 1         d 1
                                51
---
Huffman Coding Algorithm
                   Join with parent that stores
                 the sum of the children’s counts
                               6
                        4                       2
  a  5         b  2        r  2        c  1         d  1
                                 52
---
Huffman Coding Algorithm
                    Find two minimum subtrees
                               6
                        4                       2
  a  5         b  2        r  2        c  1         d  1
                                 53
---
Huffman Coding Algorithm
                          We’re done!
              11
                               6
                        4                       2
  a  5         b  2        r  2        c  1         d  1
                                 54
---
Huffman Coding Algorithm
                          Label with 0’s and 1’s to get
                           encodings for all characters
              11
                      1                                    a      0
                               6                           b     100
        0               0              1                   r     101
                                                           d     111
                        4                       2          c     110
                   0      1                0       1
  a  5         b  2        r  2        c  1         d  1
                                 55
---
Building Huffman Trees: Recap
1.  Store each character and its count in its own node.
2.  Until a single tree remains:
   ‣  Find two subtrees with minimum counts
      - Use a min-heap for best performance (we’ll learn about these soon)
   ‣  Join subtrees with a parent node that stores sum of counts
                            56
---
  Building Huffman Trees: Recap
✓ Resulting encoding is preᶠⁱˣ⁻ᶠʳᵉᵉ
   -  All characters are at the leaves
✓ Frequently occurring characters have shorter codes
   -  We build from the bottom up, starting with infrequent characters
                           57
---
Encoding
• Encoding:                                                 a      0
   ‣ Just look up the encoding for each character           b     100
                                                            r     101
              “abracadabra”                                 d     111
       01001010110011101001010                              c     110
                                 58
---
Encoding
• Encoding:                                                 a      0
   ‣ Just look up the encoding for each character           b     100
                                                            r     101
              “abracadabra”                                 d     111
       01001010110011101001010                              c     110
 Encoding uses just 23 bits!
    -  3-bit fixed-length code used 33 bits
    -  ASCII used 77 bits
                                 58
---
Decoding
• Decoding:
  ‣  Uses Huffman tree
  ‣  Read bits one at a time
     -  Go to left child on tree for 0, right child on tree for 1
     -  When we encounter a leaf node, print the corresponding character
     -  Repeat, starting from the root
                              59
---
      Decoding
   Code:    01001010110011101001010
Decoded:
                        11
                                1
                                          6
                  0               0               1
                                  4                        2
                             0       1                0       1
             a  5        b  2         r 2         c  1        d  1
                                       60
---
      Decoding
   Code:    01001010110011101001010
Decoded: a
                        11
                                1
                                          6
                  0               0               1
                                  4                        2
                             0       1                0       1
             a  5        b  2         r 2         c  1        d  1
                                       61
---
      Decoding
   Code:    01001010110011101001010
Decoded: a
                        11
                                1
                                          6
                  0               0               1
                                  4                        2
                             0       1                0       1
             a  5        b  2         r 2         c  1        d  1
                                       62
---
      Decoding
   Code:    01001010110011101001010
Decoded: a
                        11
                                1
                                          6
                  0               0               1
                                  4                        2
                             0       1                0       1
             a  5        b  2         r 2         c  1        d  1
                                       63
---
      Decoding
   Code:    01001010110011101001010
Decoded: a
                        11
                                1
                                          6
                  0               0               1
                                  4                        2
                             0       1                0       1
             a  5        b  2         r 2         c  1        d  1
                                       64
---
      Decoding
   Code:    01001010110011101001010
Decoded: ab
                        11
                                1
                                          6
                  0               0               1
                                  4                        2
                             0       1                0       1
             a  5        b  2         r 2         c  1        d  1
                                       65
---
      Decoding
   Code:    01001010110011101001010
Decoded: ab
                        11
                                1
                                          6
                  0               0               1
                                  4                        2
                             0       1                0       1
             a  5        b  2         r 2         c  1        d  1
                                       66
---
      Decoding
   Code:    01001010110011101001010
Decoded: ab
                        11
                                1
                                          6
                  0               0               1
                                  4                        2
                             0       1                0       1
             a  5        b  2         r 2         c  1        d  1
                                       67
---
      Decoding
   Code:    01001010110011101001010
Decoded: ab
                        11
                                1
                                          6
                  0               0               1
                                  4                        2
                             0       1                0       1
             a  5        b  2         r 2         c  1        d  1
                                       68
---
      Decoding
   Code:    01001010110011101001010
Decoded: abr
                                      and so on…
                        11
                                1
                                          6
                  0               0               1
                                  4                        2
                             0       1                0       1
             a  5        b  2         r 2         c  1        d  1
                                       69
---
Huffman Coding Properties
               70
---
Huffman Coding Properties
•  Huffman compression is optimal among algorithms that:
   ‣  produce single-symbol encodings
   ‣  assume a known character frequency distribution
                          70
---
Huffman Coding Properties
•  Huffman compression is optimal among algorithms that:
   ‣  produce single-symbol encodings
   ‣  assume a known character frequency distribution
•  Note: decoder must have Huffman tree as well
   ‣  This occupies space alongside the encoded data
   ‣  Typically not a problem as encoded data grows larger
                            70
---
Practice Questions
• Get the exercise:
   ‣  https://docs.google.com/document/d/
      1RcI3r8uFA1w02kY5NJ_RVS_BId6_gUcGPmqxoESs6gQ/
      edit?usp=sharing
                            71
---
Practice Solutions
1 (a).                     Char Encoding
                            b
                            e
                            k
                            p
                            r
                            s
                            SP
1 (b).
2.
                                 72
---
Practice Solutions
1 (a).                       Char  Encoding
                              b      001
                              e       1
                              k      0100
                              p      0101
                              r      0110
                              s      0111
                              SP     000
1 (b).
2.
                                   73
---
Practice Solutions
1 (a).                       Char Encoding
                              b      001
                              e       1
                              k     0100
                              p     0101
                              r     0110
                              s     0111
                              SP    000
1 (b). 010110101010110110
          p   e   p      p   e   r
2.
                                   74
---
Practice Solutions
1 (a).                       Char Encoding
                              b      001
                              e       1
                              k     0100
                              p     0101
                              r     0110
                              s     0111
                              SP    000
1 (b). 010110101010110110
          p   e   p      p   e   r
2. beekeepers keep bees
                                   75
---
Recap
• We covered:
  ‣  Compression: reducing the size of data representation
     -  Lossy: sacrificing data to reduce size
     -  Lossless: reducing size without sacrificing data
  ‣  Encoding systems like ASCII, which convert data of one format
     to data of another format
  ‣  Variable-length codes: encodings of different sizes per symbol
  ‣  Prefix-free codes: ambiguity-free variable-length codes
  ‣ Huᶠᶠᵐᵃⁿ coding: an algorithm for developing prefix-free codes
     for use in compression
                             76
---
CS 15: Data Structures
      Welcome!
---
Some Logistics
Instructor: Milod Kazerounian (he/him)
   ‣  pronunciation: “mee-lah-d”
Email: milod.kazerounian@tufts.edu
   ‣  But use Piazza
Oﬃce Hours:
   ‣   Tuesdays 1-2pm in JCC 469
   ‣   Thursday 2-3pm: https://tufts.zoom.us/my/milod
Course Website: www.cs.tufts.edu/comp/15
   ‣   Contains all HWs, labs, slides, and more
                             2
---
Your TAs
•  They are incredible, and they’re here to help!
• Oﬃce hours:
   ‣ Begin on Wednesday, January 22
   ‣  Take place in JCC 3rd floor common area next to elevators
   ‣  Details will be posted on Piazza
                          3
---
Lecture Recordings
                   •  All lectures are being recorded!
                   •  Recordings only shared with
                      enrolled students
                   • You can find them on Canvas,
                      under “Echo360”
                      ‣ https://canvas.tufts.edu
                          4
---
Course Forum
•  We will use Piazza as our course forum
•  You should have been enrolled already
   ‣  If not, email me
• You must join and keep up with Piazza
   ‣  We will regularly post announcements here
•  Use Piazza to:
   ‣  Post publicly: Common questions which pertain to all students
      -  Never share solutions!!!
      -  Always search first to see if question has been asked before
   ‣  Post privately: Questions containing code, or private info
                             5
---
Course Website
•  https://www.cs.tufts.edu/comp/15/
•  Schedule contains all slides, HWs, labs, and readings
•  Reference page includes helpful… references
   ‣ C++ help, style guide, CS 11 lectures, …
• Admin page covers course policy
   ‣You must read the admin page!
                           6
---
  Course Policies
  Can I get extensions on HWs?
                      How is my final grade calculated?
 How do I request a regrade?
                How can I view my HW autograder score?
What extra support can I access?
          Read the course admin page!
                         7
---
Homework
• See course webpage for HW schedule
   ‣  3 HWs
   ‣  4 projects
   ‣  Projects have multiple stages
• HWs: 7 days
•  Projects: 14 days
• You should always start early
                          8
---
Labs
•  Every Tuesday (you should already be signed up)
•  We take attendance: You must come to lab!
   ‣  You may miss up to 2 lab sessions and receive full credit
      -  But you still must submit work for these labs
•  Labs are low-stress: You will receive full credit for
   submitting a good-faith eﬀort
• Labs are due at the latest by Friday at 6pm
   ‣  But you should submit your work at the end of lab on
      Tuesday (can always resubmit later)
•  Some labs have a pre-lab. Do these!
                           9
---
Academic Integrity
•  Read our policy on the course admin page
• Students may discuss HWs, projects at a high level
   ‣ i.e., using natural languages and drawings
• Students may not show code to anyone other than
   course staﬀ
•  We rely on automated systems for detecting plagiarism
   ‣ We compare submissions with current and previous semesters
•  Any suspected violation will be reported to Dean of
   Student Aﬀairs oﬃce for an investigation
                        10
---
Academic Integrity
    No using ChatGPT!!!
             11
---
Textbook Readings
•  We regularly post readings from the online textbook
   Data Structures and Algorithm Analysis by C.A. Shaﬀer
•  Textbook readings are optional
•  However, you will usually find them to be a useful
   supplement to lectures
                         12
---
Using C++, Terminal
• This class assumes you have the basics down
   ‣  Everything covered in CS 11
• We have some resources to support you!
   ‣  See course reference page
   ‣  It includes some of my recorded lectures from CS 11
   ‣  See also: “C++ Review” lecture on course schedule
•  (Optional) Lab 0 introduces students to writing and
   submitting programs
                            13
---
Learning in this Class
• Computer science can be challenging
• …but it is not beyond your reach!
                        14
---
Learning in this Class
• Computer science can be challenging
• …but it is not beyond your reach!
 If you have prior background in CS:
  Please be respectful of others who are learning.
                       14
---
TODOs for Next Week
• Read course admin page
• Browse course reference page
   ‣  Review any materials you wish
•  Optional:
   ‣  Lab 0: Basics of terminal, working remotely
   ‣  Read posting from Shaﬀer textbook
   ‣  See “Classes Review” lecture slides for a C++ review
                            15
---
Data Structures
---
   Merriam-  SINCE 1828
   Webster
data structure HOUI
Definition of data structure
 any of various methods or formats (such as an array, file, or record) for organizing
data in a computer
---
Why Data Structures?
---
Why Data Structures?
There are two big reasons why this subject is
important:
      1. Abstraction
      2. Performance
               19
---
What is abstraction?
                20
---
What is abstraction?
•  In CS, abstraction is the hiding of low-level details to
   focus on details of greater importance
   ‣  It makes complexity more manageable
•  Abstraction is fundamental to computers and CS
   ‣  Without it, we could not build complex systems
                           20
---
Abstraction in Computers
•  When we write programs, we rely on many layers of
   abstraction
•  Each layer assumes certain functionality from the
   previous layer. Doesn’t care about low-level details!
 High-Level Language
  Assembly Language
    Machine Code
      Hardware
                         21
---
Abstraction in Computers
• Hardware: the physical components of computers
•  In fact, there are many layers of abstraction within this
   layer:
                             Motherboard
 High-Level Language         Integrated Circuits (chips)
  Assembly Language
                             Logic Gates
     Machine Code
       Hardware              Circuits
                                         Wires   Transistors
                             22
---
Abstraction in Computers
•  Machine Code: instructions, expressed in binary
   numbers, that cause the CPU to perform a specific task
 High-Level Language
 Assembly Language
    Machine Code
      Hardware
                         23
---
Abstraction in Computers
• Assembly language: slightly higher-level than machine
  code
  ‣  Instructions are more English-like
  ‣  Some instructions map to multiple machine code instructions
 High-Level Language
  Assembly Language
     Machine Code
       Hardware
                          24
---
Abstraction in Computers
• High-level language: C++, Java, Python, Ruby, …
 High-Level Language
 Assembly Language
    Machine Code
      Hardware
                        25
---
Abstraction in Computers
 High-Level Language
 Assembly Language
    Machine Code
      Hardware
                        26
---
The Power of Abstraction
•  When operating at a higher layer, we don’t need to
   care about the lower-level details
•  When I program in C++, I don’t care about circuits
   or transistors
•  When I watch Netflix, I’m not worried about the
   code it comprises
                          27
---
What About Data Structures?
•  In theory, every single program could be written using
   only arrays
•  But this would get extremely complex, tedious
•  Diﬀerent data structures provide diﬀerent abstractions
   ‣ Which you should use depends on your goal!
                          28
---
Data Structures and Abstractions
•  What if you want to represent hierarchical relationships
   among entities?
• Use trees!
                        29
---
Data Structures and Abstractions
• Representing distances between locations?
• Use graphs
                        30
---
Data Structures and Abstractions
• Representing an ordered line?
• Use queues
                        31
---
Why Data Structures?
There are two big reasons why this subject is
important:
      1. Abstraction
      2. Performance
               32
---
Performance
•  Diﬀerent data structures are associated with various
   costs/benefits in time and space
• These are crucial considerations, especially as
   programs grow larger, handle more data
•  In CS 15, we will learn to formally classify and compare
   costs in time/space associated with data structures
                         33
---
CS 15
•  This course will:
   ‣  Equip you with fundamental tools—data structures—for writing
      programs
   ‣  Teach you how to pick which data structure is appropriate
   ‣  Train you in writing medium-sized programs
                            34
---
CS 15
•  This course will:
   ‣  Equip you with fundamental tools—data structures—for writing
      programs
   ‣  Teach you how to pick which data structure is appropriate
   ‣  Train you in writing medium-sized programs
         This is one of the most useful
      courses for employment, interviews
                          34
---
CS 15: Data Structures
     Linked Lists
---
Previously: the List ADT
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
int size()
void  addAt(ElementType elt, int index)
void  removeAt(int index)
bool  isEmpty()
ElementType elementAt(int index)
         …and more (if you’d like)!
                   2
---
Before: ArrayLists
•  ArrayLists are one choice to implement the List ADT
   ‣ addAtBack, addAtFront, elementAt, isEmpty, etc.
•  Under the hood, ArrayLists use a dynamically-
   allocated (i.e., heap) array
   ‣ Grow size of array when necessary
                             3
---
ArrayLists: Advantages
• Not fixed-size (unlike normal C++ arrays)
                        4
---
ArrayLists: Advantages
• Not  fixed-size (unlike normal C++ arrays)
•  Instantaneous access to any array element
   ‣  Elements are stored contiguously in memory
                       11 6 3  17 1  9
   ‣  Given address of first index, compute address of any index i
      by adding i *  sizeof(int)     to address of first index (for int
      arrays)
                               5
---
ArrayLists: Disadvantages?
• Can you think of any?
                        6
---
ArrayLists: Disadvantages?
•  Certain insertions/removals are expensive
   ‣  addAtFront, or addAt(index) for index near front
   ‣  Removals at or near front
   ‣  Need to “shift” all subsequent elements of array
                             7
---
ArrayLists: Disadvantages?
•  Certain insertions/removals are expensive
   ‣  addAtFront, or addAt(index) for index near front
   ‣  Removals at or near front
   ‣  Need to “shift” all subsequent elements of array
                        addAtFront(42)
             2    17    -4   39    20   14    42   99
                                   7
---
ArrayLists: Disadvantages?
•  Certain insertions/removals are expensive
   ‣  addAtFront, or addAt(index) for index near front
   ‣  Removals at or near front
   ‣  Need to “shift” all subsequent elements of array
                        addAtFront(42)
             2    17    -4   39    20   14    42   99
                                   8
---
ArrayLists: Disadvantages?
•  Certain insertions/removals are expensive
   ‣  addAtFront, or addAt(index) for index near front
   ‣  Removals at or near front
   ‣  Need to “shift” all subsequent elements of array
                        addAtFront(42)
                  2     17   -4    39   20    14   42    99
                                   9
---
ArrayLists: Disadvantages?
•  Certain insertions/removals are expensive
   ‣  addAtFront, or addAt(index) for index near front
   ‣  Removals at or near front
   ‣  Need to “shift” all subsequent elements of array
                        addAtFront(42)
            42    2     17   -4    39   20    14   42    99
                                   10
---
ArrayLists: Disadvantages?
• Time vs. space tradeoﬀ when growing array
  ‣  Recall: when we reach capacity, we create an array that is
     2 * capacity + 2, then copy over elements
  ‣  This turns out to be relatively time eﬃcient
     -  Copying all elements is time-intensive
     -  But we don’t do it often
     -  Average case: pretty fast! (analysis left to CS 160)
                               11
---
ArrayLists: Disadvantages?
• Time vs. space tradeoﬀ when growing array
  ‣  Recall: when we reach capacity, we create an array that is
     2 * capacity + 2, then copy over elements
  ‣  This turns out to be relatively time eﬃcient
     -  Copying all elements is time-intensive
     -  But we don’t do it often
     -  Average case: pretty fast! (analysis left to CS 160)
  ‣  But can be space ineﬃcient
     -  Half of newly expanded array is (initially) unused
     -  As array gets larger (millions? billions?) that’s a lot of wasted space!
                               12
---
ArrayLists: Disadvantages?
• Time vs. space tradeoﬀ when growing array
  ‣ New idea: grow array to size original_size + 1
                        13
---
ArrayLists: Disadvantages?
• Time vs. space tradeoﬀ when growing array
  ‣  New idea: grow array to size original_size   +  1
     -  Space eﬃcient! Only one (initially) empty space
     -  Time ineﬃcient! Need to copy entire array each time we add an element
                              14
---
Linked Lists
•  Today, we study a new data structure: linked lists
•  Like ArrayLists, they can be used to implement List ADT
   ‣  i.e., same public interface as ArrayLists!
   ‣  addAtBack, addAtFront, elementAt, isEmpty, etc.
•  Diﬀerent implementation strategy, with new costs/
   benefits
                          15
---
Linked Lists
•  The building blocks of linked lists are nodes
• A node is composed of:
   ‣  A data element (like a string, int, Person, etc.)
   ‣  A pointer to another node
struct  Node {
       ElementType data;
       Node *next;
};
                        16
---
Linked Lists
•  The building blocks of linked lists are nodes
• A node is composed of:
   ‣  A data element (like a string, int, Person, etc.)
   ‣  A pointer to another node
struct  Node {                We draw them as:
       ElementType data;          data  next
       Node *next;
};                                “bob”
                        16
---
Linked List
• A linked list is a linear series of nodes:
 “bob”          “alice”        “carol”       “diego”          …
• Each node could be stored anywhere in memory
  ‣  Unlike arrays, data is not contiguous
  ‣  The key is that each node keeps track of the next node
                               17
---
Linked List: Front
•  With a linked list, we only need to keep track of the
   front node:
  “bob”        “alice”      “carol”       “diego”        …
front
•  If we have access to the front node, we can reach
   all subsequent nodes
   ‣ Just follow the links!
                            18
---
  Linked List: Sentinel
  • We   use  a  special  value, called  a  sentinel,  to
     indicate we’ve reached the end of a list
     ‣  More generally, sentinel values are used to indicate the end
        of some data
  •  Our choice of sentinel: nullptr
  “bob”       “alice”      “carol”      “diego”      nullptr
front
                             19
---
  Linked List: (Optional) Back
  •  Many linked list implementations also include a back
     pointer
  •  This gives quicker access to the end of the list
  “bob”        “alice”      “carol”      “diego”      nullptr
front                                    back
                             20
---
Linked List: Overview
•  A linked list can either be:
   ‣  Empty (nullptr)
   ‣  A node with: a data element, and a pointer to a linked list
•  Notice: this definition is recursive!
   ‣  Empty list is like the “base case”
•  We will use its recursive structure to inspire some
   operations over linked lists
                             21
---
 addToFront
 • Say we wanted to add the string “sofia” as the            first
    piece of data in the list
 • What sequence of operations do we need to perform?
  “bob”         “alice”       “carol”       “diego”       nullptr
front
                               22
---
  addToFront
  1.    Create a node with data “sofia”.
   “sofia”
   “bob”               “alice”             “carol”             “diego”              nullptr
front
                                            23
---
  addToFront
  2.    Set “next” pointer of node to first element in list.
   “sofia”
   “bob”               “alice”             “carol”             “diego”              nullptr
front
                                            24
---
  addToFront
  3.    Update “front” to point to new node.
   “sofia”
   “bob”               “alice”             “carol”             “diego”              nullptr
front
                                            25
---
addToFront: LL vs. AL
•  Linked list: easy!
   ‣ Just create a new node and update two pointers
•  ArrayList: more costly
   ‣ All elements in array must be “shifted over” to next space
                             26
---
Implementing Linked Lists
• Let’s (partially) do it!
         class StringLinkedList
         {
         public:
             StringLinkedList();
             ~StringLinkedList();
             // Same public interface as ArrayLists!
         private:
             struct Node {
                 std::string data;
                 Node *next;
             };
             Node *front;
             // Any additional helper functions, vars…
         };
                              27
---
Implementing Linked Lists
• Let’s (partially) do it!                  Notice: We keep “Node”
                                     ‣     struct private to class!
         class StringLinkedList         - Better data abstraction!!
         {                                 Client doesn’t need to
         public:                        -  know about Node
             StringLinkedList();           Client may even have their
             ~StringLinkedList();          own Node class
             // Same public interface as ArrayLists!
         private:
             struct Node {
                 std::string data;
                 Node *next;
             };
             Node *front;
             // Any additional helper functions, vars…
         };
                              27
---
Private Structs
•  Syntactic oddity when using structs that are private to a
   class:
   ‣  To refer to struct in the return type of a function, must scope it
      under class name (i.e., ClassName::StructName)
   ‣  To refer to struct in argument type of a function, we can just
      refer directly to the struct name
                                28
---
    Private Structs
    •  Syntactic oddity when using structs that are private to a
       class:
       ‣  To refer to struct in the return type of a function, must scope it
          under class name (i.e., ClassName::StructName)
       ‣  To refer to struct in argument type of a function, we can just
          refer directly to the struct name
StringLinkedList::Node *StringLinkedList::newNode(string newData, Node *next)
{
    …
}
                                     29
---
    Private Structs
    •  Syntactic oddity when using structs that are private to a
       class:
       ‣  To refer to struct in the return type of a function, must scope it
          under class name (i.e., ClassName::StructName)
       ‣  To refer to struct in argument type of a function, we can just
          refer directly to the struct name
                               Out here, C++ doesn’t know
                               what a Node is, so we must
                             explicitly state it comes from
                                StringLinkedList class.
StringLinkedList::Node *StringLinkedList::newNode(string newData, Node *next)
{
    …
}
                                    29
---
    Private Structs
    •  Syntactic oddity when using structs that are private to a
       class:
       ‣  To refer to struct in the return type of a function, must scope it
          under class name (i.e., ClassName::StructName)
       ‣  To refer to struct in argument type of a function, we can just
          refer directly to the struct name
StringLinkedList::Node *StringLinkedList::newNode(string newData, Node *next)
{   …                    Inside here, C++ knows we
}                              are defining a
                       StringLinkedList function, and
                          deduces what a Node is.
                                    29
---
Implementing Linked Lists
•  Let’s write (some of) an implementation:
   ‣ StringLinkedList.h
   ‣ StringLinkedList.cpp
   ‣ StringListClient.cpp
                          30
---
 Side Note: Wrapper Functions
 • Notice how we implement printRecursive()
               void StringLinkedList::printRecursive()
public         {   printRecHelper(front);
               }
               void StringLinkedList::printRecHelper(Node *curr)
               {
                   if (curr !=  nullptr) {
                       cout <<  curr->data << " ";
private            }   printRecHelper(curr->next);
                   else {
                       cout <<  "\n";
                   }
               }
                                31
---
Side Note: Wrapper Functions
•  Any Linked List client just needs to call
   list.printRecursive()
•  But if we want a recursive function, the function needs to
   take an argument telling it where to start printing from
•  So, we use printRecHelper(Node *curr)
   ‣  This is also more modular, since it works for any node in the list, not
      just the front node
•  We call printRecursive  a wrapper function for
   printRecHelper
•  We will use this pattern frequently in this course
                         32
---
Linked Lists and Memory
• Linked list data is non-contiguous in memory
• Pros/cons?
                        33
---
Linked Lists and Memory
• Linked list data is non-contiguous in memory
• Pros/cons?
• Con: can’t calculate list memory addresses based on
  indices
  ‣ That means we don’t get instantaneous access to elements
                          33
---
Linked Lists and Memory
• Linked list data is non-contiguous in memory
• Pros/cons?
• Con: can’t calculate list memory addresses based on
   indices
   ‣  That means we don’t get instantaneous access to elements
•  Pro: insertion/removal at front is easier, faster
   ‣  Because it’s not important where things are in memory
   ‣  Just need to make sure all data is pointed to
                          33
---
Linked Lists: More Operations
•  Let’s take a high-level look at some more operations
   ‣ removeFront
   ‣ elementAt
   ‣ insertAt
                        34
---
  removeFront
   “sofia”
   “bob”                “alice”              “carol”              “diego”               nullptr
front
                                              35
---
  removeFront
  1.   Save a pointer to the original front
                       old_front
  “sofia”
   “bob”              “alice”            “carol”            “diego”             nullptr
front
                                          36
---
  removeFront
  2.   Update “front” pointer.
                       old_front
  “sofia”
   “bob”              “alice”            “carol”            “diego”             nullptr
front
                                          37
---
  removeFront
  3.   Recycle old_front
                       old_front
  “sofia”
   “bob”              “alice”            “carol”            “diego”             nullptr
front
                                          38
---
removeFront
•  Linked list: once again cheap
   ‣ Save old front, set new front, recycle memory
•  ArrayList: expensive
   ‣ Must “shift left” all elements after removal
                            39
---
 elementAt
 • elementAt: given int i, return data at position i in list
    ‣ Counting starts at 0
 • e.g., how would we compute elementAt(2)?
  “bob”        “alice”       “carol”      “diego”       nullptr
front
                             40
---
  elementAt
  •  Keep track of a current_node and a count
  • Keep updating current_node    to next in list,
     incrementing count, until count == 2
 count == 0
 current_node
  “bob”       “alice”    “carol”     “diego”     nullptr
front
                          41
---
  elementAt
  •  Keep track of a current_node and a count
  • Keep updating current_node    to next in list,
     incrementing count, until count == 2
 count == 1
 current_node
  “bob”       “alice”    “carol”     “diego”     nullptr
front
                          42
---
 elementAt
 •  Keep track of a current_node and a count
 • Keep updating current_node          to next in list,
    incrementing count, until count == 2
count == 2
current_node             return “carol”!
  “bob”       “alice”     “carol”     “diego”      nullptr
front
                           43
---
elementAt
•  Linked Lists: expensive
   ‣  Must iterate through list until we reach element that we want
•  ArrayLists: cheap
   ‣  Values are contiguous in memory
   ‣  So we can just compute and jump to the address of the element
                            44
---
 insertAt
 • insertAt(int index,          string data)
    ‣ Inserts data at position index in list
 •  Say we want to insert data “sofia” at position 2
  “bob”        “alice”      “carol”      “diego”       nullptr
front
                             45
---
  insertAt
  1.    Make new node containing data “sofia”
                                    “sofia”
   “bob”               “alice”             “carol”             “diego”              nullptr
front
                                            46
---
 insertAt
 2.  Find position 1 to insert new node at position 2
                         “sofia”
 count == 0
current_node
  “bob”         “alice”       “carol”       “diego”       nullptr
front
                               47
---
 insertAt
 2.  Find position 1 to insert new node at position 2
                         “sofia”
 count == 1
current_node
  “bob”         “alice”       “carol”       “diego”       nullptr
front
                               48
---
  insertAt
  3.  Change “next” pointer of new node to node #2
                          “sofia”
 count == 1
 current_node
  “bob”          “alice”       “carol”       “diego”        nullptr
front
                                49
---
  insertAt
  4.  Change “next” pointer of current_node to new node
                          “sofia”                 Done!
 count == 1
 current_node
  “bob”          “alice”       “carol”       “diego”        nullptr
front
                                50
---
insertAt
•  Linked Lists:
   ‣  Finding position to insert is expensive
      -  Have to iterate through list until that position
   ‣  Inserting new data is cheap: just update two pointers
•  ArrayLists:
   ‣  Finding position to insert is cheap
   ‣  Inserting new data is expensive
      - Have to “shift over” all subsequent elements
                               51
---
insertAt
•  Better for inserting at front: Linked Lists
•  Better for inserting in middle: could use either
•  Better for inserting at back: ArrayLists
   ‣ potentially Linked Lists, if we have a back pointer
                            52
---
insertAt
•  Let’s implement it
   ‣  Important: We’ll assume for now that given index is within
      correct range
                            53
---
Implementing Linked Lists
•  Implementation is all about correct pointer management
•  Order matters!!
   ‣   Can’t access a pointer for a recycled node
     -  Example: destructor (had to recycle rest of list before recycling current node)
   ‣   Only update a pointer if what it is currently pointing to is saved
     -  Example: insertAt (set new node’s next before updating current node’s next)
                               54
---
Implementing Linked Lists
•  Implementation is all about correct pointer management
•  Order matters!!
   ‣   Can’t access a pointer for a recycled node
     -  Example: destructor (had to recycle rest of list before recycling current node)
   ‣   Only update a pointer if what it is currently pointing to is saved
     -  Example: insertAt (set new node’s next before updating current node’s next)
•   Additionally: be careful about dereferencing nullptr
   ‣   e.g., accessing node->next when node is nullptr
   ‣   You will get a segmentation fault!
                            55
---
Implementing Linked Lists
•  Pay careful attention to edge cases
   ‣  e.g., handling an empty list or a singleton (1-element) list
   ‣  e.g., inserting/removing at front or end
              Draw pictures before
             implementing anything,
         and test thoroughly afterwards!
                        56
---
Linked Lists: Variations
• Could have back member         variable that points to last
   node in list
•  Circular lists
   ‣  “Last” node of list points to first node
•  “Header” and “trailer” nodes
   ‣  Special, empty nodes that front and back always point to
   ‣  Makes it easier to avoid mistakes when handling edge cases
• Doubly linked lists
                            57
---
Doubly Linked Lists
•  Similar to linked list, but each node now keeps
   track of next and previous node
  struct Node {                 We draw them as:
      ElementType data;
      Node  *next;                 prev  data  next
      Node  *prev;                    “bob”
  };
                        58
---
      Doubly Linked List
      front
                prev    data   next      prev    data   next       prev   data   next
                       “bob”                    “alice”                  “carol”
nullptr                                                                                nullptr
                                                 59
---
      Doubly Linked List
      front
                prev    data   next      prev    data   next       prev   data   next
                       “bob”                    “alice”                  “carol”
nullptr                                                                                nullptr
                                                 59
---
Doubly Linked List
•  There are now more pointers to maintain
   ‣  And we must be careful!
• But certain operations are now easier
   ‣  Starting at any node, we can reach any other node in the list
      -  We can traverse forward, backward, reverse the list easily, etc.
   ‣  If we need to insert at or remove at a particular position, we can
      easily access the previous & next nodes to update pointers
                              60
---
      insertAt: Doubly Linked List
      • insertAt(int index,                        string data)
      •  Say we want to insert “sofia” at index 2
     front
               prev   data   next      prev   data  next      prev   data   next
                     “bob”                   “alice”                “carol”
nullptr                                                                           nullptr
                                              61
---
     insertAt: Doubly Linked List
     1.    Make a new node containing data “sofia”
                                              “sofia”
    front
               prev   data   next       prev   data   next      prev   data   next
                     “bob”                    “alice”                 “carol”
nullptr                                                                             nullptr
                                               62
---
     insertAt: Doubly Linked List
     2.    Find node at index 1
                                              “sofia”
    front
               prev   data   next       prev   data   next      prev   data   next
                     “bob”                    “alice”                 “carol”
nullptr                                                                             nullptr
                 current_node
                 count ==     0
                                               63
---
     insertAt: Doubly Linked List
     2.    Find node at index 1
                                              “sofia”
                                                                Insert after here!
    front
               prev   data   next       prev   data   next      prev   data   next
                     “bob”                    “alice”                 “carol”
nullptr                                                                             nullptr
                 current_node
                 count ==     1
                                               64
---
      insertAt: Doubly Linked List
      3.   newNode->next = current_node->next
                                             “sofia”
                                                              Insert after here!
     front
               prev   data   next      prev   data  next      prev   data   next
                     “bob”                   “alice”                “carol”
nullptr                                                                           nullptr
                 current_node
                 count ==     1
                                              65
---
     insertAt: Doubly Linked List
     3.   newNode->next = current_node->next
     4.   newNode->prev = current_node
                                          “sofia”
                                                          Insert after here!
     front
              prev   data  next      prev  data  next      prev  data   next
                    “bob”                 “alice”               “carol”
nullptr                                                                      nullptr
                current_node
                count ==    1
                                            66
---
    insertAt: Doubly Linked List
    3.  newNode->next = current_node->next
    4.  newNode->prev = current_node
    5.  current_node->next = newNode
                                   “sofia”
                                                 Insert after here!
    front
            prev  data  next   prev  data  next   prev  data  next
                 “bob”             “alice”            “carol”
nullptr                                                          nullptr
             current_node
             count ==  1
                                     67
---
    insertAt: Doubly Linked List
    3.  newNode->next = current_node->next
    4.  newNode->prev = current_node
    5.  current_node->next = newNode
    6.  newNode->next->prev          = newNode
                                   “sofia”
                                                 Insert after here!
    front
            prev  data  next   prev  data  next   prev  data  next
                 “bob”             “alice”            “carol”
nullptr                                                          nullptr
             current_node
             count ==  1
                                     68
---
insertAt: Potential Pitfalls
•  Notice: once again, order matters!
   ‣  e.g., can’t reassign current_node->next until we have
      used it to set newNode->next
                            69
---
insertAt: Potential Pitfalls
•  Notice: once again, order matters!
   ‣  e.g., can’t reassign current_node->next    until we have
      used it to set newNode->next
•  Be careful for edge cases!
   ‣  Need to specially handle insertion at front (just like before)
   ‣  When inserting at the back, newNode->next will be
      nullptr. This means you can’t reassign
      newNode->next->prev. You will get a Segmentation
      Fault. You need a special check to avoid this.
                               70
---
insertAt: Potential Pitfalls
•  Notice: once again, order matters!
   ‣  e.g., can’t reassign current_node->next until we have
      used it to set newNode->next
•  Be careful for edge cases!
   ‣  Need to specially handle insertion at front (just like before)
   ‣  When inserting at the back, newNode->next will be
      nullptr. This means you can’t reassign
      newNode->next->prev. You will get a Segmentation
      Fault. You need a special check to avoid this.
               Draw pictures before
              implementing anything,
          and test thoroughly afterwards!
                          71
---
ArrayLists vs. Linked Lists
•  Both ArrayLists and Linked Lists implement List ADT
   ‣ i.e., provide the same operations
•  Which is preferable? Depends on how you use it!
                         72
---
ArrayLists vs. Linked Lists
• Which is faster for the following operations?
                          AL     LL
          elementAt
          addAtBack
          addAtFront
             size
            addAt
           removeAt
           isEmpty
                         73
---
ArrayLists vs. Linked Lists
• Which is faster for the following operations?
                          AL     LL
          elementAt
          addAtBack
          addAtFront
             size
            addAt
           removeAt
           isEmpty
                         74
---
ArrayLists vs. Linked Lists
• Which is faster for the following operations?
                           AL      LL
           elementAt
           addAtBack                     (or both, if LL has
                                         a back member)
           addAtFront
              size
             addAt
           removeAt
            isEmpty
                          75
---
ArrayLists vs. Linked Lists
• Which is faster for the following operations?
                          AL     LL
          elementAt
          addAtBack
          addAtFront
             size
            addAt
           removeAt
           isEmpty
                         76
---
ArrayLists vs. Linked Lists
• Which is faster for the following operations?
                           AL      LL
           elementAt
           addAtBack
           addAtFront
              size                      (assuming both have
                                         a size member)
             addAt
           removeAt
            isEmpty
                          77
---
ArrayLists vs. Linked Lists
• Which is faster for the following operations?
                            AL     LL
           elementAt
           addAtBack
           addAtFront
              size
             addAt         It depends!  closer to back: AL
                                        closer to front: LL
           removeAt
            isEmpty
                          78
---
ArrayLists vs. Linked Lists
• Which is faster for the following operations?
                               AL       LL
            elementAt
            addAtBack
            addAtFront
                size                        •  LL quickly removes
               addAt           It depends!  •  elements once found
                                               AL finds elements
             removeAt          It depends!     quickly, but has to
                                            •  perform “shift”
              isEmpty                       •  Closer to front: LL
                                               Closer to back: AL
                             79
---
ArrayLists vs. Linked Lists
• Which is faster for the following operations?
                           AL     LL
           elementAt
           addAtBack
          addAtFront
              size
             addAt         It depends!
           removeAt        It depends!
            isEmpty
                         80
---
 CS 15: Data Structures
Makefiles: A Quick Tutorial
---
Review: Separate Compilation
• We have seen that when we use classes:
   ‣  We put each class X’s interface in a file named X.h
   ‣  We put each class X’s implementation in a file named X.cpp
   ‣  Any clients of a class X must #include “X.h”
                              2
---
Review: Separate Compilation
•  There are two main stages when building an executable
•  Compilation
   ‣  For each X.cpp file, use clang++ with the flag -c in order to
      compile X.cpp into a file named X.o
•  Linking
   ‣  Use clang++ to link all the separately compiled .o files
   ‣  Include “-o final_program_name” to name the final program
•  Often times, people refer to both of the above steps as
   “compilation”—but this is imprecise
                              3
---
Example
•  Say we have the following files:
   ‣  Point.cpp, Point.h, Rectangle.cpp, Rectangle.h, and
      main.cpp
•  We can compile with:
clang++ -Wall -Wextra -c  Point.cpp
clang++ -Wall -Wextra -c  Rectangle.cpp
clang++ -Wall -Wextra -c  main.cpp
clang++ -Wall -Wextra -o  final_prog Point.o Rectangle.o main.o
•  Let’s see it in action
                              4
---
Can we do better?
•  Our current approach to separate compilation is
   tedious, repetitive
•  Even worse, it can be slow
   ‣ …if we re-compile every file, even those that haven’t changed
•  This is true in CS 15, but it is especially true with real-
   world programs
   ‣  Industrial programs often comprise 100s of .cpp and .h files
   ‣  Compilation time is a serious concern!
                              5
---
Solution: make
• make is a special program that automates tasks
•  Typically used to automate the compilation and linking
   of programs
• make follows the instructions provided in a Makefile
•  It can automatically track which files have changed
   since a previous compilation, avoid re-compiling
                         6
---
Makefiles
• A Makefile is built of rules with the following structure:
           target: prerequisites
                  recipe
                     7
---
Makefiles
• A Makefile is built of rules with the following structure:
             target: prerequisites
                     recipe
The target is the argument given to the make program on
the command line (i.e, we write make target). Typically,
it is the name of the file that will be created after the rule is
executed.
                        8
---
Makefiles
• A Makefile is built of rules with the following structure:
              target:   prerequisites
                        recipe
A list of 0 or more prerequisites (also called
dependencies) name the     files or targets that the current
rule depends on.
The current rule will only be executed if a file named target
does not exist, or if any of the prerequisites are more
recent than the target file.
                           9
---
  Makefiles
  • A Makefile is built of rules with the following structure:
               target:  prerequisites
                        recipe
Note: This must be a tab (not spaces)
  The recipe is the command(s) that are actually executed
  when this rule is run.
                          10
---
Makefile: Example
We already have the knowledge we need to write a simple,
naive Makefile, which consists of one rule:
final_prog:
      clang++ -Wall -Wextra -c  Point.cpp
      clang++ -Wall -Wextra -c  Rectangle.cpp
      clang++ -Wall -Wextra -c  main.cpp
      clang++ -Wall -Wextra -o  final_prog Point.o Rectangle.o main.o
Target named final_prog, no prerequisites, and a recipe
that performs standard separate compilation and linking.
Let’s try!
                                11
---
Makefile: Example
•  Notice:
   ‣  We can type make final_prog, or we can simply type make
      (without a specified rule, the first rule in the Makefile is executed)
                            12
---
Makefile Variables
•  Let’s try to reduce the repetition in our Makefile
•  First, notice: every command used the same compiler
   (clang++) and series of flags (-Wall, etc.)
• We can put the compiler and flag names into variables
•  By convention:
   ‣  We put the compiler in a variable named CXX
   ‣  We put the compilation flags in a variable named CXXFLAGS
   ‣  We put the linking flags in a variable named LDFLAGS
                             13
---
Makefile Variables
•  New state of Makefile:
CXX = clang++                  We define variables at
CXXFLAGS = -g -Wall -Wextra       top of Makefile,
LDFLAGS = -g                    with VARNAME = …
final_prog:
   ${CXX}  ${CXXFLAGS}  -c  Point.cpp         Let’s try!
   ${CXX}  ${CXXFLAGS}  -c  Rectangle.cpp
   ${CXX}  ${CXXFLAGS}  -c  main.cpp
   ${CXX}  ${LDFLAGS} -o final_prog Point.o Rectangle.o main.o
               We use variables with
                   ${VARNAME}
                            14
---
Separating Rules
•  Until now, we’ve put everything in one rule
•  Typically, we want a separate rule for every file built
                           15
---
Separating Rules
• First, let’s write the rules for the separately compiled .o files:
         Each rule named for the file it creates
Point.o: Point.cpp Point.h            First prereq is
   ${CXX} ${CXXFLAGS} -c Point.cpp corresponding .cpp
                                   file, followed by any
                                     included .h files
Rectangle.o: Rectangle.cpp Rectangle.h Point.h
   ${CXX} ${CXXFLAGS} -c Rectangle.cpp
main.o: main.cpp Point.h Rectangle.h
   ${CXX} ${CXXFLAGS} -c main.cpp
                        16
---
Separating Rules
•  Finally, the rule for linking:
final_prog: Point.o Rectangle.o main.o
   ${CXX} ${LDFLAGS} -o final_prog Point.o Rectangle.o main.o
    Notice: the prereqs are the .o files that are linked.
       This tells make to run the same-named rules
          (Point.o, etc.) before running this one.
                            17
---
Separating Rules
•  Finally, the rule for linking:
final_prog: Point.o Rectangle.o main.o
   ${CXX} ${LDFLAGS} -o final_prog Point.o Rectangle.o main.o
             We always place the linking rule
             at the top, so that we can create
            an executable by just typing make.
                         Let’s try!
                            18
---
Special Variables
• make comes with some special, pre-defined variables
   that can be used in recipes:
   ‣  $@ refers to the target name of the current rule
   ‣  $^ refers to the list of all prerequisites
   ‣  $< refers to the name of the first prerequisite
                            19
---
Special Variables
• make comes with some special, pre-defined variables
   that can be used in recipes:
   ‣  $@ refers to the target name of the current rule
   ‣  $^ refers to the list of all prerequisites
   ‣  $< refers to the name of the first prerequisite
•  We can use these to shorten our rules, e.g., the linking
   rule can be rewritten as:
final_prog:   Point.o  Rectangle.o  main.o
   ${CXX}  ${LDFLAGS}  -o  $@ $^
Let’s try!                 20
---
Built-In Rules
• make includes many built-in rules, which we can use to
   simplify our Makefile even further
•  For example:
   ‣  Given a rule named X.o, with a prereq named X.cpp, make
      knows it should compile X.cpp to make X.o
      - It even knows to use the CXX and CXXFLAGS variables!
   ‣  We just need to provide the prerequisites for any .o rule
                            21
---
Simplifying .o Rules
• We can rewrite:
Point.o: Point.cpp Point.h
   ${CXX} ${CXXFLAGS} -c Point.cpp
• as:
Point.o: Point.cpp Point.h
No recipe needed! Let’s try.
                        22
---
Phony Targets
• Sometimes, we define rules that aren’t used to create
   files, but to execute some other task. These are called
   phony targets.
•  For example, it is common to have a rule named clean
   that:
   ‣  Removes the executable file
   ‣  Removes all object (.o) files
   ‣  Removes any temporary files (e.g., files ending in ~)
                              23
---
  clean
  • For our program, we can write the following clean rule:
  clean:
     rm -f final_prog *.o *~
Shell command for
  removing files
                          24
---
clean
• For our program, we can write the following clean rule:
clean:
   rm -f final_prog *.o *~
   “force” flag:
 remove without
    warnings
                        25
---
clean
• For our program, we can write the following clean rule:
clean:
   rm -f  final_prog  *.o *~
          List of files to remove:
            -final_prog executable
            -* is a “wildcard” character
               -*.o matches all files ending in “.o”
               -*~ matches any files ending in “~"
                          26
---
clean
• For our program, we can write the following clean rule:
clean:
   rm -f final_prog   *.o *~
          Warning: Be very careful when using rm
           with *. If you accidentally add a space
           after * (e.g., “rm -f * ~”), you will delete
                all files in current directory!
                          27
---
clean
• For our program, we can write the following clean rule:
clean:
   rm -f final_prog *.o *~
                     Let’s try!
                        28
---
unit_test and Makefiles
•  In order to use the unit_test framework, you must
   have the following rule in your Makefile:
unit_test: unit_test_driver.o [list of .o files used in tests]
        ${CXX}  $^
                         unit_test_driver.o will be
                         automatically created for you
   The unit_test program calls make  unit_test,
              which executes this rule.
                         29
---
    unit_test and Makefiles
    • For example, for your HW1, you need this rule:
unit_test: unit_test_driver.o CharArrayList.o
           ${CXX} $^
                              30
---
CS 15: Data Structures
     Midterm Info
---
Exam Logistics
•  The exam will take place in class, in-person, on
   Wednesday, March 12th
•  You will have 75 minutes to complete it
   ‣ Show up a few minutes early if you can!
•  It will be written (no laptops, iPads allowed)
• You must show up to the lecture that you are
   registered for
• Students with exam accommodations: you should have
   already reached out to the StAAR Center about scheduling
   your exam
   ‣  You will not receive accommodations if you show up to the regular
      exam                2
---
Cheat Sheet
•  You will be allowed one 8.5’’ x 11’’ cheat sheet
   ‣ Paper filled up with any notes you want
• You may use both sides
• Must be handwritten (not a print-out, not written on
   iPad)
•  You will turn in your cheat sheet along with the exam
   ‣ Put your name on the cheat sheet!
                         3
---
Exam Topics
•  Lists                         •  Trees
   ‣  ArrayLists                    ‣  Tree vocab
   ‣  Linked Lists                  ‣  Binary trees
• Complexity                        ‣  Tree traversals
• Queues                            ‣  Binary search trees
• Stacks                            ‣  AVL trees
• Recursion                            -  Insertion, not removal
   ‣ Wrapper/helper functions       ‣  -  Single & double rotations
• Binary Search                        Huﬀman coding
                             4
---
What is not on the exam
• C++ programming specifics:
   ‣  Big three
   ‣  Makefiles
   ‣  File I/O
   ‣  Exceptions
   ‣  Templates
                             5
---
Types of Questions
•  There will be programming questions!
   ‣  e.g., given some function spec, provide the function definition
   ‣  Code will be written in C++
      -  We do not care about minor syntax errors (e.g., forgetting a “;”)
      -  We do not care about style (e.g., “and” vs. “&&”)
      -  We care that the overall logic of your code is clear and correct
•  Fill in the blank
•  Multiple choice
• Short answer
                                6
---
Studying Recommendations
•  Lecture slides are full of practice questions
   ‣  Many of these would be good candidates for exam questions.
      Make sure you know how to solve them!
•  We will release practice questions today
•  Revisit HWs and labs
   ‣  Especially labs: good chance you did not complete all of them.
      Go back and finish them!
•  Review the vocab, concepts covered in lectures
                             7
---
Midterm Review
•  Next week: Monday lecture will be midterm review day
   ‣  Bring questions!
•  Next week: Tuesday lab will be midterm review day
   ‣  Bring questions!
                             8
---
CS 15: Data Structures
    Midterm Review
---
Midterm Review
•  We’ll do a quick overview of the topics we’ve covered
   so far
• This review is not comprehensive
   ‣ Could be things we don’t talk about that are on the
     midterm
                        2
---
Types, ADTs, and Data Structures
• A type is a name for a set of values
   ‣  bool: {true, false}
   ‣  int: {…, -2, -1, 0, 1, 2, … }
   ‣  char: {‘a’, ‘b’, ‘c’, …}
• An abstract data type (ADT) is a model for a type
   ‣  The model tells us: what operations define the type
   ‣  Notably, an ADT is defined independently of any implementation
      -  Like an interface
• A data structure is means of organizing and storing data
   ‣  We will use them to implement ADTs
                             3
---
Our First ADT: Lists
•  List: An ordered collection of elements
   ‣  Elements could be of any type: int, strings, animals…
               [🐶, 🐱, 🐭, 🦊, 🐵, 🐷]
   ‣  Ordered means there is a specific first, second, third, etc.
   ‣  Ordered ≠ Sorted!
•  Size: varies, not known until runtime
• What operations do we want to perform?
                             4
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
int size()
void  addAt(ElementType elt, int index)
void  removeAt(int index)
bool  isEmpty()
ElementType elementAt(int index)
         …and more (if you’d like)!
                   5
---
Implementing Lists
•  Notice: the List ADT only tells us a List’s operations
   ‣  Not how the operations are implemented
•  We studied two data structures for implementing Lists:
   ‣  ArrayLists
   ‣  Linked Lists
                             6
---
 Arrays in Memory
int  main()               •  Recall: an array variable is
{  int *arr = new int[4];    really just a pointer to the
                             first element
   return 0;
}
                          7
---
 Arrays in Memory
int main()
{
  int *arr = new int[4];
  return 0;
}
                 IN MEMORY
       Stack                         Heap
     arr
main
                          8
---
   Arrays in Memory
int   main()                      •  Now that arr is full, what
{
   int  *arr  = new int[4];          do we do if we want to
   arr[0]  =  4;
   arr[1]  =  33;                    add more?
   arr[2]  =  24;
   arr[3]  =  -9;
}  return  0;         IN MEMORY
           Stack                              Heap
                                          4 33 24 -9
       arr
 main
                                9
---
  Arrays in Memory
•  Idea: arr is just the address of a four element array
•  Let’s reassign it to be the address of a bigger array!
                    IN MEMORY
         Stack                            Heap
                                       4 33 24 -9
       arr
  main
                             10
---
  Arrays in Memory
1.  Create an eight element array.
                     IN MEMORY
         Stack                             Heap
                                        4 33 24 -9
       arr
  main
                              11
---
  Arrays in Memory
1.  Create an eight element array.
2.  Reassign arr to contain the address of the new array.
                     IN MEMORY
         Stack                             Heap
                                        4 33 24 -9
       arr
  main
                              12
---
  Arrays in Memory
1.  Create an eight element array.
2.  Reassign arr to contain the address of the new array.
3.  Copy the elements of the old array into the new array.
                     IN MEMORY
         Stack                             Heap
                                        4 33 24 -9
       arr
  main
                                        4 33 24 -9
                              13
---
  Arrays in Memory
1.  Create an eight element array.
2.  Reassign arr to contain the address of the new array.
3.  Copy the elements of the old array into the new array.
4.  Recycle the old array.
                     IN MEMORY
         Stack                             Heap
                                        4 33 24 -9
       arr
  main
                                        4 33 24 -9
                              14
---
ArrayLists: Advantages
• Not  fixed-size (unlike normal C++ arrays)
•  Constant-time access to any array element
   ‣  Elements are stored contiguously in memory
                       11 6 3  17 1  9
   ‣  Given address of first index, compute address of any index i
      by adding i *  sizeof(int)     to address of first index (for int
      arrays)
                               15
---
ArrayLists: Disadvantages?
•  Certain insertions/removals are expensive
   ‣  addAtFront, or addAt(index) for index near front
   ‣  Removals at or near front
   ‣  Need to “shift” all subsequent elements of array
                        addAtFront(42)
             2    17    -4   39    20   14    42   99
                                   16
---
ArrayLists: Disadvantages?
•  Certain insertions/removals are expensive
   ‣  addAtFront, or addAt(index) for index near front
   ‣  Removals at or near front
   ‣  Need to “shift” all subsequent elements of array
                        addAtFront(42)
             2    17    -4   39    20   14    42   99
                                   17
---
ArrayLists: Disadvantages?
•  Certain insertions/removals are expensive
   ‣  addAtFront, or addAt(index) for index near front
   ‣  Removals at or near front
   ‣  Need to “shift” all subsequent elements of array
                        addAtFront(42)
                  2     17   -4    39   20    14   42    99
                                   18
---
ArrayLists: Disadvantages?
•  Certain insertions/removals are expensive
   ‣  addAtFront, or addAt(index) for index near front
   ‣  Removals at or near front
   ‣  Need to “shift” all subsequent elements of array
                        addAtFront(42)
            42    2     17   -4    39   20    14   42    99
                                   19
---
   Linked List
   •  A series of nodes                      struct Node {
                                                 ElementType data;
      ‣  Each containing one piece of data   };  Node *next;
      ‣  Each points to exactly one node, except back
      ‣  Distinct front node
   • Each node could be anywhere in memory
      ‣  Easy to create, insert new node
      ‣  More work to find nodes in memory
  “bob”         “alice”      “carol”       “diego”      nullptr
front                                      back
                               20
---
 addToFront
 • Say we wanted to add the string “sofia” as the            first
    data element in the list
 • What sequence of operations do we need to perform?
  “bob”         “alice”       “carol”       “diego”       nullptr
front
                               21
---
  addToFront
  1.    Create a node with data “sofia”.
   “sofia”
   “bob”               “alice”             “carol”             “diego”              nullptr
front
                                            22
---
  addToFront
  2.    Set “next” pointer of node to first element in list.
   “sofia”
   “bob”               “alice”             “carol”             “diego”              nullptr
front
                                            23
---
  addToFront
  3.    Update “front” to point to new node.
   “sofia”
   “bob”               “alice”             “carol”             “diego”              nullptr
front
                                            24
---
addToFront: List vs. Array
•  Linked list: easy!
   ‣ Just create a new node and update two pointers
•  ArrayList: more costly
   ‣ All elements in array must be “shifted over” to next space
                             25
---
 elementAt
 • elementAt: given int i, return data at position i in list
    ‣ Counting starts at 0
 • e.g., how would we compute elementAt(2)?
  “bob”        “alice”       “carol”      “diego”       nullptr
front
                             26
---
  elementAt
  •  Keep track of a current_node and a count
  • Keep updating current_node    to next in list,
     incrementing count, until count == 2
 count == 0
 current_node
  “bob”       “alice”    “carol”     “diego”     nullptr
front
                          27
---
  elementAt
  •  Keep track of a current_node and a count
  • Keep updating current_node    to next in list,
     incrementing count, until count == 2
 count == 1
 current_node
  “bob”       “alice”    “carol”     “diego”     nullptr
front
                          28
---
 elementAt
 •  Keep track of a current_node and a count
 • Keep updating current_node          to next in list,
    incrementing count, until count == 2
count == 2
current_node             return “carol”!
  “bob”       “alice”     “carol”     “diego”      nullptr
front
                           29
---
elementAt
•  Linked Lists: expensive
   ‣  Must iterate through list until we reach element that we want
•  ArrayLists: cheap
   ‣  Values are contiguous in memory
   ‣  So we can just compute and jump to the address of the element
                            30
---
  Side Note: Wrapper Functions
  • Notice how we implement printRecursive()
 public         void StringLinkedList::printRecursive()
wrapper         {   printRecHelper(front);
                }
                void StringLinkedList::printRecHelper(Node *curr)
                {
                    if (curr !=  nullptr) {
  private               cout <<  curr->data << " ";
                        printRecHelper(curr->next);
   helper           }
                    else {
                        cout <<  "\n";
                    }
                }
                                 31
---
Measuring Time
•  We measure a program’s time complexity in terms of
   the number of elementary operations it runs
   ‣  Variable Declarations (int x;)
   ‣  Assignment of primitives (x = 10;)
   ‣  Comparison of primitives (x < y;)
   ‣  Other primitive operations (x + y;)
   ‣  …
•  Note: under the hood, some of these operations may
   take longer than others
   ‣  We don’t care about these diﬀerences
   ‣  Only care that they are all constant time operations
                            32
---
Asymptotic Analysis
•  We’re not interested in performance for small inputs
   ‣ Generally, the diﬀerences are negligible
•  Moreover, we don’t really even care about the specific
   number of operations (i.e., 7 vs. 10 vs. 100 vs. …)
•  Rather, we care how the number of operations grows
   as the input size grows
   ‣ This is called asymptotic analysis
                           33
---
Big O Notation
•  We achieve asymptotic analysis using Big O Notation:
   a technique for describing the upper bound of a
   function as it approaches infinity.
                         34
---
Big O Notation: In Practice
•  In practice, we use Big O to identify the complexity
   class of a function/program/algorithm based on the
   shape of the curve of its performance vs. input size
•  Complexity classes:
   ‣  O(1): constant
   ‣  O(n): linear
   ‣  O(n²): quadratic
   ‣ …
                            35
---
Complexity Classes
•  From asymptotically smallest to largest:
   ‣  O(1): constant
   ‣  O(log n): logarithmic
   ‣  O(n): linear
   ‣  O(n²): quadratic
   ‣  O(nᵏ): polynomial
   ‣  O(2ⁿ): exponential
                                36
---
ArrayLists vs. Linked Lists
Using Big O, give the runtime complexity of each operation, for a list
of size n.
You may ignore any potential “expand and copies” for the ArrayList.
                                     ArrayList     w/Linked List
                                                      back pointer
                  insert at front
                  insert at back
                  get kᵗʰ element
                  check if given
                element is in list
                                         37
---
ArrayLists vs. Linked Lists
Using Big O, give the runtime complexity of each operation, for a list
of size n.
You may ignore any potential “expand and copies” for the ArrayList.
                                      ArrayList      w/Linked List
                                                        back pointer
                   insert at front       O(n)              O(1)
                   insert at back
                  get kᵗʰ element
                  check if given
                element is in list
                                          38
---
ArrayLists vs. Linked Lists
Using Big O, give the runtime complexity of each operation, for a list
of size n.
You may ignore any potential “expand and copies” for the ArrayList.
                                      ArrayList      w/Linked List
                                                        back pointer
                   insert at front       O(n)              O(1)
                   insert at back        O(1)              O(1)
                  get kᵗʰ element
                  check if given
                element is in list
                                          39
---
ArrayLists vs. Linked Lists
Using Big O, give the runtime complexity of each operation, for a list
of size n.
You may ignore any potential “expand and copies” for the ArrayList.
                                      ArrayList      w/Linked List
                                                        back pointer
                   insert at front       O(n)              O(1)
                   insert at back        O(1)              O(1)
                  get kᵗʰ element        O(1)          O(n) (or O(k))
                  check if given
                element is in list
                                          40
---
ArrayLists vs. Linked Lists
Using Big O, give the runtime complexity of each operation, for a list
of size n.
You may ignore any potential “expand and copies” for the ArrayList.
                                      ArrayList      w/Linked List
                                                        back pointer
                   insert at front       O(n)              O(1)
                   insert at back        O(1)              O(1)
                  get kᵗʰ element        O(1)          O(n) (or O(k))
                  check if given         O(n)              O(n)
                element is in list
                                          41
---
What is a Queue?
•  It’s simple: a queue is a line
   ‣  Elements are added at the back, taken from the front
• Examples
   ‣  Waiting in line to buy a coﬀee
   ‣  Customer service queue
   ‣  A printer queue on a network
   ‣  …
•  We often refer to queues as first in, first out or FIFO
                            42
---
The Queue ADT
• What operations does a queue have?
  ‣ enqueue(ElemType     element)
     -  Adds element to back
  ‣ dequeue()
     -  Removes element from front
     -  Depending on implementation: may or may not return the element
  ‣ isEmpty()
  ‣ size()
  ‣ peek()   (sometimes called front or top)
     -  Returns front element (without dequeueing)
                            43
---
The Queue ADT
enqueue(ElemType element)
dequeue()
isEmpty()
size()
peek() (sometimes called front or top)
              Notice: no operations for
            accessing/adding/removing
               any data in the middle
                        44
---
Stacks
• The stack ADT:
   ‣  Elements always added to the “top” of the stack
      -  This is called a “push”
   ‣  Elements always removed from the “top” of the stack
      -  This is called a “pop”
•  The stack is last in, first out (or LIFO)
                              45
---
The Stack ADT
• What operations does a stack have?
  ‣ push(ElemType element)
    -  Adds new element to the top of the stack
  ‣ pop()
    -  Removes element from top of stack
    -  Depending on implementation: may or may not return element
  ‣ isEmpty()
  ‣ size()
  ‣ peek() (sometimes called top())
    -  Returns top element (without popping)
                        46
---
     Find Element in List
                             Consider a list of ints:
             ArrayList                                  Linked List
bool ArrayList::find(int   x)                   bool LinkedList::find(int   x)
{   for  (int i = 0; i  <  size; i++) {         {   Node *curr  = front;
         if  (array[i] ==  x)                       while (curr !=  nullptr) {
             return true;                               if  (curr->data ==  x)
    }                                                   currreturn  true;
}   return   false;                                 }        =  curr->next;
                                                    return  false;
                                                }
                    Assuming a list of size n, both of
                these operations have complexity O(n)
                                        47
---
Find in a Sorted List
•  What if the list is sorted?
   ‣  Say, from smallest to largest
   ‣  e.g., [1, 5, 9, 13, 20, … ]
• We can use binary search to find an element
                            48
---
Step 1: the High-Level Algorithm
Searching for an integer x:
1.  Start with the index   middle=list.size()/2
2.  If list[middle]      ==  x, we’re done! Return true.
3.  Otherwise:
   -  If x<list[middle], we know that x can only be in the first half
      of the list. Start from Step 1 with subarray from 0 to middle-1
   -  If list[middle]<x, we know that x can only be in the second
      half of the list. Start from Step 1 with subarray from middle+1
      to size-1.
Continue until remaining list is empty, then return false.
                            49
---
Binary Search: Complexity?
• For each comparison we make, we cut the search
   space in half
   ‣ We’ve seen this pattern before…
• Time complexity: O(log n)!
•  But notice: insertion, deletion is O(n), because all
   elements must be placed in sorted order
                          50
---
How much faster is Binary Search?
•  For list of size n, linear search makes n comparisons,
   binary search makes log(n) comparisons
                   Binary Search  Linear Search
         n=1            1               1
         n=10           4              10
        n=100           7              100
        n=1,000        10             1,000
      n=1,000,000      20           1,000,000
                         51
---
Sets
•  A very simple ADT: Unordered, duplicate-free collection
   of elements
• Unordered
   ‣  { 4, 7, 17 } is the same set as { 7, 17, 4 }
•  Duplicate-free
   ‣  No such set as { 4, 4, 7, 17 } (either an error, or this just reduces
      to { 4, 7, 17 }, depending on implementation)
                            52
---
Set ADT: Basic Operations
void add(ElemType element)
void remove(ElemType element)
int size()
bool contains(ElemType element)
                    53
---
Set ADT: Additional Operations
union
  ‣  Given two sets A and B, computes the set of all elements
     in A or B (or possibly both). Remember: duplicate-free!
intersection
  ‣  Given two sets A and B, computes the set of all elements
     in both A and B
subtract
  ‣  A-B is the set of elements in A but not in B
isSubset
  ‣  A is a subset of B iﬀ all elements in A are also in B
                             54
---
Sets: In Practice
•  In practice, sets are typically implemented using either
   binary search trees or hashes, another kind of data
   structure we’ll learn about later in the semester
   ‣  In C++:
      -  ordered_set is implemented using binary search tree
      -  unordered_set is implemented using hash
                            55
---
  Trees
  •  Similar to linked lists, but now, every node can point to
     more 1 or more other nodes
  •  Plus some additional restrictions…
               A
B     C      D     E     F           G
        H       I    J    K     L    M    N     O
                   P     Q
                            56
---
Trees: Definition
•  A tree can be empty or non-empty
•  A non-empty tree has a distinguished node called the
   root
•  Every node in the tree points to zero or more subtrees
   ‣  We call these pointers directed edges
   ‣  The “pointing” node is called a parent node
   ‣  The “pointed to” node is called a child node
•  Every node in the tree has exactly one parent, except
   the root which has no parents
---
Tree Vocabulary List
•  tree                   •  sibling
• node                    •  ancestor
•  root                   • descendant
•  leaf                   •  path
•  internal node          • depth
•  child                  •  height
• parent                  •  binary tree
                          •  n-ary tree
                         58
---
Binary Trees
• Binary trees: trees where each node has a
   maximum of 2 children
•  We call these children the left child and right child
     struct   BinaryTreeNode    {
        int  data;
        BinaryTreeNode    *left, *right;
     };
                        A
                  B           C
               left child  right child
                        59
---
     Binary Tree Traversals
In-Order                    Pre-Order                    Post-Order
   ‣  Handle empty tree        ‣  Handle empty tree         ‣  Handle empty tree
   ‣  Visit left subtree       ‣  Visit current node        ‣  Visit left subtree
   ‣  Visit current node       ‣  Visit left subtree        ‣  Visit right subtree
   ‣  Visit right subtree      ‣  Visit right subtree       ‣  Visit current node
    Visiting Order:               Visiting Order:              Visiting Order:
    DBEAFCG                           ABDECFG                      DEBFGCA
                                         A
                               B                 C
                         D         E        F         G
                                       60
---
    Binary Tree Traversals
In-Order                  Pre-Order                  Post-Order
  ‣  Handle empty tree       ‣  Handle empty tree       ‣  Handle empty tree
  ‣  Visit left subtree      ‣  Visit current node      ‣  Visit left subtree
  ‣  Visit current node      ‣  Visit left subtree      ‣  Visit right subtree
  ‣  Visit right subtree     ‣  Visit right subtree     ‣  Visit current node
 •  In-order, pre-order, and post-order traversals are all types
    of depth-first traversal
    ‣ Go as deep into tree as possible before backtracking
                                     61
---
Breadth-First Traversal
• A breadth-first traversal    first visits the root, then all
   nodes at depth 1 from left-to-right, then all nodes at
   depth 2…
   ‣ Also called a level-order traversal
                              A
                      B              C
                 D       E       F       G
                  Order: A, B, C, D, E, F, G
                              62
---
Binary Search Trees
•  Key idea: We will use the structure of a binary tree to
   capture information about the data in the tree
   ‣ This info will help us eﬃciently find elements
• A binary search tree (BST) is a special kind of binary
   tree that allows us to eﬃciently search for data
•  It is built on the BST invariant
                           63
---
BST Invariant
• The BST invariant is a condition that must be true
   of every node in a BST
•  Invariant: For a given node n with key k,
   ‣  All nodes with keys less than k are in n’s left subtree
   ‣  All nodes with keys greater than k are in n’s right subtree
               42                        Remember:
                                    The BST invariant is
       17            84            true of every node in
  …         …     …      …                the BST.
                            64
---
BST Operations
• We discussed a number of BST operations:
   ‣  contains
   ‣  min
   ‣  insert
   ‣  remove
•  In all of these cases, the general time complexity was
   O(n)
   ‣ Ideally, we could get O(log n) if our BST is well-balanced…
                            65
---
AVL Trees
•  AVL trees enforce the BST invariant, plus:
•  For every node in a non-empty tree, the node’s left and
   right subtrees can diﬀer in height by at most 1
   ‣ balance factor = abs(left subtree height - right subtree height)
   ‣ For all nodes in AVL tree: balance factor ≤ 1
•  Recall:
   ‣  height of empty tree = -1
   ‣  height of any leaf = 0
   ‣  height of arbitrary node = length of longest path to a leaf
                            66
---
   AVL Trees: insert
   •  AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree
                                     5
                           2               8
                      1         4       7
                           3
                                    67
---
   AVL Trees: insert
   • AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree                             6 > 5
                                   5
                          2               8
                     1        4       7
                          3
                                  68
---
   AVL Trees: insert
   • AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree                             6 < 8
                                   5
                          2               8
                     1        4       7
                          3
                                  69
---
   AVL Trees: insert
   • AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree                             6 < 7
                                   5
                          2               8
                     1        4       7
                          3
                                  70
---
   AVL Trees: insert
   •  AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree
                                     5
                           2               8
                      1         4       7
                           3         6
                                    71
---
Rebalancing after insert
•  Next: starting from inserted node, move up tree and
   find first node (if any) that is out-of-balance
                                       5
                             2                8
                      1          4        7
                            3          6
                                   72
---
Rebalancing after insert
•  Next: starting from inserted node, move up tree and
   find first node (if any) that is out-of-balance
                                       5
                             2                8
                      1          4        7
                            3          6
                                   73
---
Rebalancing after insert
•  Next: starting from inserted node, move up tree and
   find first node (if any) that is out-of-balance
                                       5
                             2                8
                      1          4        7
                            3          6
                                   74
---
Rebalancing after insert
• This is the subtree that we need to rebalance
      Next: Determine which “imbalance case”
               the subtree falls under
                         8
                    7
                  6
                         75
---
AVL Cases: Implementation
•  There are four cases for an out-of-balance node:
1.  New node was inserted into left child’s left subtree (LL)
2.  New node was inserted into right child’s right subtree (RR)
3.  New node was inserted into right child’s left subtree (RL)
4.  New node was inserted into left child’s right subtree (LR)
                                 76
---
AVL Cases
• “outside” cases are
   easier
• Handle them with a
  single rotation
                         77
---
LL Rebalancing: General Case
•  Circles are nodes, triangles are subtrees
• k₂ out of balance due to LL insertion: left subtree
   height (starting at k₁) now 2 greater than right subtree
             k₂
      k₁             Z
             Y
X
                              78
---
LL Rebalancing: General Case
•  We solve this case with a single right rotation at k₂
   because we “rotate” the nodes rightward to rebalance
             k₂                                  k₁
      k₁             Z                                  k₂
                                       X
             Y                                      Y         Z
X
                              79
---
LL Rebalancing: Complexity?
•  Had to update three pointers: original pointer to k₂,
   k₁’s right pointer, and k₂’s left pointer
•  Have to update heights of k₁ and k₂
                            O(1)!
             k₂                                   k₁
      k₁             Z                                   k₂
                                       X
             Y                                       Y         Z
X
                              80
---
  RR Case
  • The RR Case is completely symmetrical
  • Re-balance by performing a single left rotation
        k₁                                        k₂
X             k₂                           k₁               Z
         Y                            X          Y
                    Z
                                81
---
LR Case
•  k₂ out of balance due to insertion in left child's right subtree
               k₂
        k₁             Z
 X            k₃
         A          B
                                82
---
LR Case: Double Rotation
•  We solve this case with a double rotation
   ‣  Key idea: Rotate once to get tree in a “familiar” state, rotate
      again to balance
              k₂
       k₁             Z
 X           k₃
         A         B
                              83
---
   LR Case: Double Rotation
                k₂                                              k₂
        k₁               Z                               k₃              Z
 X             k₃                                 k₁            B
          A          B                      X            A
First, perform left rotation at k₁
                                      84
---
  LR Case: Double Rotation
             k₂                                        k₂
      k₁             Z                           k₃            Z
X           k₃                             k₁          B
       A         B                    X          A
                              Notice: k₂ now out of balance
                              because left child’s left subtree is
         Now what?            heavy (LL). We can solve this!
                                85
---
    LR Case: Double Rotation
                   k₂                                   k₃
              k₃           Z                   k₁             k₂
        k₁         B                      X        A       B      Z
  X           A
                                                     Balanced!
Perform right rotation at k₂
                                  86
---
LR Case: Recap
•  Recap: for LR case, we perform a double rotation
   ‣  First, perform left rotation at k₁
   ‣  Then, perform right rotation at k₂
                k₂
        k₁                Z
 X             k₃
          A           B
                                   87
---
RL Case: Mirror Image
•  Once again, the RL case is symmetric
   ‣  For out of balance node k:
      -  First perform right rotation at k->right
      -  Then perform left rotation at k
                            88
---
Finite Map ADT
•  Balanced binary search trees are often used to
   implement the finite map ADT
   ‣ Other names/variations: maps, dictionaries, associative arrays
•  Main idea: a finite map is a collection of (key, value) pairs
   • The key is what we use for lookup
   • The value is the data we want to store
                           89
---
Finite Map: Examples
•  Dictionaries
   ‣  Key is word, value is definition
•  Contact list
   ‣  Key is person’s name, value is info (phone #, address, …)
•  Hospital records
   ‣  Key is wristband number, value is patient information
• …
                            90
---
Finite Map ADT
add(KeyType key,     ValueType   val)
  ‣  Often map.add(k,v) is often expressed map[k]=v
remove(KeyType    key)
  ‣  Removes (key, value) pair from the map
lookup(KeyType    key)
  ‣  Returns the associated value
  ‣  map.lookup(k) is often expressed map[k]
reassign(KeyType key,      ValueType   val)
  ‣  Again map.reassign(k,v) is often expressed map[k]=v
                        91
---
Compression
• Compression is the process of reducing the
  number of bits needed to represent some data.
  ‣ A bit is a binary digit (i.e., 0 or 1)
                         92
---
Encoding
• Encoding is the process of converting data of one
  format into another format
   Example: Computers encode all data as binary numbers.
            How should strings be converted to 0s and 1s?
     “abracadabra”       ???
                          93
---
ASCII Encodings
                            CHAR      BINARY
                           [space]    010 0000
                              !       010 0001
                              “       010 0010
                              …
                              0       011 0000
                              1       011 0001
                              2       011 0010
                              …
                              A       100 0001
                              B       100 0010
                              C       100 0011
                              …
                              a       110 0001
                              b       110 0010
                              c       110 0011
                              …
                                   94
---
Encoding With ASCII
• Encoding  with ASCII  is easy:  just look up  the
  encoding for each character
                   “abracadabra”
    1100001110001011100101100001
    1100011110000111001001100001
         110001011100101100001
                         95
---
Decoding With ASCII
•  Break binary encoding into 7 bit pieces, look up the
   character corresponding to that encoding
     1100001110001011100101100001
           a           b           r           a
     1100011110000111001001100001
           c           a           d           a
            110001011100101100001
                 b           r           a
                            96
---
Code Trees
We can use binary trees to represent encodings!
     Code trees:
     1.  Let some tree nodes represent characters
     2.  A character’s encoding is determined by following
         the path from the root to that character’s node
          ‣  Taking a “left turn” is read as bit ‘0’
          ‣  Taking a “right turn” is read as bit ‘1’
                                 97
---
    Example: Code Tree
    For example, say we have the following encodings:
                                                            a      00
                  0            1                            b      01
                                                            c      10
      0          1              0          1
                                                            d      11
a                     b     c                    d
                                     98
---
Varying Frequencies
              Can we do better than ASCII?
•  Observation: Characters occur at diﬀerent frequencies
                                          char count
                                            a    5
           “abracadabra”                    b    2
                                            r    2
                                            c    1
                                            d    1
                                 99
---
Variable-Length Codes
   Idea: Do we really need to encode all characters
             with the same number of bits?
    ‣ That is, do we need to use a fixed-length encoding?
   Answer: No! We can use variable-length code
     ‣  Fewer bits for frequently used characters
     ‣  More bits for less frequently used characters
          This is how we achieve compression with
                the Huffman coding algorithm
                            100
---
Attempt #1: Decoding
• Decoding:
             0110010001101100
Is this a “b”?        a                         a       0
 Or the start                                   b       1
  of a “d”?
                                                r      10
                                                d      11
                                                c     100
                                101
---
Ambiguous Decoding
• This ambiguity occurs because some encodings
   form the prefix of other encodings
   ‣  e.g., b’s encoding “1” is the prefix of d’s encoding “11”
   ‣  When decoding “11”, do we decode to “b” or “d”?
                              102
---
Prefix-Free Code
• What we need is a prefix-free code
   ‣  An encoding system where no encoding    is the prefix of
      another encoding
                         a     0
                         b     10
                         r    110
                         d    1111
                         c    1110
          How do we come up with a prefix-free code?
                             103
---
Huffman Trees
•  We want a way to construct code trees where:
   ‣  The leaves correspond to characters
   ‣  More frequently occurring characters are closer to the root
•  Such a tree is called a Huffman tree
•  They are constructed using the Huffman coding
   algorithm
   ‣  Developed by David Huﬀman at MIT in 1952
      - Developed for his final paper for a course
                            104
---
Huffman Coding Algorithm
1.   Create a node for each character you want to encode. Each
     node should store two pieces of data:             “abracadabra”
    (1)  the character                                   char count
    (2)  the count of the character’s uses                 a    5
                                                           b    2
                                                           r    2
                                                           c    1
                                                           d    1
   a 5         b  2        r  2         c  1        d  1
                                 105
---
Huffman Coding Algorithm
2.  Pick the two subtrees with the lowest counts, and join them
    with a parent node.
   ‣ Assign the parent node the sum of the counts of the children
  a  5         b 2         r  2        c  1        d  1
                                106
---
Huffman Coding Algorithm
2.  Pick the two subtrees with the lowest counts, and join them
    with a parent node.
   ‣ Assign the parent node the sum of the counts of the children
                     c  1        d  1
  a  5         b 2         r  2
                                107
---
Huffman Coding Algorithm
2.  Pick the two subtrees with the lowest counts, and join them
    with a parent node.
   ‣ Assign the parent node the sum of the counts of the children
                              2
                     c  1        d  1
  a  5         b  2        r  2
                                108
---
Huffman Coding Algorithm
3.  Return the new tree to the group.
                                                2
  a  5         b  2        r  2        c  1         d  1
                                109
---
Huffman Coding Algorithm
4.  Repeat!
   ‣ Until a single tree remains.
                                                2
  a  5         b  2        r  2        c  1         d  1
                                110
---
Huffman Coding Algorithm
                    Find two minimum subtrees
                     (break ties arbitrarily)
                                                2
  a  5         b  2        r  2        c  1         d  1
                                111
---
Huffman Coding Algorithm
                    Find two minimum subtrees
                     (break ties arbitrarily)
                                              2
                         r  2        c  1        d  1
  a  5         b  2
                                112
---
Huffman Coding Algorithm
                   Join with parent that stores
                 the sum of the children’s counts
                                  4
                                              2
                         r  2        c  1        d  1
  a  5         b  2
                                113
---
Huffman Coding Algorithm
                    Find two minimum subtrees
                                    4
                                               2
  a  5        b  2         r 2         c 1         d 1
                                114
---
Huffman Coding Algorithm
                   Join with parent that stores
                 the sum of the children’s counts
                        6
                                     4
                                                2
  a  5         b  2        r  2        c  1         d  1
                                115
---
Huffman Coding Algorithm
                    Find two minimum subtrees
                        6
                                     4
                                                2
  a  5         b  2        r  2        c  1         d  1
                                116
---
Huffman Coding Algorithm
            We’re done!
          11
                        6
                                     4
                                                2
  a  5         b  2        r  2        c  1         d  1
                                117
---
Huffman Coding Algorithm
                          Label with 0’s and 1’s to get
                           encodings for all characters
          11
                1
                        6
                             1
     0                               4
                  0             0         1     2
                                           0       1
  a  5         b  2        r  2        c  1         d  1
                                118
---
Huffman Coding Algorithm
                          Label with 0’s and 1’s to get
                           encodings for all characters
          11
                1                                          a      0
                        6    1                             b      10
     0                               4                     r     110
                  0             0         1     2          d     1111
                                                           c     1110
                                           0       1
  a  5         b  2        r  2        c  1         d  1
                                119
---
Building Huffman Trees: Recap
1.  Store each character and its count in its own node.
2.  Until a single tree remains:
   ‣  Find two subtrees with minimum counts
      - Use a min-heap for best performance (we’ll learn about these soon)
   ‣  Join subtrees with a parent node that stores sum of counts
                             120
---
Huffman Tree
• We use the Huﬀman code tree to:
  ‣  Come up with the encodings for each character
  ‣  Decode encoded messages
                          121
---
CS 15: Data Structures
    Priority Queues
---
Triage
• From Wikipedia:
                        2
---
Triage
• Common example: order of treatment in emergency room
•  Treatment is not FIFO, like a typical queue
•  Rather, patients are treated in order of priority
•  Example patient priority ordering:
    1.  Require immediate, life-saving care
    2.  Need significant intervention, but life not in imminent danger
    3.  Need minimal treatment
    4.  Medical Attention will not help
                              3
---
Priority Queue ADT
•  Triage system is an example of the priority queue ADT
•  Similar operations to queues, stacks, but:
   ‣  Each element has an associated priority
   ‣  “Front of the line” is always the element with the highest priority
                           4
---
Priority Queue Examples
•  Hospital triage
•  Boarding airplanes: people who need special
   assistance, families with young children, first class, …
• Operating system task scheduler
• Many CS algorithms use priority queues
   ‣  Dijkstra’s algorithm (finding shortest paths)
   ‣  Huffman coding (compression)
   ‣  Prim’s algorithm (finding a minimum spanning tree)
•  Covid vaccine eligibility ordering
                            5
---
Priorities: Some Questions
•  How to handle items with equal priorities? Depends on
   implementation:
   ‣  Option 1: Handle items in order in which they were enqueued
   ‣  Option 2: Leave ordering undefined
•  Common confusion: when assigning priorities, do lower
   numbers have higher or lower priority?
   ‣  e.g., is 1 a higher or lower priority than 10?
   ‣  Varies by application, but must be consistent in implementation
                             6
---
Keys and Values (again)
• Again, we often use priority queues to store key/value
  pairs
   ‣ Key is used for lookup, value is the data associated with that key
• We typically compute priorities based on keys
• Sometimes, keys and values are completely separate
   ‣  e.g., key is ID #, value is a struct
• Other times, key and value share parts, or are entirely the
  same
   ‣  e.g., key and value are both AirlineCustomer struct, priority
      computed based on class (first/economy), seat #, age, special
      needs…
                            7
---
Comparing Priorities
•  Any priority queue needs a comparison function C
   ‣  Given two elements, returns a boolean based on priority order
   ‣  Sometimes called a comparator
• When comparing ints, C is simple: just use ≤ (or ≥)
• Otherwise, may need to define our own C
   ‣  e.g., function that compares two airline customers based on
      fares paid, frequent flyer status, time of check-in, etc.
   ‣  e.g., function that compares HuffmanTreeNodes based on
      frequency
                             8
---
Priority Queues
•  A PQ is just a container that allows us to find the next
   most important value
• Highest priority can be minimum or maximum key
•  For today, we’ll use minimum
   ‣  So, a container that allows us to only access the minimum
      element
                         9
---
Priority Queue ADT
insert(key, value)
minElement()
   ‣  Returns the value in the PQ corresponding to minimum key
   ‣  Sometimes called top()
minKey()
   ‣  Returns the minimum key in the PQ
removeMin()
   ‣  Sometimes called pop()
size()
isEmpty()
                              10
---
Example: Using a Priority Queue
•  We’ll depict the PQ as a set:
     Operation     Result                 PQ State
                                            {  }
                                11
---
Example: Using a Priority Queue
•  We’ll depict the PQ as a set:
     Operation     Result                 PQ State
                                            {  }
   insert(5, A)       -                   {(5,A)}
                                12
---
Example: Using a Priority Queue
•  We’ll depict the PQ as a set:
     Operation     Result                 PQ State
                                            {   }
   insert(5,  A)      -                   {(5,A)}
   insert(9,  C)      -                {(5,A),  (9,C)}
                                13
---
Example: Using a Priority Queue
•  We’ll depict the PQ as a set:
     Operation     Result                 PQ State
                                            {   }
   insert(5,  A)      -                   {(5,A)}
   insert(9,  C)      -                {(5,A),  (9,C)}
   insert(3,  B)      -            {(5,A), (9,C), (3,B)}
                                14
---
Example: Using a Priority Queue
•  We’ll depict the PQ as a set:
     Operation     Result                 PQ State
                                            {   }
   insert(5,  A)      -                   {(5,A)}
   insert(9,  C)      -                {(5,A),  (9,C)}
   insert(3,  B)      -            {(5,A), (9,C), (3,B)}
   insert(7,  D)      -         {(5,A), (9,C),  (3,B), (7,D)}
                                15
---
Example: Using a Priority Queue
•  We’ll depict the PQ as a set:
     Operation     Result                 PQ State
                                            {   }
   insert(5, A)       -                   {(5,A)}
   insert(9, C)       -                {(5,A),  (9,C)}
   insert(3, B)       -            {(5,A), (9,C), (3,B)}
   insert(7, D)       -         {(5,A), (9,C),  (3,B), (7,D)}
   minElement()       B         {(5,A), (9,C),  (3,B), (7,D)}
                                16
---
Example: Using a Priority Queue
•  We’ll depict the PQ as a set:
     Operation     Result                 PQ State
                                            {   }
   insert(5, A)       -                   {(5,A)}
   insert(9, C)       -                {(5,A),  (9,C)}
   insert(3, B)       -            {(5,A), (9,C), (3,B)}
   insert(7, D)       -         {(5,A), (9,C),  (3,B), (7,D)}
   minElement()       B         {(5,A), (9,C),  (3,B), (7,D)}
     minKey()         3         {(5,A), (9,C),  (3,B), (7,D)}
                                17
---
Example: Using a Priority Queue
•  We’ll depict the PQ as a set:
     Operation     Result                 PQ State
                                            {   }
   insert(5, A)       -                   {(5,A)}
   insert(9, C)       -                {(5,A),  (9,C)}
   insert(3, B)       -            {(5,A),  (9,C), (3,B)}
   insert(7, D)       -         {(5,A), (9,C),  (3,B), (7,D)}
   minElement()       B         {(5,A), (9,C),  (3,B), (7,D)}
     minKey()         3         {(5,A), (9,C),  (3,B), (7,D)}
   removeMin()        -            {(5,A),  (9,C), (7,D)}
                                18
---
Example: Using a Priority Queue
•  We’ll depict the PQ as a set:
     Operation     Result                 PQ State
                                            {   }
   insert(5, A)       -                   {(5,A)}
   insert(9, C)       -                {(5,A),  (9,C)}
   insert(3, B)       -            {(5,A),      (9,C), (3,B)}
   insert(7, D)       -         {(5,A), (9,C),  (3,B), (7,D)}
   minElement()       B         {(5,A), (9,C),  (3,B), (7,D)}
     minKey()         3         {(5,A), (9,C),  (3,B), (7,D)}
   removeMin()        -            {(5,A),      (9,C), (7,D)}
      size()          3            {(5,A),      (9,C), (7,D)}
                                19
---
Example: Using a Priority Queue
•  We’ll depict the PQ as a set:
     Operation     Result                 PQ State
                                            {   }
   insert(5, A)       -                   {(5,A)}
   insert(9, C)       -                {(5,A),  (9,C)}
   insert(3, B)       -            {(5,A),      (9,C), (3,B)}
   insert(7, D)       -         {(5,A), (9,C),  (3,B), (7,D)}
   minElement()       B         {(5,A), (9,C),  (3,B), (7,D)}
     minKey()         3         {(5,A), (9,C),  (3,B), (7,D)}
   removeMin()        -            {(5,A),      (9,C), (7,D)}
      size()          3            {(5,A),      (9,C), (7,D)}
   minElement()       A            {(5,A),      (9,C), (7,D)}
                                20
---
Example: Using a Priority Queue
•  We’ll depict the PQ as a set:
     Operation     Result                 PQ State
                                            {   }
   insert(5, A)      -                    {(5,A)}
   insert(9, C)      -                 {(5,A),  (9,C)}
   insert(3, B)      -             {(5,A),      (9,C), (3,B)}
   insert(7, D)      -          {(5,A), (9,C),  (3,B), (7,D)}
   minElement()      B          {(5,A), (9,C),  (3,B), (7,D)}
     minKey()        3          {(5,A), (9,C),  (3,B), (7,D)}
   removeMin()       -             {(5,A),      (9,C), (7,D)}
      size()         3             {(5,A),      (9,C), (7,D)}
   minElement()      A             {(5,A),      (9,C), (7,D)}
   removeMin()       -                 {(9,C),  (7,D)}
   removeMin()       -                    {(9,C)}
   removeMin()       -                      {   }
    isEmpty()       TRUE                    {   }
                                21
---
Implementation
•  As with other ADTs, we have choices for underlying
   implementation:
   ‣  Lists (ArrayList or Linked List)
   ‣  Binary search tree (balanced or unbalanced)
   ‣  Other choices?
                            22
---
Implementation Complexities
•  Provide the Big O time complexities for each PQ
   operation for the following implementation choices:
                              insert     minElement     removeMin
       Unordered array list
        Ordered array list
       Ordered linked list
          General BST
         Balanced BST
                                   23
---
Implementation Complexities
• Answers:
                                  insert       minElement        removeMin
       Unordered array list        O(1)             O(n)             O(n)
        Ordered array list
        Ordered linked list
           General BST
          Balanced BST
                                        24
---
Implementation Complexities
• Answers:
                                   insert        minElement        removeMin
       Unordered array list         O(1)             O(n)             O(n)
        Ordered array list          O(n)             O(1)             O(1)
        Ordered linked list
           General BST
          Balanced BST
                                         25
---
Implementation Complexities
• Answers:
                                    insert        minElement        removeMin
        Unordered array list         O(1)             O(n)              O(n)
         Ordered array list          O(n)             O(1)              O(1)
        Ordered linked list          O(n)             O(1)              O(1)
           General BST
           Balanced BST
                                          26
---
Implementation Complexities
• Answers:
                                    insert        minElement        removeMin
        Unordered array list         O(1)             O(n)              O(n)
         Ordered array list          O(n)             O(1)              O(1)
        Ordered linked list          O(n)             O(1)              O(1)
           General BST               O(n)             O(n)              O(n)
           Balanced BST
                                          27
---
Implementation Complexities
• Answers:
                                    insert        minElement        removeMin
        Unordered array list         O(1)             O(n)              O(n)
         Ordered array list          O(n)             O(1)              O(1)
        Ordered linked list          O(n)             O(1)              O(1)
           General BST               O(n)             O(n)              O(n)
           Balanced BST            O(log n)         O(log n)          O(log n)
                                          28
---
Array of Queues
•  If we know exactly how many priority levels there are,
   we can implement a PQ as an array of queues
   ‣  Each array index represents one priority level
   ‣  Each queue contains elements at that priority
                            29
---
Array of Queues
• e.g., recall the priorities in our hospital triage system:
    1.  Require immediate, life-saving care
    2.  Need significant intervention, but life not in imminent danger
    3.  Need minimal treatment
    4.  Medical Attention will not help
•  We can represent this PQ as an array of queues:
           Priority 1     (Mo, Alice)
           Priority 2       (Bob)
           Priority 3   (Carol, Fran, Dio)
           Priority 4        ( )
                               30
---
Array of Queues
• Time complexity
                        31
---
Array of Queues
• Time complexity
  ‣ insert
                         31
---
Array of Queues
• Time complexity
   ‣  insert
      - Access correct queue: O(1)
                            31
---
Array of Queues
• Time complexity
  ‣  insert
     -  Access correct queue: O(1)
     -  Insert into queue: O(1)
                              31
---
Array of Queues
• Time complexity
  ‣  insert
     -  Access correct queue: O(1)
     -  Insert into queue: O(1)
     -  Total: O(1)
                              31
---
Array of Queues
• Time complexity
  ‣  insert
     -  Access correct queue: O(1)
     -  Insert into queue: O(1)
     -  Total: O(1)
  ‣  minElement
                              31
---
Array of Queues
• Time complexity
  ‣  insert
     -  Access correct queue: O(1)
     -  Insert into queue: O(1)
     -  Total: O(1)
  ‣  minElement
     -  Find first non-empty queue: O(# priority levels)
                              31
---
Array of Queues
• Time complexity
  ‣  insert
     -  Access correct queue: O(1)
     -  Insert into queue: O(1)
     -  Total: O(1)
  ‣  minElement
     -  Find first non-empty queue: O(# priority levels)
     -  Get front of queue: O(1)
                              31
---
Array of Queues
• Time complexity
  ‣  insert
     -  Access correct queue: O(1)
     -  Insert into queue: O(1)
     -  Total: O(1)
  ‣  minElement
     -  Find first non-empty queue: O(# priority levels)
     -  Get front of queue: O(1)
     -  Total: O(# priority levels)
                              31
---
Array of Queues
• Time complexity
  ‣  insert
     -  Access correct queue: O(1)
     -  Insert into queue: O(1)
     -  Total: O(1)
  ‣  minElement
     -  Find first non-empty queue: O(# priority levels)
     -  Get front of queue: O(1)
     -  Total: O(# priority levels)
  ‣  removeMin: O(# priority levels) (similar analysis as above)
                              31
---
Array of Queues
• Time complexity
   ‣ insert
     -  Access correct queue: O(1)
     -  Insert into queue: O(1)
     -  Total: O(1)
   ‣ minElement
     -  Find first non-empty queue: O(# priority levels)
     -  Access front of queue: O(1)
     -  Total: O(# priority levels)
   ‣ removeMin: O(# priority levels) (similar analysis as above)
•  If we know # priority levels in advance, and it is small,
   this is a good choice!
                                 32
---
Another Option: Heaps
•  Another choice is the heap data structure
•  Asymptotically similar to BSTs, but can work very
   well in practice
                          33
---
Heaps
---
Implementing priority queues
Sequence Type insertItem(k,e) minElement()  removeMin()
Unordered List     O(1)          O(n)         O(n)
Ordered List       O(n)          O(1)         O(1)
BST            O(log n) to O(n)  O(log n) to O(n) O(log n) to O(n)
---
Implementing priority queues
 • Today, we see heaps, a data structure that is
  very effective for implementing PQs
 • Note: the “heap” data structure is entirely
  different from “heap” memory
---
(Binary) Heap interface
 • Two types
    – min-heap (we’ll look at these)
    – max-heap
---
(Binary) Heap interface
 • Two types
    – min-heap (we’ll look at these)
    – max-heap
 • Operations:
    – insert(key, value)
    – minElement()
    – removeMin()
    – isEmpty()
    – size()
    – minKey()
---
(Binary) Heap invariants
 • A binary heap is a binary tree that satisfies
  two invariants:
   1. Shape property
   2. Heap property
---
 1. Shape Property (invariant)
  • A binary tree follows the shape property if and
   only if it is a complete binary tree:
     – Each level is full, except possibly the last
     – Lowest level fills from the left
                              5
                         10        8
                       12   11   14    13
                    22  43  18
Note: Just showing keys and leaving out values.
---
2. Heap Property (invariant)
• The heap property:
   ‣Parents have higher priority than their
    children.
     - For min-heap, parent key is less than any
      child key
     - For max-heap, parent key is greater than any
      child key
   ‣Order between children does not matter
                NOT A BST!!!
---
Examples
            Min Heap                                Max Heap
                5                                       50
          10           8                           19          36
       12     11   14      13                   17     3    25      1
     22    43                                 2     7
---
Heaps are not BSTs!
 • No implied ordering between siblings
 • Both min-heaps:
         5              5
      10     12     12     10
---
A note about shapes
                             •Note: there are 9 nodes in the left tree
              5              •Every heap with 9 nodes will have this
        10          8          shape
                             •If a 10th node is added, the new tree will
     12     11   14     13     always have the same shape (see 18 below)
  22    43
                                                     5
                                               10          8
                                            12    11    14     13
                                         22  43  18
---
Important: All heaps of size N have
the same shape.
Comes from shape property: tree
must be complete.
Therefore, all 9-node heaps look
alike in shape!
---
What is the best way to store a heap?
                                         5
                                   10          8
                                12    11   14      13
                             22   43
        Could use nodes and pointers…
        Or instead, we can use a data structure that
        provides constant-time access to elements:
        array list!
---
Representing a heap with an array
 •Put root at position 1 instead of                                    5
   position 0 (to make math a bit easier)                        10          8
 • Store nodes in array in level-order                        12    11    14     13
 •Data member for current size                             22   43
      5   10    8   12 11 14      13 22 43
 [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9] [10] [11] [12] [13] [14] [15]
currentSize:     9
---
Representing a heap with an array                                    5
• For an element at position        i:                         10          8
      A. left child is at:      2i                          12     11   14     13
      B. right child is at: 2i + 1                       22   43
      C. parent is at:          ⌊i / 2⌋
      5   10    8   12 11 14      13 22 43
 [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9] [10] [11] [12] [13] [14] [15]
currentSize:     9
---
Practice Questions
You are given the following array representing a
heap: [X, 2, 4, 16, 7, 9, 64, 51, 42, 23, 72]
Note that the X represents an unused index.
1. What is the parent of node 9?
2. What are the children of node 9?
3. Draw the tree for this array.
4. Given any arbitrary array representing a complete
tree of size S, what is the position of the last (i.e.,
rightmost, lowest), non-leaf node in the tree?
---
Popular exam questions
• Given tree, write array
• Given array, draw tree
• Identify parent, left child, right child of given element
---
Heap Operations
•Recall 3 main priority queue operations. For priority queue P
 (implemented with heap h):
    1.minElement(): return value of h with the smallest key.
    2.insertItem(k,      e): insert an element e with key k into h.
    3.removeMin(): removes the smallest element from h.
(1 and 3 could be maxElement() and removeMax())
---
Heap Operations: minElement()
                                    5
                            10               8
                       12        11      14        13
                   22     43
---
 Heap Operations: minElement()
• O(1) operation: just return h[1]
                                     5
                             10               8
                        12        11      14        13
                    22     43
---
 Heap Operations: minElement()
• O(1) operation: just return h[1]
                                     5
                             10               8
                        12        11      14        13
                    22     43
  What about insertion and removal?
---
       Heaps: The meta-algorithm
For all heap algorithms that modify data structure,
ALWAYS
1. (Re)establish shape property first, ignoring the
  heap property
2. (Re)establish heap property, without disrupting
  shape property
3. Be sure to update heap size as appropriate
---
Heap Operations: insertItem(k,                                     e)
How might we go about
inserting into a binary heap?
    insert(9,                e)
             ?                                                5
                                                      10               8
                                                  12       11      14         13
                                              22     43
---
  Heap Operations: insertItem(k,                  e)
  How might we go about
  inserting into a binary heap?
     insert(9,         e)
           ?                                   5
                                         10           8
                                      12     11   14      13
                                   22   43
Start by putting the element here to maintain shape property!
What array index is this?
---
Heap Operations: insertItem(k,e)
---
Heap Operations: insertItem(k,e)
1. Insert item at element h[heapSize + 1]
 (probably destroying the heap property)
---
Heap Operations: insertItem(k,e)
1. Insert item at element h[heapSize + 1]
 (probably destroying the heap property)
2. Increment heap size
---
Heap Operations: insertItem(k,e)
1. Insert item at element h[heapSize + 1]
 (probably destroying the heap property)
2. Increment heap size
3. Bubble up/up-heap until you get to root:
   a. Compare the inserted element with its parent
    — if in correct order, stop
   b. If not, swap and up-heap from parent.
 See animation at: http://www.cs.usfca.edu/
 ~galles/visualization/Heap.html
---
Heap Operations: insertItem(k,                                     e)
insert(9, e):                            5
                                10                8
                            12       11      14         13
                        22     43
---
Heap Operations: insertItem(k,                                     e)
insert(9, e):                            5
                                10                8
                            12       11      14         13
                        22     43     9
---
Heap Operations: insertItem(k,                                     e)
insert(9, e):                            5
                                10                8
                            12       11      14         13
                        22     43     9
---
Heap Operations: insertItem(k,                                     e)
insert(9, e):                            5
                                10                8
                            12        9      14         13
                        22     43    11
---
Heap Operations: insertItem(k,                                     e)
insert(9, e):                            5
                                10                8
                            12        9      14         13
                        22     43    11
---
Heap Operations: insertItem(k,                                     e)
insert(9, e):                            5
                                9                 8
                            12       10      14         13
                        22     43    11
---
Heap Operations: insertItem(k, e)
 insertItem(k,  e)
 worst case complexity:
---
Heap Operations: insertItem(k, e)
 insertItem(k,  e)
 worst case complexity: O(log n)
---
Heap Operations: insertItem(k,  e)
 insertItem(k,    e)
 worst case complexity: O(log n)
 average complexity: provably O(1)!!
 (see: http://ieeexplore.ieee.org/xpls/
 abs_all.jsp?arnumber=6312854)
---
Heap Operations: removeMin()
   How are we going to
   implement removeMin()?
                                                   5
                                           9                8
                                      12       10      14         11
                                  22     43    13
---
Heap Operations: removeMin()
---
Heap Operations: removeMin()
1. Remove root (save for later return)
 maintain shape: replace root with last element in array
---
Heap Operations: removeMin()
1. Remove root (save for later return)
 maintain shape: replace root with last element in array
2. Decrement size
---
Heap Operations: removeMin()
1. Remove root (save for later return)
 maintain shape: replace root with last element in array
2. Decrement size
3. Bubble-down/down-heap the new root:
   a. Compare the root with its children, if in correct order, stop.
   b. If not, swap with smallest child, and bubble down from there.
   c. Be careful to check whether the children exist (if right exists,
     left must…)
---
Heap Operations: removeMin()
                                         5
                                 9                8
                            12       10      14         11
                        22     43    13
---
Heap Operations: removeMin()
                   5
                                 9                8
                            12       10      14         11
                        22     43    13
---
Heap Operations: removeMin()
                                 9                8
                            12       10      14         11
                        22     43    13
---
Heap Operations: removeMin()
                                        13
                                 9                8
                            12       10      14         11
                        22     43
---
Heap Operations: removeMin()
                                        13
                                 9                8
                            12       10      14         11
                        22     43
---
Heap Operations: removeMin()
                                        8
                                 9               13
                            12       10      14         11
                        22     43
---
Heap Operations: removeMin()
                                        8
                                 9               13
                            12       10      14         11
                        22     43
---
Heap Operations: removeMin()
                                        8
                                 9               11
                            12       10      14         13
                        22     43
---
Heap Operations: removeMin()
                                        8                       Big O?
                                 9               11
                            12       10      14         13
                        22     43
---
Heap Operations: removeMin()
                                        8                       Big O?
                                 9               11              O(log n)
                            12       10      14         13
                        22     43
---
Recap: Heap operations
•minElement: O(1)
•insert: O(log n) (but on average: O(1))
•remove: O(log n)
---
What is the best method for building a heap
from scratch (buildHeap())?
       14, 9, 13, 43, 10, 8, 11, 22, 12
---
What is the best method for building a heap
from scratch (buildHeap())?
       14, 9, 13, 43, 10, 8, 11, 22, 12
We could insert each in turn, e.g., insert(14),
then insert(9), then insert(13), then…
---
What is the best method for building a heap
from scratch (buildHeap())?
       14, 9, 13, 43, 10, 8, 11, 22, 12
We could insert each in turn, e.g., insert(14),
then insert(9), then insert(13), then…
 Insertion takes O(log n), doing it n times
 Total worst-case complexity: O(n log n)
---
There is a better way: heapify!
      14, 9, 13, 43, 10, 8, 11, 22, 12
---
There is a better way: heapify!
      14, 9, 13, 43, 10, 8, 11, 22, 12
1. Insert all elements into an array
   representing a binary tree in original
   order
---
There is a better way: heapify!
      14, 9, 13, 43, 10, 8, 11, 22, 12
1. Insert all elements into an array
   representing a binary tree in original
   order
• Notice:
    – Shape property is satisfied
    – All leaves already satisfy heap property
    (easy: they have no children!)
---
There is a better way: heapify!
      14, 9, 13, 43, 10, 8, 11, 22, 12
1. Insert all elements into an array
   representing a binary tree in original
   order
• Key Idea: To make non-leaves satisfy
  heap property, perform down-heap on
  every non-leaf node, starting with the
  last (lowest, furthest right) non-leaf
---
Question: What is the array index of the
last (lowest, furthest right) non-leaf node?
---
Question: What is the array index of the
last (lowest, furthest right) non-leaf node?
Answer: index current_size/2
   – Last leaf is at index current_size
   – Parent of any node is at node_index/2
---
There is a better way: heapify!
      14, 9, 13, 43, 10, 8, 11, 22, 12
1. Insert all elements into an array
  representing a binary tree in original
  order
2. Starting at index current_size/2 and
  moving backwards, perform down-heap
  on every non-leaf node
---
          14, 9, 13, 43, 10, 8, 11, 22, 12
       14    9   13 43 10       8   11 22 12
   [0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9] [10] [11] [12] [13] [14] [15]
     loop down:                        14
i  = heapSize        /  2        9            13
 heapSize ==         9,      43      10     8       11
       i   ==   4         22    12
---
       14, 9, 13, 43, 10, 8, 11, 22, 12
    14    9   13 43 10       8   11 22 12
[0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9] [10] [11] [12] [13] [14] [15]
       i  ==   4                    14
                              9            13
                          43      10     8       11
                       22    12
---
       14, 9, 13, 43, 10, 8, 11, 22, 12
    14    9   13 12 10       8   11 22 43
[0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9] [10] [11] [12] [13] [14] [15]
                                    14
                              9            13
                          12      10     8       11
                       22    43
---
       14, 9, 13, 43, 10, 8, 11, 22, 12
    14    9   13 12 10       8   11 22 43
[0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9] [10] [11] [12] [13] [14] [15]
       i  ==   3                    14
                              9            13
                          12      10     8       11
                       22    43
---
       14, 9, 13, 43, 10, 8, 11, 22, 12
    14    9   13 12 10       8   11 22 43
[0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9] [10] [11] [12] [13] [14] [15]
       i  ==   3                    14
                              9            13
                          12      10     8       11
                       22    43
---
       14, 9, 13, 43, 10, 8, 11, 22, 12
    14    9    8   12 10 13      11 22 43
[0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9] [10] [11] [12] [13] [14] [15]
       i  ==   2          ok  9     14      8
                          12      10    13       11
                       22    43
---
       14, 9, 13, 43, 10, 8, 11, 22, 12
    14    9    8   12 10 13      11 22 43
[0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9] [10] [11] [12] [13] [14] [15]
       i  ==   1                    14
                              9             8
                          12      10    13       11
                       22    43
---
       14, 9, 13, 43, 10, 8, 11, 22, 12
     8    9   14 12 10 13        11 22 43
[0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9] [10] [11] [12] [13] [14] [15]
                                    8         continue down-heaping
                              9            14
                          12      10    13       11
                       22    43
---
       14, 9, 13, 43, 10, 8, 11, 22, 12
     8    9   11 12 10 13        14 22 43
[0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9] [10] [11] [12] [13] [14] [15]
                                    8
                              9            11
                          12      10    13       14
                       22    43
---
       14, 9, 13, 43, 10, 8, 11, 22, 12
     8    9   11 12 10 13        14 22 43
[0]  [1]  [2]  [3]  [4]  [5]  [6]  [7]  [8]  [9] [10] [11] [12] [13] [14] [15]
                                    8
                              9            11
                          12      10    13       14
                       22    43
 Total time complexity: O(n). Magic!
 (proof in CS 160)
---
Readings
1. http://en.wikipedia.org/wiki/Binary_heap (excellent)
2.http://www.cs.usfca.edu/~galles/visualization/Heap.html (excellent
  visualization)
3.Another explanation online: http://www.cs.cmu.edu/~adamchik/15-121/
  lectures/Binary%20Heaps/heaps.html (excellent)
4.A great online explanation of asymptotic complexity of a heap:
  http://www.cs.umd.edu/~meesh/351/mount/lectures/lect14-heapsort-
  analysis-part.pdf
5. YouTube video with more detail and math: https://www.youtube.com/
  watch?v=B7hVxCmfPtM (excellent, mostly max heaps)
---
References
  http://en.wikipedia.org/wiki/Binary_heap
---
CS 15: Data Structures
       Queues
---
What is a Queue?
•  It’s simple: a queue is a line
   ‣  Or, if you’re British: a queue is a queue
   ‣  Elements are added at the back, taken from the front
                             2
---
What is a Queue?
•  It’s simple: a queue is a line
   ‣  Or, if you’re British: a queue is a queue
   ‣  Elements are added at the back, taken from the front
• Examples
   ‣  Waiting in line to buy a coﬀee
   ‣  Customer service queue
   ‣  A printer queue on a network
   ‣ …
                             3
---
What is a Queue?
• We often refer to queues as first in, first out or FIFO
                          4
---
The Queue ADT
• What operations does a queue have?
  ‣ enqueue(ElemType     element)
  ‣ -   Adds element to back              That’s it!
     dequeue()
     -  Removes element from front
     -  Depending on implementation: may or may not return the element
  ‣ isEmpty()
  ‣ size()
  ‣ peek()   (sometimes called front or top)
     -  Returns front element (without dequeueing)
                            5
---
The Queue ADT
enqueue(ElemType element)
dequeue()
isEmpty()
size()
peek() (sometimes called front or top)
              Notice: no operations for
            accessing/adding/removing
               any data in the middle
                         6
---
Example: Restaurant
Queue<Customer> CustomerQueue;
Queue<Order> OrderQueue;
                              7
---
Example: Restaurant
Queue<Customer> CustomerQueue;
Queue<Order> OrderQueue;
Order Taker Program:
while (store is open)
    if !CustomerQueue.isEmpty()
        curr_customer = CustomerQueue.dequeue()
        order = takeOrder(curr_customer)
        OrderQueue.enqueue(order)
                              8
---
Example: Restaurant
Queue<Customer> CustomerQueue;
Queue<Order> OrderQueue;
Order Taker Program:
while (store is open)
    if !CustomerQueue.isEmpty()
        curr_customer = CustomerQueue.dequeue()
        order = takeOrder(curr_customer)
        OrderQueue.enqueue(order)
Cook Program:
while (store  is open)
    if !OrderQueue.isEmpty()
        order = OrderQueue.dequeue()
        meal  = prepareMeal(order)
        deliverToCustomer(meal)
                              9
---
Implementing Queues
• We saw the operations. How do we implement them?
•  We know two data structures which could naturally be
   used to implement queues
   ‣  Linked Lists
   ‣  ArrayLists
          Which is more appropriate for a queue?
                          10
---
Implementing Queues
• We saw the operations. How do we implement them?
•  We know two data structures which could naturally be
   used to implement queues
   ‣  Linked Lists
   ‣  ArrayLists
           Which is more appropriate for a queue?
              If speed is a concern: Linked Lists!
   ‣          (assuming we have a back pointer)
   ‣   Linked list: pushAtBack and popFromFront both O(1)
       ArrayList: popFromFront is O(n)
                            11
---
Implementing Queues
class OrderQueue
{
public:
    OrderQueue() {}
    void enqueue(Order order)
    {   queue.pushAtBack(order);  Side note: notice the Queue constructor
    }                            doesn’t need to initialize the LinkedList.
    Order dequeue()                  For member variables of some class
    {                                 type (e.g., LinkedList<Order>),
        Order result = queue.elementAt(0);
        queue.popFromFront();           if we don’t explicitly initialize it,
        return result;              the default constructor of the class
    }                                  will be automatically called.
    int size()
    {
        return queue.size();
    }
    //  ...
private:
    LinkedList<Order> queue;
};
                                 12
---
Queues vs. Lists
• Isn’t a Queue just a restricted version of a List?
                        13
---
Queues vs. Lists
•  Isn’t a Queue just a restricted version of a List?
• Yes! That is why they are useful!
   ‣  Humans are error-prone
   ‣  As programs grow, get more complex, restrictions are valuable
•  This is yet another example of an abstraction barrier
   ‣  Instead of giving the programmer the full functionality of a List
      (which is too powerful for many purposes), we give them the
      more restricted Queue operations
                             14
---
CS 15: Data Structures
         Sets
---
Sets
•  A very simple ADT: Unordered, duplicate-free collection
   of elements
• Unordered
   ‣  { 4, 7, 17 } is the same set as { 7, 17, 4 }
•  Duplicate-free
   ‣  No such set as { 4, 4, 7, 17 } (either an error, or this just reduces
      to { 4, 7, 17 }, depending on implementation)
                             2
---
Set ADT: Basic Operations
void add(ElemType element)
void remove(ElemType element)
int size()
bool contains(ElemType element)
                    3
---
Set ADT: Additional Operations
union
  ‣  Given two sets A and B, computes the set of all elements
     in A or B (or possibly both). Remember: duplicate-free!
  {1,2,3}.union({3,4,5})  == {1,2,3,4,5}
                     4
---
Set ADT: Additional Operations
intersection
  ‣  Given two sets A and B, computes the set of all elements
     in both A and B
      {1,2,3}.intersect({3,4,5})           == {3}
                            5
---
Set ADT: Additional Operations
subtract
   ‣ A-B is the set of elements in A but not in B
     {1,2,3}.subtract({3,4,5})            ==  {1,2}
                             6
---
Set ADT: Additional Operations
isSubset
  ‣ A is a subset of B iﬀ all elements in A are also in B
     {1,2,3}.isSubset({1,2})  == false
     {1,2}.isSubset({1,2,3})  == true
                     7
---
Sets: Examples
•  Set of students in a class
   ‣  May be interested in subsets:
      -  Who has registered but not been graded?
      -  Who has submitted HW but not been graded?
•  Users of a website/application
•  Players on a team
• …many more!
                              8
---
Sets: General Usage
•  Sets are useful when we are primarily interested in
   element membership
   ‣  i.e., modeling whether an element does or does not belong to a
      collection of values
   ‣  Notice with membership: order doesn’t matter, and you can’t
      have duplicates
                             9
---
Sets: Implementing with Lists
•  Consider using an unsorted list to implement the
   following operations:
    operation          description         ArrayList  Linked List
       add   search for element, insert if not present
     remove    search for element and remove it
      size      return number of elements in list
     contains  search for element, return true if
                   present, false otherwise
           What are the Big O time complexities
                 for ArrayLists/Linked Lists?
                                10
---
Sets: Implementing with Lists
•  Consider using an unsorted list to implement the
   following operations:
     operation             description             ArrayList  Linked List
        add    search for element, insert if not present  O(n)   O(n)
      remove      search for element and remove it
        size     return number of elements in list
      contains  search for element, return true if
                      present, false otherwise
                                                          For both:
                                                       -Search: O(n)
                                                       -Insertion: O(1)
                                                       -Overall: O(n)
                                      11
---
Sets: Implementing with Lists
•  Consider using an unsorted list to implement the
   following operations:
     operation            description             ArrayList  Linked List
        add    search for element, insert if not present  O(n)  O(n)
      remove      search for element and remove it        O(n)  O(n)
       size     return number of elements in list
     contains  search for element, return true if
                     present, false otherwise
                                       -Search: O(n)             -Search: O(n)
                                       -Removal: O(n)            -Removal: O(1)
                                          -Could also be O(1)!   -Overall: O(n)
                                       -Overall: O(n)
                                     12
---
Sets: Implementing with Lists
•  Consider using an unsorted list to implement the
   following operations:
     operation             description             ArrayList  Linked List
        add    search for element, insert if not present  O(n)   O(n)
      remove      search for element and remove it        O(n)   O(n)
        size     return number of elements in list        O(1)   O(1)
      contains  search for element, return true if
                      present, false otherwise
                                                   Assuming we have
                                                   a “size” data member
                                      13
---
Sets: Implementing with Lists
•   Consider using an unsorted list to implement the
    following operations:
      operation              description               ArrayList  Linked List
         add     search for element, insert if not present  O(n)      O(n)
       remove       search for element and remove it        O(n)      O(n)
         size    return number of elements in list          O(1)      O(1)
      contains  search for element, return true if          O(n)      O(n)
                        present, false otherwise
          ArrayLists vs. Linked Lists: same complexity!
                                         14
---
Sets: Alternative implementation
•  Notice: we could also just have add operation add to
   the underlying list no matter what
   ‣  This is an implementation-specific detail. Client doesn’t need to
      know that our underlying list includes duplicates.
• This changes add operation to O(1)
•  But: it aﬀects time of other operations!
   ‣  size: now O(n), because we have to go through and count # of
      unique elements
   ‣  remove: Need to now remove all occurrences of an element in
      underlying list.
                            15
---
Sets: Additional Operations
union(A,B)
Pseudocode:
    C =  copy of  A
    for  element  e in B:
         C.add(e)
    return C
               What is the complexity?
                  For simplicity: Assume A and B
                  each have size n, and use the
                  O(n) version of add.
                        16
---
Sets: Additional Operations
union(A,B)
Pseudocode:
    C =  copy of  A  O(n)
    for  element  e  in B: Loop runs n times Overall, loop
         C.add(e)  Remember: add is O(n)        is O(n²)
    return C O(1)
               O(n²) + O(n) + O(1) is O(n²)
                         17
---
Sets: Additional Operations
union(A,B)    O(n²)
intersection(A,B)
Pseudocode:
    C =  new  Set O(1)
    for  element e in  A: Loop runs n times
         if  B.contains(e) Remember: contains is O(n)
              C.add(e)  Remember: add is O(n)
    return   C O(1)
                     Loop is: n * (O(n) + O(n))
    Overall: O(n²)     This is O(n²) + O(n²),
                           which is O(n²)
                         18
---
Sets: Additional Operations
union(A,B)      O(n²)
intersection(A,B) O(n₂)
                                   All operations: O(n²)
subtract(A,B) O(n₂)
isSubset(A,B) O(n₂)
---
Sets: In Practice
•  In practice, sets are typically implemented using either
   binary search trees or hashes, two data structures
   we’ll be learning about soon
   ‣  Both oﬀer quick insertion/lookup
   ‣  In C++:
      -  ordered_set is implemented using binary search tree
      -  unordered_set is implemented using hash
                             20
---
CS 15: Data Structures
        Stacks
---
My Saturday Afternoon
               2
---
My Saturday Afternoon
   Started with some light reading
                                   3
---
      My Saturday Afternoon
My friend calls to talk about traffic.
                                               4
---
My Saturday Afternoon
    June asks for pets.
                                5
---
     My Saturday Afternoon
June leaves, so I take my friend off hold.
                                        6
---
My Saturday Afternoon
    Ice cream truck drives by,
  so I put my friend back on hold.
                                   7
---
My Saturday Afternoon
Resume talking to my friend.
                                     8
---
   My Saturday Afternoon
Open up to my bookmark, and keep reading.
                                9
---
Stack
• What we just saw was an example of a stack
   ‣  Elements always added to the “top” of the stack
      -  This is called a “push”
   ‣  Elements always removed from the “top” of the stack
      -  This is called a “pop”
•  The stack is a last in, first out (or LIFO) data structure
                              10
---
Example: Stack in Action
  operation                  Stack
                   11
---
Example: Stack in Action
 push(🐶)                   🐶
 operation                Stack
                 12
---
Example: Stack in Action
                            🐵
 push(🐵)                   🐶
 operation                Stack
                 13
---
Example: Stack in Action
                          🐷
                          🐵
 push(🐷)                 🐶
 operation               Stack
                14
---
Example: Stack in Action
                          🐷
                          🐵
  pop()                   🐶
 operation               Stack
                15
---
Example: Stack in Action
                          🦊
                          🐵
 push(🦊)                 🐶
 operation               Stack
                16
---
Example: Stack in Action
                          🦊
                          🐵
  pop()                   🐶
 operation               Stack
                17
---
Example: Stack in Action
                             🐵
   pop()                    🐶
 operation                 Stack
                 18
---
Example: Stack in Action
   pop()                    🐶
 operation                 Stack
                 19
---
Stack Examples
•  Classic example: spring-loaded plate/tray dispenser
   ‣  New plates added to the top
   ‣  People retrieve plates from the top
                            20
---
Stack Examples
•  A stack is useful for modeling task interruption and
   resumption
   ‣ Where we always resume with the most recently interrupted task
•  e.g., a business putting customers on hold
•  e.g., reading Wikipedia
   ‣  Start reading about one topic
   ‣  See a new topic you want to learn about, follow link
   ‣  …repeat previous step many times…
   ‣  Finish reading current topic, pick up previously paused topic
                            21
---
Stack Example: Function Calls
• Having used C++, you already know about one stack:
  the function call stack!
---
  Stack Example: Function Calls
int main()  {                       Call Stack
   int x =  5;
   foo(x+2)                         a       8
   return 0;
}
                                  bar
void foo(int x)  {           64     x       7
   int y =  x + 1;                  y       8
   int z =  bar(y);
}                                   z
                                  foo
int bar(int a) {                    x       5
   return a*a;
}
                       23         main
---
  Stack Example: Function Calls
int main()  {                       Call Stack
   int x =  5;
   foo(x+2)                         a       8
   return 0;
}
                                  bar
void foo(int x)  {           64     x       7
   int y =  x + 1;                  y       8
   int z =  bar(y);
}                                   z      64
                                  foo
int bar(int a) {                    x       5
   return a*a;
}
                       24         main
---
  Stack Example: Function Calls
int main()  {                       Call Stack
   int x =  5;
   foo(x+2)
   return 0;
}
void foo(int x)  {                  x       7
   int y =  x + 1;                  y       8
   int z =  bar(y);
}                                   z      64
                                  foo
int bar(int a) {                    x       5
   return a*a;
}
                       25         main
---
  Stack Example: Function Calls
int main()  {                       Call Stack
   int x =  5;
   foo(x+2)
   return 0;
}
void foo(int x)  {
   int y =  x + 1;
   int z =  bar(y);
}
int bar(int a) {                    x       5
   return a*a;
}
                       26         main
---
  Stack Example: Function Calls
int main()  {                       Call Stack
   int x =  5;
   foo(x+2)
   return 0;
}
void foo(int x)  {
   int y =  x + 1;
   int z =  bar(y);
}
int bar(int a) {
   return a*a;
}
                       27
---
History of the Call Stack
•  Fun fact: the idea for the call stack was     first proposed
   by Alan Turing in 1946
      “We also wish to be able to arrange for the splitting up
      of operations into subsidiary operations. This should
      be done in such a way that once we have written
      down how an operation is done we can use it as a
      subsidiary to any other operation....
      When we wish to start on a subsidiary operation we
      need only make a note of where we left off the major
      operation and then apply the first instruction of the
      subsidiary. When the subsidiary is over we look up
      the note and continue with the major operation.”
         -A. Turing, “Proposals for the development in the Mathematics
                   Division of an Automatic Computing Engine.”
                               28
---
The Stack ADT
• What operations does a stack have?
  ‣ push(ElemType element)
    -  Adds new element to the top of the stack
  ‣ pop()
    -  Removes element from top of stack
    -  Depending on implementation: may or may not return element
  ‣ isEmpty()
  ‣ size()
  ‣ peek() (sometimes called top())
    -  Returns top element (without popping)
                        29
---
Implementing a Stack
•  Like queues, it’s easy to implement the stack using a list
•  Unlike queues, there is only one “busy” end
   ‣ i.e., we add and remove elements from the same end of the list
•  If using an ArrayList: add/remove from back
•  If using a LinkedList: add/remove from front
   ‣ Or back if you have a back pointer
                            30
---
Abstraction Barrier
•  Like queues, stacks are a more restricted version of lists
•  Restrictions are powerful! They’re good!
   ‣  Force us to use data structure in a particular way
   ‣  Makes it impossible for us to make certain mistakes
                            31
---
Parenthesis Matching
•  Stacks are also useful for analyzing nested structures
•  Well-known application: parenthesis/brace/bracket
   matching
   ‣ Given a string with (, ), {, }, [, and ], is the string well-balanced?
•  Your C++ compiler does this (and much more)!
                         32
---
Parenthesis Matching
• Are the following expressions well-balanced?
()
                        33
---
Parenthesis Matching
• Are the following expressions well-balanced?
()  Balanced!
                        34
---
Parenthesis Matching
• Are the following expressions well-balanced?
()  Balanced!
{([])[(])}
                        35
---
Parenthesis Matching
• Are the following expressions well-balanced?
()  Balanced!
{([])[(])}      Not balanced!
             Notice: Any “closers” must match
           the most recent, un-matched “opener”
                             36
---
Parenthesis Matching
• Are the following expressions well-balanced?
()  Balanced!
{([])[(])}    Not balanced!
([(){}]())
                        37
---
Parenthesis Matching
• Are the following expressions well-balanced?
()  Balanced!
{([])[(])}    Not balanced!
([(){}]())    Balanced!
                        38
---
Parenthesis Matching
• Are the following expressions well-balanced?
()  Balanced!
{([])[(])}    Not balanced!
([(){}]())    Balanced!
((({})
                        39
---
Parenthesis Matching
• Are the following expressions well-balanced?
()  Balanced!
{([])[(])}      Not balanced!
([(){}]())      Balanced!
((({})    Not balanced!
    All “openers” must be matched with a “closer”
                             40
---
Parenthesis Matching
• Are the following expressions well-balanced?
()  Balanced!
{([])[(])}    Not balanced!
([(){}]())    Balanced!
((({})   Not balanced!
()]
       No “opener” to close
                         41
---
Parenthesis Matching
• Are the following expressions well-balanced?
() Balanced!
{([])[(])}   Not balanced!
([(){}]())   Balanced!
((({})  Not balanced!
()]  Not balanced!
                        42
---
Parenthesis Matching
•  We can think of this problem in the same way that
   we think about starting/interrupting/resuming tasks
   ‣  Each “opener” starts a new “task”
   ‣  Each “closer” ends the currently active “task”
      - The closer must match the current task’s opener
   ‣  At the end, all “tasks” must be ended
                               43
---
Practice Problem
Write the pseudocode for a function with header:
bool is_balanced(string expr)
The function takes a string expr as input, consisting of just (, ),
{, }, [, and ]. It returns true if the expression is well-balanced, and
false otherwise.
Your pseudocode should use a stack.
Remember, with pseudocode we are not writing actual code. So
you can write English phrases, like “read next character”, “char is
an opener/closer” or “char1 matches char2”. Just make sure the
high-level algorithm is clear!
Try “testing” your pseudocode on some sample expressions.
                             44
---
Pseudocode Solution
               45
---
     Pseudocode Solution
• Remember, this is just one solution:
bool is_balanced(string expr)
    initialize stack
    while (expr has  chars left)
        curr_char =  read_next_char(expr)
        if (curr_char is opener)
            stack.push(curr_char)
        else // curr_char must be   closer)
            if  stack.isEmpty() or  (not matches(stack.top(), curr_char))
                return false
            else
                stack.pop()
    return stack.isEmpty()
                                    46
---
Example
• Use the stack to check if expression is balanced:
{([])[(])}
                          Stack
                        47
---
Example
• Use the stack to check if expression is balanced:
{([])[(])}
                        {
                      Stack
                    48
---
Example
• Use the stack to check if expression is balanced:
{([])[(])}              (
                        {
                      Stack
                    49
---
Example
• Use the stack to check if expression is balanced:
{([])[(])}             [
                       (
                       {
                     Stack
                   50
---
    Example
    • Use the stack to check if expression is balanced:
    {([])[(])}                   [
                                 (
Matches current top of stack!    {
                               Stack
                             51
---
    Example
    • Use the stack to check if expression is balanced:
                                  Done with this subexpression,
                                             so pop()
    {([])[(])}                    [
                                  (
Matches current top of stack!     {
                               Stack
                             52
---
Example
• Use the stack to check if expression is balanced:
{([])[(])}              (
                        {
                      Stack
                    53
---
    Example
    • Use the stack to check if expression is balanced:
    {([])[(])}                   (
Matches current top of stack!    {
                               Stack
                             54
---
Example
• Use the stack to check if expression is balanced:
{([])[(])}
                        {
                      Stack
                    55
---
Example
• Use the stack to check if expression is balanced:
{([])[(])}              [
                        {
                      Stack
                    56
---
Example
• Use the stack to check if expression is balanced:
{([])[(])}             (
                       [
                       {
                     Stack
                   57
---
Example
•  Use the stack to check if expression is balanced:
{([])[(])}                        (
                                  [
        Does not match!           {
Expression is not well ballanced  Stack
                             58
---
Example #2
• Use the stack to check if expression is balanced:
([])
                          Stack
                        59
---
Example #2
• Use the stack to check if expression is balanced:
([])
                        (
                      Stack
                    60
---
Example #2
• Use the stack to check if expression is balanced:
([])                    [
                        (
                      Stack
                    61
---
    Example #2
    • Use the stack to check if expression is balanced:
    ([])                         [
Matches current top of stack!    (
                               Stack
                             62
---
    Example #2
    • Use the stack to check if expression is balanced:
    ([])
Matches current top of stack!      (
                                Stack
                              63
---
Example #2
• Use the stack to check if expression is balanced:
            Done reading expression, and stack is empty.
([])                Expression is well-balanced!
                              Stack
                            64
---
Implementation
•  Let’s see a simple implementation
   ‣ paren_matching.cpp
                         65
---
CS 15: Data Structures
 Intro to C++ Templates
---
Type-Specific Classes
•  Thus far, we have implemented data structures in C++
   that only work for one element type
   ‣  IntArrayList
   ‣  StringLinkedList
•  Say we want a linked list for a diﬀerent type
   ‣  e.g., a Person Linked List
   ‣  With current approach, need to implement entirely new class
      - With nearly identical code
                             2
---
Type-Specific Functions
• You have probably implemented some nearly identical
   functions that are type-specific
   ‣ e.g., functions for printing arrays
            void printIntArray(int data[], int length)
            {
                cout  <<  '[';
                for (int  i   =  0;  i < length; ++i) {
                          cout   <<  data[i];
                          if  (i !=   length  - 1)
                                     cout <<  ", ";
                }
                cout  <<  ']';
            }
                                     3
---
Type-Specific Functions
• You have probably implemented some nearly identical
   functions that are type-specific
   ‣ e.g., functions for printing arrays
            void printIntArray(int data[], int length)
            {
                cout  <<  '[';
                for (int  i   =  0;  i < length; ++i) {
                          cout   <<  data[i];
                          if  (i !=   length  - 1)
                                     cout <<  ", ";
                }
                cout  <<  ']';
            }
•  To handle other types, need essentially identical
   functions: printStringArray, printCharArray, …
                                     4
---
Solution: Templates!
• A template in C++ is a special kind of function or class
•  Instead of defining the function/class for a specific
   type, we define it in terms of a type variable
   ‣ The type variable is a placeholder for an actual type
•  The type variable gets instantiated with a specific type
   when we use the function/class
   ‣ Exactly like a function parameter being bound to a specific arg
                            5
---
Making Templates
• Simply add this line above the function or class:
        template <typename        YourTypeVarName>
  You can write either  Name the type variable
                    typename
    or class here. Both whatever you want, here
                     work.
                                6
---
Function Template
    template <typename ElemType>
    void printArray(ElemType  data[], int length)
    {
           cout <<  '[';
           for (int i =   0;  i < length; ++i) {
                    cout  <<  data[i];
                    if (i !=   length  - 1)
                              cout <<  ", ";
           }
           cout <<  ']';
   }
•  Now we have one function that works for int[],
   string[], char[], …
                          7
---
      Using Function Templates
template <typename    ElemType>                        int arr1[3]        = {1, 2, 3};
void printArray(ElemType data[], int length)           printArray<int>(arr1, 3);
{
        cout  <<  '[';
        for (int  i   =  0;  i < length; ++i) {
                  cout   <<  data[i];
                  if  (i !=   length  - 1)
                             cout <<  ", ";
        }
}       cout  <<  ']';                           When we call the template,
                                                         we provide the type between
                                                       < and >, after the function name
                                      In fact, C++ can often automatically determine
                                               the type from the use case…
                                               8
---
      Using Function Templates
template <typename    ElemType>                        int arr1[3]        = {1, 2, 3};
void printArray(ElemType data[], int length)           printArray<int>(arr1, 3);
{
        cout  <<  '[';
        for (int  i   =  0;  i < length; ++i) {
                  cout   <<  data[i];                  string arr2[3]          =
                  if  (i !=   length  - 1)
        }                    cout <<  ", ";            printArray{“a","b","c"};
        cout  <<  ']';                                                 (arr2, 3);
}
                                                         C++ automatically determined
                                                       we are passing in a string array
                                               9
---
Using Templates
   template <typename ElemType>
   void printArray(ElemType   data[], int length)
   {
           cout <<  '[';
           for (int i =   0;  i < length; ++i) {
                    cout  <<  data[i];
                    if (i !=   length  - 1)
                              cout <<  ", ";
           }
           cout <<  ']';
   }
Question: Can we pass in any type for ElemType? Or
            are there some restrictions?
                          10
---
Using Templates
   template <typename ElemType>
   void printArray(ElemType             data[], int length)
   {
           cout <<            '[';
           for (int           i =   0;  i < length; ++i) {
   Notice: We send values of  cout  <<  data[i];
         type ElemType        if (i !=   length  - 1)
        to cout using <<                cout <<  ", ";
           }
           cout <<            ']';
   }
• C++ must know how to print the type using <<
                                    11
---
Class Templates
•  In addition to functions, we can make class templates
•  In fact, we’ve seen an example already: vectors!
          vector<int> myNums;
          vector<string> myNames;
          vector<Person> people;
          vector<vector<int> > matrix;
                        12
---
 StringLinkedList
 •  Recall our StringLinkedList class:
class StringLinkedList
{
public:
    StringLinkedList();
    ~StringLinkedList();
   void addAtFront(std::string elem);      We can use a template, and replace
   void printLoopily();                       string with a type variable
   void printRecursive();
   …
private:
    struct Node {
        std::string data;
        Node *next;
    };
    Node *front;
    Node *newNode(std::string newData, Node *next);
    void printRecHelper(Node *curr);
    void recycleRecursive(Node *curr);
};
                                      13
---
Linked List Template
            template <typename ElemType>
            class LinkedList
            {
            public:
                LinkedList();
                ~LinkedList();
               void  addAtFront(ElemType elem);
               void printLoopily();
               void printRecursive();
                …
            private:
                struct Node {
                     ElemType data;
                     Node *next;
                };
                Node  *front;
                Node  *newNode(ElemType newData, Node *next);
                void printRecHelper(Node *curr);
                void recycleRecursive(Node *curr);
            };
                                   14
---
        Linked List Template
template <typename ElemType>
class LinkedList
{                                                              •   Every function of a template
public:
    LinkedList();
    ~LinkedList();                                                 class is also a template…
   void  addAtFront(ElemType elem);
   void  printLoopily();
   void  printRecursive();
    …
private:
    struct Node {
         ElemType data;
         Node *next;
    };
    Node  *front;
    Node  *newNode(ElemType newData, Node *next);
    void  printRecHelper(Node *curr);
    void  recycleRecursive(Node *curr);
};
                                                              15
---
        Linked List Template
          each function prefaced with
              template declaration
                                                   template    <typename ElemType>
                                                   LinkedList<ElemType>::LinkedList()
template <typename ElemType>                       {    front   =  nullptr;
class LinkedList
{                                                  }
public:
    LinkedList();
    ~LinkedList();                                 template    <typename ElemType>
   void  addAtFront(ElemType elem);                LinkedList<ElemType>::~LinkedList()
   void  printLoopily();                           {
   void  printRecursive();                              recycleRecursive(front);
    …
private:                                           }
    struct Node {
         ElemType data;                            template    <typename ElemType>
         Node *next;
    };                                             void  LinkedList<ElemType>::addAtFront(ElemType elem)
    Node  *front;                                  {
    Node  *newNode(ElemType newData, Node *next);  }    front   =  newNode(elem, front);
    void  printRecHelper(Node *curr);
    void  recycleRecursive(Node *curr);
};
                                                             16
---
        Linked List Template
     We must instantiate
               LinkedList
          when we refer to it                      template    <typename ElemType>
                                                   LinkedList<ElemType>::LinkedList()
template <typename ElemType>                       {    front   =  nullptr;
class LinkedList
{                                                  }
public:
    LinkedList();
    ~LinkedList();                                 template    <typename ElemType>
   void  addAtFront(ElemType elem);                LinkedList<ElemType>::~LinkedList()
   void  printLoopily();                           {
   void  printRecursive();                              recycleRecursive(front);
    …
private:                                           }
    struct Node {
         ElemType data;                            template    <typename ElemType>
         Node *next;
    };                                             void  LinkedList<ElemType>::addAtFront(ElemType elem)
    Node  *front;                                  {
    Node  *newNode(ElemType newData, Node *next);  }    front   =  newNode(elem, front);
    void  printRecHelper(Node *curr);
    void  recycleRecursive(Node *curr);
};
                                                             17
---
Interface/Implementation?
•  Any clients of a template must not only know what
   functions it provides (interface) but also how to
   instantiate+define them (implementation)
• What this means for you: Unfortunately, we
   cannot separate the interface and implementation
   into diﬀerent files for templates
•  For templates, place all definitions in the header file
                           18
---
Template Class Example
•  Let’s see an example:
   ‣ LinkedList.h
   ‣ ListClient.cpp
                         19
---
Terminology
• Templates allow C++ to achieve parametric
  polymorphism
  ‣  Definition: the ability to define a function or class generically so
     that it can handle values without depending on their type.
  ‣  Also known as: generic polymorphism, universal polymorphism
                             20
---
Templates: Pros and Cons
• Pro: More modular, reusable code
  ‣  This is a big win! It is good practice to “factor out” identical code
     into a single, reusable module.
• Con: Can no longer separate interface/implementation
  ‣  Everything must go in header file
  ‣  Still, this is usually worthwhile avoid code duplication
• Con: Compiler/linker error messages can be very
  verbose, confusing when using template classes
  ‣ Tip: When defining a template (e.g., ArrayList), start by defining a
      non-template class (e.g., IntArrayList). Make sure everything
      compiles/links correctly. Then, go in and change it to a template.
                              21
---
CS 15: Data Structures
        Trees
---
Until Now: Linear Data Structures
• Most of the data structures/ADTs we have seen are linear
   ‣  Lists: ArrayLists, Linked Lists
   ‣  Stacks
   ‣  Queues
•  There is a total order on the structure’s elements: a first
   element, a second element, etc.
•  Linear structures can be costly for some operations
   ‣  Find, insert, remove, …
•  Additionally, we may want to model other relationships
   ‣  e.g., hierarchical relationships
                             2
---
  Trees
  •  Similar to linked lists, but now, every node can point to
     more 1 or more other nodes
  •  Plus some additional restrictions…
               A
B     C      D     E     F           G
        H       I    J    K     L    M    N     O
                   P     Q
                             3
---
 Trees: Definition
 •  A tree can be empty or non-empty
 •  A non-empty tree has a distinguished node called the
    root                   root
              A
B     C     D     E     F           G
       H       I     J   K     L    M     N    O
                  P     Q
                            4
---
Trees: Definition
•  A tree can be empty or non-empty
•  A non-empty tree has a distinguished node called the
   root
•  Every node in the tree points to zero or more subtrees
   ‣  We call these pointers edges or directed edges
   ‣  The “pointing” node is called a parent node
   ‣  The “pointed to” node is called a child node
---
Trees: Definition
•  A is the parent of D
•  D is the child of A
•  D is the parent of H
• …                 A
     B      C     D     E     F            G
             H       I     J    K    L     M    N     O
                        P   6  Q
---
Trees: Definition
•  A tree can be empty or non-empty
•  A non-empty tree has a distinguished node called the
   root
•  Every node in the tree points to zero or more subtrees
   ‣  We call these pointers directed edges
   ‣  The “pointing” node is called a parent node
   ‣  The “pointed to” node is called a child node
•  Every node in the tree has exactly one parent, except
   the root which has no parents
---
Is this a tree?
                                       tree?
                                     8
---
Is this a tree?
                        A
                       Yes!
      A is the root node, and it has no children.
                         9
---
Is this a tree?
                        1
          17          0
                 39      100
                       Yes!
     1 is the root node, and all edges are valid.
                         10
---
Is this a tree?
                       1
                 17         0
                              100
                       No!
    There must be a distinct root with no parent
                        11
---
Is this a tree?
                       1
                 17         0
                              100
                       No!
          Every node (other than the root)
          should have exactly one parent
                        12
---
Is this a tree?
           A        B        C        D
                       Yes!
      A is the root, each node (except D) has
     just 1 child. A linked list is a simple case
                     of a tree!
                         13
---
Is this a tree?
                Ceci n’est pas une tree.
                     No!
            It has more than one root.
                      14
---
Is this a tree?
                        1
                 17         0
                               100
                       No!
         17 and 0 both have two parents.
    In general: a tree is acyclic (has no cycles).
                         15
---
Trees are Recursive
•  Notice: trees, like linked lists, are a recursive data
   structure
   ‣  Base case: the empty tree is a tree
   ‣  Recursive case: a tree is a node with pointers to zero or more
      trees
•  This will help us define recursive operations over trees
                             16
---
Trees: Examples
•  In biology, phylogenetic trees are used to show
   evolutionary relationships
   ‣ Among species, genes, …
                              credit: http://web.stanford.edu/class/cs262/presentations/lecture15.pdf
                            17
---
Trees: Example
•  Call trees
                 credit: https://www.rapidrecall.net/automated-call-tree.html
                            18
---
Trees: Examples
• Pyramid schemes
             credit: https://therubyhub.com/the-ponzi-no-one-told-you-about/
                        19
---
Trees: Examples
•   Parse trees
    ‣   Useful in both CS and linguistics
    https://www.researchgate.net/figure/Abstract-syntax-  https://en.wikipedia.org/wiki/Branching_(linguistics)
           tree-of-the-while-loop_fig1_228792639
                                               20
---
Trees: Examples
•   File systems are represented using trees
           credit: http://swcarpentry.github.io/2014-04-14-wise/novice/shell/01-filesystem.html
                                               21
---
Depicting Trees
•  We draw trees with the root at the top, and the
   leaves at the bottom
                    A
      B     C     D     E     F           G
             H       I     J   K     L    M     N    O
                        P     Q
                          22
---
Depicting Trees
•  It’s usually obvious which node is the root, and thus
   which direction each edge points in. When this is the
   case, we often omit the arrows:
                    A
      B     C     D     E     F           G
             H       I     J   K     L    M     N    O
                        P     Q
                          23
---
Depicting Trees
•  Technically, the bottom nodes point to empty trees. We
   typically leave these pointers out of our depiction.
                    A
      B     C     D     E     F           G
             H       I     J   K     L    M     N    O
                        P     Q
                          24
---
Tree Vocabulary
• A lot of vocabulary associated with trees
• We’ve already seen some:
   ‣  Root
   ‣  Parent
   ‣  Child
                            25
---
Tree Vocabulary
• A leaf node is a node with no children.
  Examples:
                    A
      B     C     D     E     F           G
             H       I     J   K     L    M     N    O
                        P     Q
                          26
---
Tree Vocabulary
• A leaf node is a node with no children.
  Examples: B, C, H, I, P, Q, K, L, M, N, O.
                    A
      B     C     D     E     F           G
             H       I     J   K     L    M     N    O
                        P     Q
                          27
---
Tree Vocabulary
• An internal node is a non-leaf.
  Examples:
                    A
      B     C     D     E     F           G
             H       I     J   K     L    M     N    O
                        P     Q
                          28
---
Tree Vocabulary
• An internal node is a non-leaf.
  Examples: A, D, E, F, G, J
                    A
      B     C     D     E     F           G
             H       I     J   K     L    M     N    O
                        P     Q
                          29
---
   Tree Vocabulary
   • A path is a sequence of nodes that follow the edges of
     a tree
Example: A, D, H
Example: E, J, Q       A
         B     C     D     E     F           G
                H       I     J   K     L    M     N    O
                           P     Q
                             30
---
   Tree Vocabulary
   • A path is a sequence of nodes that follow the edges of
     a tree
Example: A, D, H                       Not a path: D, F, O
Example: E, J, Q      A                Not a path: H, D, A
        B     C     D    E     F           G
               H       I    J   K    L    M     N    O
                         P     Q
                            31
---
Tree Vocabulary
• Node X is an ancestor of node Y iﬀ X is on the path
  from the root to Y      Example: E is an ancestor of Q
                          Example: A is an ancestor of
                   A      every other node
     B     C     D     E     F           G
             H      I    J    K    L    M     N    O
                       P     Q
                         32
---
Tree Vocabulary
•  Node X is a descendant of node Y iﬀ X is on a path
   from Y to a leaf        Example: Q is a descendant of E
                           Example: Every node is a
                    A      descendant of A
      B     C     D     E     F           G
             H       I     J   K     L    M     N    O
                        P     Q
                          33
---
Tree Vocabulary
• Two nodes are siblings if they have the same parent
  Example: I and J are siblings
                    A
      B     C     D     E     F           G
             H       I     J   K     L    M     N    O
                        P     Q
                          34
---
Tree Vocabulary
• The length of a path is the number of edges on the
  path. Not the number of nodes!
                   A   Example: Length of A, D, H is 2
     B     C     D    E     F           G
            H       I    J   K    L    M     N    O
                      P     Q
                         35
---
Tree Vocab: Height
• The height of a node is the length of the of the
  longest path from that node to a leaf
  ‣  A leaf’s height is 0
• The height of a tree is the height of the root
  ‣  An empty tree’s height is -1
                         36
---
Tree Vocabulary
The tree’s height is: 3 (longest path from root: A, E, J, Q)
Node E’s height is:  2 (longest path: E, J, Q)
Node L’s height is:  0
                     A
      B     C     D     E      F           G
              H      I     J    K    L     M    N     O
                        P      Q
                           37
---
Tree Vocab: Depth
• The depth of a node is the length of the path from the
  root down to that node
  ‣ The depth of the root is 0
                         38
---
Tree Vocabulary
Node L’s depth: 2
Node Q’s depth is: 3
Node A’s depth is: 0
                    A
      B     C     D     E     F           G
             H       I     J   K     L    M     N    O
                        P     Q
                          39
---
Trees: Special Cases
•  A tree with a maximum of two children per node is
   called a binary tree
•  A tree with a maximum of N children per node is called
   an n-ary tree
•  What is a tree with a maximum of one child per node
   called?
                         40
---
Trees: Special Cases
•  A tree with a maximum of two children per node is
   called a binary tree
•  A tree with a maximum of N children per node is called
   an n-ary tree
•  What is a tree with a maximum of one child per node
   called?
   ‣ A linked list!
                         41
---
Implementing Trees
•  Like linked lists, we’ll build trees using nodes
•  Unlike linked lists, a node may point to more than
   one other node
           struct TreeNode {
               ElementType data;
               TreeNode *child1;
               TreeNode *child2;
               TreeNode *child3;
               …
           };
        Will this node representation suffice?
                     42
---
    Implementing Tree Nodes
If we know max # children, we     If we don’t know max #
  can use separate member         children, we can store
         variables:                children in a list:
struct BinaryTreeNode {        struct TreeNode {
  ElementType data;              ElementType data;
  BinaryTreeNode  *child1;       vector<TreeNode*> children;
  BinaryTreeNode  *child2;     };
};
                        could also use linked list
                             43
---
Implementing Trees
•  Trees can be represented using a pointer to the root
   node
   ‣ Similar to keeping track of front node for linked lists
•  Empty tree represented as as nullptr
                         44
---
Practice Questions
Given the tree node struct:  struct IntTreeNode {
                             int data;
                             IntTreeNode *child1, *child2;
                           };
Implement the following operations, recursively:
1) int sum(IntTreeNode *node)
  ‣  Computes sum of all elements in tree rooted at node.
2) int size(IntTreeNode    *node)
  ‣  Computes number of elements in tree rooted at node.
3) int height(IntTreeNode     *node)
  ‣  Computes height of tree rooted at node. Recall: height(empty_tree) = -1,
     height(leaf) = 0, height(node) = length of longest path from node to leaf
4) bool contains(IntTreeNode *node,       int val)
  ‣  Returns true if tree rooted at node contains val, false otherwise
                              45
---
Trees: Example
•  Let’s implement these functions:
   ‣ int_tree_example.cpp
• Typically we would implement a tree using a class; for
  now we’ll just use a node struct
• Notice we’re using a binary tree: max 2 children/node
                          46
---
Vocabulary List
•  tree                   •  sibling
• node                    •  ancestor
•  root                   • descendant
•  leaf                   •  path
•  internal node          • depth
•  child                  •  height
• parent                  •  binary tree
                          •  n-ary tree
                         47
---
CS 15: Data Structures
      ArrayLists
---
Types, ADTs, and Data Structures
                2
---
Types, ADTs, and Data Structures
• A type is a name for a set of values
   ‣  bool: {true, false}
   ‣  int: {…, -2, -1, 0, 1, 2, … }
   ‣  char: {‘a’, ‘b’, ‘c’, …}
                             2
---
Types, ADTs, and Data Structures
• A type is a name for a set of values
   ‣  bool: {true, false}
   ‣  int: {…, -2, -1, 0, 1, 2, … }
   ‣  char: {‘a’, ‘b’, ‘c’, …}
• An abstract data type (ADT) is a model for a type
   ‣  The model tells us: what operations define the type
   ‣  Notably, an ADT is defined independently of any implementation
      -  Like an interface
                             2
---
Types, ADTs, and Data Structures
• A type is a name for a set of values
   ‣  bool: {true, false}
   ‣  int: {…, -2, -1, 0, 1, 2, … }
   ‣  char: {‘a’, ‘b’, ‘c’, …}
• An abstract data type (ADT) is a model for a type
   ‣  The model tells us: what operations define the type
   ‣  Notably, an ADT is defined independently of any implementation
      -  Like an interface
• A data structure is means of organizing and storing data
   ‣  We will use them to implement ADTs
                             2
---
Our First ADT: Lists
•  List: An ordered collection of elements
   ‣  Elements could be of any type: int, strings, animals…
               [🐶, 🐱, 🐭, 🦊, 🐵, 🐷]
   ‣  Ordered means there is a specific first, second, third, etc.
   ‣  Ordered ≠ Sorted!
•  Size: varies, can grow/shrink
• What operations do we want to perform?
                             3
---
List Operations
void addAtBack(ElementType new_element)
                   4
---
List Operations
void addAtBack(ElementType new_element)
    [🐶,🐱,🐭,🦊,🐵,🐷].addatBack(🐥)
                  ⟹
          [🐶,🐱,🐭,🦊,🐵,🐷,🐥]
                   4
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
                   5
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
    [🐶,🐱,🐭,🦊,🐵,🐷].addatFront(🐥)
                  ⟹
          [🐥,🐶,🐱,🐭,🦊,🐵,🐷]
                   5
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
int size()
                   6
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
int size()
      [🐶,🐱,🐭,🦊,🐵,🐷].size() == 6
                   6
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
int size()
void  addAt(ElementType elt, int index)
                   7
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
int size()
void  addAt(ElementType elt, int index)
      [🐶,🐱,🐭,🦊,🐵,🐷].addAt(🐥,2)
                  ⟹
          [🐶,🐱,🐥,🐭,🦊,🐵,🐷]
                   7
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
int size()
void  addAt(ElementType elt, int index)
void  removeAt(int index)
                   8
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
int size()
void  addAt(ElementType elt, int index)
void  removeAt(int index)
      [🐶,🐱,🐭,🦊,🐵,🐷].removeAt(2)
                  ⟹
            [🐶,🐱,🦊,🐵,🐷]
                   8
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
int size()
void  addAt(ElementType elt, int index)
void  removeAt(int index)
bool  isEmpty()
                   9
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
int size()
void  addAt(ElementType elt, int index)
void  removeAt(int index)
bool  isEmpty()
  [🐶,🐱,🐭,🦊,🐵,🐷].isEmpty() == false
                   9
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
int size()
void  addAt(ElementType elt, int index)
void  removeAt(int index)
bool  isEmpty()
ElementType elementAt(int index)
                   10
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
int size()
void  addAt(ElementType elt, int index)
void  removeAt(int index)
bool  isEmpty()
ElementType elementAt(int index)
  [🐶,🐱,🐭,🦊,🐵,🐷].elementAt(0) == 🐶
                   10
---
List Operations
void  addAtBack(ElementType new_element)
void  addAtFront(ElementType new_element)
int size()
void  addAt(ElementType elt, int index)
void  removeAt(int index)
bool  isEmpty()
ElementType elementAt(int index)
         …and more (if you’d like)!
                   11
---
Implementing Lists
•  Notice: the List ADT only tells us a List’s operations
   ‣ Not how the operations are implemented
•  We will study two data structures for implementing
   Lists:
   ‣ ArrayLists
   ‣ Linked Lists
                            12
---
C++ Arrays
•  Can we just use a C++ array as a List?
                   int  main()
                   {
                        int arr[10];
                        …
                        return 0;
                   }
                            13
---
C++ Arrays
•  Can we just use a C++ array as a List?
                   int  main()
                   {
                        int arr[10];
                        …
                        return 0;
                   }
• No! Recall: C++ arrays have a    fixed size
   ‣ Lists should be able to change size
                            14
---
C++ Arrays
•  Can we just use a C++ array as a List?
                   int  main()
                   {
                        int arr[10];
                        …
                        return 0;
                   }
• No! Recall: C++ arrays have a    fixed size
   ‣ Lists should be able to change size
•  But with pointers and heap-allocated arrays, we can
   eﬀectively achieve growable arrays…
                            15
---
 Arrays in Memory
int  main()               •  Recall: an array variable is
{  int *arr = new int[4];    really just a pointer to the
                             first element
   return 0;
}
                          16
---
 Arrays in Memory
int main()
{
  int *arr = new int[4];
  return 0;
}
                 IN MEMORY
       Stack                         Heap
     arr
main
                          17
---
   Arrays in Memory
int   main()                      •  Now that arr is full, what
{
   int  *arr  = new int[4];          do we do if we want to
   arr[0]  =  4;
   arr[1]  =  33;                    add more?
   arr[2]  =  24;
   arr[3]  =  -9;
}  return  0;         IN MEMORY
           Stack                              Heap
                                          4 33 24 -9
       arr
 main
                                18
---
  Arrays in Memory
•  Idea: arr is just the address of a four element array
•  Let’s reassign it to be the address of a bigger array!
                    IN MEMORY
         Stack                            Heap
                                       4 33 24 -9
       arr
  main
                             19
---
   Arrays in Memory
1.  Create an eight element array.
                       IN MEMORY
          Stack                                Heap
                                           4 33 24 -9
        arr
  main
        new_arr
                                 20
---
   Arrays in Memory
1.  Create an eight element array.
2.  Copy the elements of the old array into the new array.
                       IN MEMORY
          Stack                                Heap
                                            4 33 24 -9
        arr
  main
        new_arr                            4 33 24 -9
                                 21
---
   Arrays in Memory
1.  Create an eight element array.
2.  Copy the elements of the old array into the new array.
3.  Recycle the old array.
                       IN MEMORY
          Stack                                Heap
                                            4 33 24 -9
        arr
  main
        new_arr                            4 33 24 -9
                                 22
---
  Arrays in Memory
1.  Create an eight element array.
2.  Copy the elements of the old array into the new array.
3.  Recycle the old array.
4.  Reassign arr to new array
                     IN MEMORY
         Stack                             Heap
                                        4 33 24 -9
       arr
  main
       new_arr                          4 33 24 -9
                              23
---
What’s Going On
• Now arr can eﬀectively store twice as many elements!
  ‣  Thanks to pointers and the heap
• Pointers give us indirection
  ‣  arr is not the array, it is the address of the array
  ‣  By changing that address, from the perspective of users of arr,
     we have eﬀectively changed the array
• The heap gives us dynamic memory allocation
  ‣  We can create and delete memory however we see fit
• Arrays that can change in size are some times called
  ArrayLists
                            24
---
Implementation
•  There’s a number of steps to growing an array
   ‣  Allocate a new, larger array
   ‣  Copy elements over
   ‣  Recycle old array
•  The client shouldn’t have to worry about all of this
                            25
---
Implementation
•  There’s a number of steps to growing an array
   ‣  Allocate a new, larger array
   ‣  Copy elements over
   ‣  Recycle old array
•  The client shouldn’t have to worry about all of this
•  Abstraction to the rescue!
   ‣  Encapsulate all of an ArrayList’s data and functions in a class
   ‣  Only provide the client with operations they need to know about
                            25
---
Implementation
•  Let’s implement a mini ArrayList:
   ‣  IntArrayList.cpp
   ‣  IntArrayList.h
   ‣  ArrayList_client.cpp
                            26
---
ArrayLists
• Now we see how we can use indirection to eﬀectively
   have lists
•  Growable arrays are featured in many languages, and
   they go by many diﬀerent names:
   ‣  Lists in Python
   ‣  Arrays in Ruby, JavaScript
   ‣  ArrayLists in Java
   ‣  …
•  In fact, C++ includes its own implementation…
                            27
---
 C++ Vectors
 •  Vectors are very similar to arrays, except they can
    grow and shrink in size
#include <iostream>
#include <vector>
using namespace std;
int main()
{
  vector<string> names; // creates vector. no size necessary!
  names.push_back("alice");  // adds element
  names.push_back("bob"); // adds element
  names.push_back("carol");  //adds element
…
                             28
---
C++ Vectors
•  Let’s see more: vectors.cpp
•  See course reference page for more vector docs
                        29
---
CS 15: Data Structures
      AVL Trees
---
BST Insertion Review
•  Insert into a BST (in this order): 8, 7, 6, 5, 4, 3, 2
•  What does the resulting tree look like?
                           2
---
BST Insertion Review
•  Insert into a BST (in this order): 8, 7, 6, 5, 4, 3, 2
•  What does the resulting tree look like?
                                   8
                           3
---
BST Insertion Review
•  Insert into a BST (in this order): 8, 7, 6, 5, 4, 3, 2
•  What does the resulting tree look like?
                                      8
                                  7
                              4
---
BST Insertion Review
•  Insert into a BST (in this order): 8, 7, 6, 5, 4, 3, 2
•  What does the resulting tree look like?
                                      8
                                  7
                              6
                              5
---
BST Insertion Review
•  Insert into a BST (in this order): 8, 7, 6, 5, 4, 3, 2
•  What does the resulting tree look like?
                                              8
                                        7
                                   6
                              5
                         4
                     3
                2                  6
---
BST Insertion Review
•  Say we want to access node 2. Have to traverse entire
   tree!
                                              8
                                        7
                                   6
                              5
                         4
                     3
                2                  7
---
BST Insertion Review
•  Ideally, we would get a more balanced tree:
                                   5
                         3                     7
                  2           4          6          8
                                   8
---
BST Complexity
• We have seen a number of BST operations whose
   complexity depends on the height of the tree
   ‣  contains, min, insert, remove, …
   ‣  O(log n) when tree is well-balanced
   ‣  O(n) in the general case
•  We want an approach to BST insertion/removal that
   guarantees tree is well-balanced
                           9
---
How much faster is log n?
                      log₂(n)           n
         n=1             1              1
         n=10            4             10
        n=100            7             100
        n=1,000         10            1,000
      n=1,000,000       20          1,000,000
     n=1,000,000,000    30         1,000,000,000
                         10
---
BST Balance
•  A number of strategies exist for ensuring BST balance:
   ‣  AVL trees: we’ll focus on these
   ‣  Red-Black trees
   ‣  2-3 trees
   ‣  Splay trees
   ‣ …
                              11
---
AVL Trees
• Invented by Adelson-Velsky and Landis
•  AVL trees are self-balancing
   ‣ If the tree ever gets out of balance, it automatically re-balances
•  Want fast (O(1)) way to restore balance
                        12
---
AVL Trees: Balance
•  Not every tree can be perfectly well-balanced
   ‣  Only trees containing exactly 2ᵏ - 1 nodes can be perfectly
      balanced (this is called a perfect binary tree)
                                    20
                          15                25
                    1         16      23         27
•  Instead, AVL trees restrict how out-of-balance a tree
   can get
                                  13
---
AVL Balance Invariant
•  AVL trees enforce the BST invariant, plus:
•  For every node in a non-empty tree, the node’s left and
   right subtrees can diﬀer in height by at most 1
   ‣ balance factor = abs(left subtree height - right subtree height)
   ‣ For all nodes in AVL tree: balance factor ≤ 1
•  Recall:
   ‣  height of empty tree = -1
   ‣  height of any leaf = 0
   ‣  height of arbitrary node = length of longest path to a leaf
                            14
---
Is this an AVL tree?
                              AVL tree?
                            15
---
Is this an AVL tree?
                        7
                       Yes!
           Each subtree has height -1,
                balance factor is 0
                        16
---
Is this an AVL tree?
                               42
                      17              84
                 height = 0        height = 0
                            Yes!
                all nodes match AVL and
                      BST invariants
                              17
---
Is this an AVL tree?
                         42
                  17            0
                        No!
              BST invariant violated,
             and all AVL trees are BSTs
                         18
---
Is this an AVL tree?
                               5
             height = 2  2           8 height = 1
                 1        4       7
        height = 0      height = 1  height = 0
                     3
                 height = 0
                            Yes!
         It’s a BST, and every node’s subtrees
              differ in height by at most 1
                              19
---
Is this an AVL tree?
                               5
             height = 2  2           8 height = 0
                 1        4
        height = 0      height = 1
                     3
                 height = 0
                             No!
       Node 5 is out of balance, since subtree
                   heights differ by > 1
                              20
---
Is this an AVL tree?
                         5
                    4        6
                3                7
            2          No!           8
      Though node 5 matches AVL invariant,
      nodes 4 and 6 don’t, e.g., node 4’s left
     subtree has height 1, but its right subtree
    is empty, so it has height -1. This difference
                is greater than 1.
                        21
---
AVL Trees
• One tweak we must make to implement AVLs: we store
   each node’s height inside node
•  This way we can access any node’s height in O(1) time
•  Must be careful to correctly update heights whenever
   tree changes
                struct Node {
                    int    data;
                    int    height;
                    Node  *left;
                    Node  *right;
                };
                        22
---
   AVL Trees: insert
   •  AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree
                                     5
                           2               8
                      1         4       7
                           3
                                    23
---
   AVL Trees: insert
   • AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree                             6 > 5
                                   5
                          2               8
                     1        4       7
                          3
                                  24
---
   AVL Trees: insert
   • AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree                             6 < 8
                                   5
                          2               8
                     1        4       7
                          3
                                  25
---
   AVL Trees: insert
   • AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree                             6 < 7
                                   5
                          2               8
                     1        4       7
                          3
                                  26
---
   AVL Trees: insert
   •  AVL insertion    first performs standard BST insertion
insert 6 into this AVL tree
                                     5
                           2               8
                      1         4       7
                           3         6
                                    27
---
AVL Trees: insert
•  Notice: our tree is now out of balance
   ‣ balance factor of node 8 is now 2
• Need to re-balance. Can you see how?
                                    5
                          2                8
                    1          4        7
                         3          6
                                   28
---
AVL Trees: insert
•  Notice: our tree is now out of balance
   ‣ balance factor of node 8 is now 2
• Need to re-balance. Can you see how?
                               5
                       2             7
                 1        4       6       8
                      3
            Let’s figure out how to automate this…
                              29
---
Insertion: Some Observations
•  Notice: only nodes on the path to newly inserted node can
   be out of balance
   ‣  All other nodes’ subtrees were untouched, so their balance factors
      remain the same
•  An out-of-balance node will be out of balance by exactly 2
   ‣  By AVL invariant, node’s balance factor was at most 1 before insert
   ‣  1 additional node can change height of subtree by at most 1
•  Therefore, only need to look down 2 levels to solve out of
   balance tree
   ‣  Always 2 levels, independent of tree size. This is O(1)!
                              30
---
Rebalancing after insert
•  After inserting: starting from inserted node, move up
   tree and   find  first node (if any) that is out-of-balance
                                       5
                             2                8
                      1          4        7
                            3          6
                                   31
---
Rebalancing after insert
•  After inserting: starting from inserted node, move up
   tree and   find  first node (if any) that is out-of-balance
                                       5
                             2                8
                      1          4        7
                            3          6
                                   32
---
Rebalancing after insert
•  After inserting: starting from inserted node, move up
   tree and   find  first node (if any) that is out-of-balance
                                       5
                             2                8
                      1          4        7
                            3          6
                                   33
---
Rebalancing after insert
• How do we check balance factors “moving up” the
   tree? By leveraging recursive calls!
      Node* insert(Node  *node, val):
           if (node == nullptr): node =  newNode(val)
           else if (val  < node->data):
                node->left =  insert(node->left, val)
           else:
                node->right   = insert(node->right, val)
           ~~  update height  of node ~~
           ~~  check balance of node ~~
           return node;
                              34
---
Rebalancing after insert
• This is the subtree that we need to rebalance
      Next: Determine which “imbalance case”
               the subtree falls under
                         8
                    7
                  6
                         35
---
    AVL Cases: Implementation
    •  There are four cases for an out-of-balance node:
    1.  New node was inserted into left child’s left subtree (LL)
    2.  New node was inserted into right child’s right subtree (RR)
    3.  New node was inserted into right child’s left subtree (RL)
    4.  New node was inserted into left child’s right subtree (LR)
How do we figure out which case applies?
  •  if height(node->left) > height(node->right), then:
     ‣ if height(node->left->left) > height(node->left->right): LL
  • ‣ else: LR
     else …
                                36
---
AVL Cases
• “outside” cases are
   easier
• Handle them with a
  single rotation
                         37
---
AVL Tree: Rebalancing
•  This is an LL case: 6 was inserted into 8’s left
   child’s left subtree
•  Fix it with a single rotation to the right
                               8
                          7
                       6
                              38
---
AVL Tree: Rebalancing
•  This is an LL case: 6 was inserted into 8’s left
   child’s left subtree
•  Fix it with a single rotation to the right
                               7
                          6         8
                              39
---
LL Rebalancing: General Case
•  Circles are nodes, triangles are subtrees
• k₂ out of balance due to LL insertion: left subtree
   height (starting at k₁) now 2 greater than right subtree
             k₂
      k₁             Z
             Y
X
                              40
---
LL Rebalancing: General Case
• Make k₁ new root of tree
  ‣  Whatever previously pointed to k₂ now points to k₁
             k₂                                   k₁
      k₁             Z                                   k₂
                                        X
             Y                                       Y         Z
X
                               41
---
LL Rebalancing: General Case
• k₂ now the right child of k₁
   ‣  This satisfies BST invariant, since (by previous tree) k₂ must
      have been greater than k₁
              k₂                                     k₁
       k₁              Z                                     k₂
                                          X
              Y                                          Y         Z
X
                                 42
---
LL Rebalancing: General Case
• k₂’s left subtree is now Y
   ‣  This satisfies BST invariant, since (by previous tree) all nodes
      in Y must have been greater than k₁ but less than k₂
              k₂                                     k₁
       k₁              Z                                     k₂
                                          X
              Y                                          Y          Z
X
                                 43
---
LL Rebalancing: General Case
•  Notice: we decreased left subtree height by 1,
   increased right subtree height by 1
   ‣ Because original height diﬀerence was 2, now diﬀerence is 0!
             k₂                                  k₁
      k₁             Z                                  k₂
                                       X
             Y                                      Y         Z
X
                              44
---
LL Rebalancing: General Case
•  This is called a single right rotation at k₂ because we
   “rotated” the nodes rightward to rebalance
             k₂                                  k₁
      k₁             Z                                  k₂
                                       X
             Y                                      Y         Z
X
                              45
---
LL Rebalancing: Complexity?
•  Had to update three pointers: original pointer to k₂,
   k₁’s right pointer, and k₂’s left pointer
•  Have to update heights of k₁ and k₂
                            O(1)!
             k₂                                   k₁
      k₁             Z                                   k₂
                                       X
             Y                                       Y         Z
X
                              46
---
LL Rebalancing: Recap
1.  Perform standard BST insertion.
2.  Moving from newly inserted node up to root,        find the
    first node (if any) that is out-of-balance.
3.  Perform single right rotation:
             k₂                                  k₁
      k₁             Z                                  k₂
                                       X
             Y                                       Y        Z
X
                              47
---
Practice Question
•  Insert 12 into the below AVL tree
   ‣  Remember: Once you find the out-of-balance node, you
      only need to look down two levels!
      -  i.e., all changes take place within two levels of out-of-balance node
                              50
                 20                  70
       10                 40      60       80
  5          15     30
                                   48
---
Solution
•  First, perform a standard BST insert
                              50
                 20                  70
       10                 40      60       80
  5          15     30
       12                          49
---
Solution
• Moving up from the new node,              find  first node (if
   any) that is out of balance
                              50
                 20                  70
       10                 40      60       80
  5          15     30
       12                          50
---
Solution
• Moving up from the new node,            find  first node (if
   any) that is out of balance
   ‣  Identify out-of-balance case. This is LL insertion!
                                         Balance factor = 2.
                             50         50 is out of balance!
                 20                70
       10                40     60       80
  5          15     30
       12                        51
---
Solution
•  Perform single right rotation to re-balance tree
                           20
             10                         50
       5          15            40             70
             12            30              60       80
                                   52
---
  RR Case
  • The RR Case is completely symmetrical
  • Re-balance by performing a single left rotation
        k₁                                        k₂
X             k₂                           k₁               Z
         Y                            X          Y
                    Z
                                53
---
AVL Cases
     Outside cases
?   LR and RL?
                       54
---
LR Case
• k₂ out of balance due to insertion in left child's right subtree
              k₂
       k₁              Z
 X
             Y
                              55
---
LR Case
•  Notice: Y must have at least one node
   ‣  We determined k₂ was out-of-balance because of LR insertion:
      -  k₂’s left subtree height 2 greater than right subtree
      -  k₁’s right subtree height 1 greater than left subtree ⇒ Y has at least one node
                k₂
         k₁               Z
 X
               Y
                                   56
---
LR Case
•  We can replace Y with a node k₃ and two (possibly empty)
   subtrees
              k₂
       k₁             Z
 X           k₃
         A         B
                              57
---
LR Case: Approach #1
•  One solution: just rewrite all the pointers in a way that
   balances the tree, satisfies BST invariant
                k₂                                         k₃
        k₁                Z                         k₁            k₂
 X             k₃                           X         A         B         Z
          A           B
                                   58
---
LR Case: Approach #1
•  If this solution works for you, then great!
   ‣ But it’s a bit unintuitive. Can we be more systematic?
                k₂                                         k₃
        k₁                Z                         k₁            k₂
 X             k₃                           X         A         B         Z
          A           B
                                   59
---
LR Case: Approach #2
•  An alternative approach is called a double rotation
   ‣  Key idea: Rotate once to get tree in a “familiar” state, rotate
      again to balance
              k₂
       k₁             Z
 X           k₃
         A         B
                              60
---
   LR Case: Approach #2
                k₂                                              k₂
        k₁               Z                               k₃              Z
 X             k₃                                 k₁            B
          A          B                      X            A
First, perform left rotation at k₁
                                      61
---
  LR Case: Approach #2
             k₂                                        k₂
      k₁             Z                           k₃            Z
X           k₃                             k₁          B
       A         B                    X          A
                              Notice: k₂ now out of balance
                              because left child’s left subtree is
         Now what?            heavy (LL). We can solve this!
                                62
---
    LR Case: Approach #2
                   k₂                                   k₃
              k₃           Z                   k₁             k₂
        k₁         B                      X        A       B      Z
  X           A
                                                     Balanced!
Perform right rotation at k₂
                                  63
---
LR Case: Recap
•  Recap: for LR case, we perform a double rotation
   ‣  First, perform left rotation at k₁
   ‣  Then, perform right rotation at k₂
                k₂
        k₁                Z
 X             k₃
          A           B
                                   64
---
RL Case: Mirror Image
•  Once again, the RL case is symmetric
   ‣  For out of balance node k:
      -  First perform right rotation at k->right
      -  Then perform left rotation at k
                            65
---
AVL: Removal
•  Node removal is a lot like insertion
   ‣  First perform standard BST removal
   ‣  Next, figure out where the extra weight lies: left child’s left
      subtree (LL), LR, RL, or RR
   ‣  Apply appropriate rotation(s) to re-balance tree
                              66
---
AVL Insertion Practice
•  Former exam question: Insert into an empty AVL tree
   2 1 4 5 9 3 7. Draw the tree after each insertion.
                         67
---
AVL Insertion Practice
•  Former exam question: Insert into an empty AVL tree
   2 1 4 5 9 3 7. Draw the tree after each insertion.
•  You can try it out using AVL visualization site:
http://www.cs.usfca.edu/~galles/visualization/
AVLtree.html
                          68
---
AVL: More Practice
•  At home, using the website (http://www.cs.usfca.edu/
   ~galles/visualization/AVLtree.html) try the following
   insertion sequences:
   ‣  Insert 3 2 1 4 5 6 7
   ‣  Insert 16 15 14 13 12 11 10 8 9
• Before each insertion, draw the tree you expect,
   then do the insertion on the website to check your
   work.
•  Over time, the tree rotations will become more intuitive
                        69
---
CS 15: Data Structures
  The C++ “Big Three”
---
A Quick Detour: References
•  If you took CS 11, you likely saw two ways of passing
   arguments to functions:
   ‣  Pass by value
   ‣  Pass by reference
                             2
---
  Pass by Value
  • In C++ most types are, by default, passed by value:
int main()
{
    int x = 5;
    func(x);
    cout << "x is now " << x;
    return 0;
}
void func(int x)
{
    x = x + 1;
}
                            3
---
  Pass by Value
  • In C++ most types are, by default, passed by value:
int main()
{
    int x = 5;
    func(x);                  This prints “x is now 5”. With
    cout << "x is now "  << x; pass by value, the value is copied
    return 0;                 when  it is passed to a function.
}                             Draw a memory diagram to
void func(int x)              visualize.
{
    x = x + 1;
}
                             3
---
  Pass by Value
   • In C++ most types are, by default, passed by value:
int main()
{
    int x = 5;
    func(x);
    cout << "x is now "  << x;
    return 0;
}
void func(int x)                        x           5
{
    x = x + 1;
}
                                       main()
                             4
---
  Pass by Value
   • In C++ most types are, by default, passed by value:
int main()
{
    int x = 5;                          x           5
    func(x);
    cout << "x is now "  << x;
    return 0;
}                                      func()
void func(int x)                        x           5
{
    x = x + 1;
}
                                       main()
                             4
---
  Pass by Value
   • In C++ most types are, by default, passed by value:
int main()
{   int x = 5;                          x         6 5
    func(x);
    cout << "x is now "  << x;
    return 0;
}                                      func()
void func(int x)                        x           5
{
    x = x + 1;
}
                                       main()
                             4
---
  Pass by Value
   • In C++ most types are, by default, passed by value:
int main()
{   int x = 5;                          x         6 5
    func(x);
    cout << "x is now "  << x;
    return 0;
}                                      func()
void func(int x)                        x           5
{
    x = x + 1;
}
                                       main()
                             4
---
  Pass by Value
   • In C++ most types are, by default, passed by value:
int main()
{
    int x = 5;
    func(x);
    cout << "x is now "  << x;
    return 0;
}
void func(int x)                        x           5
{
    x = x + 1;
}
                                       main()
                             4
---
      Arrays: Pass by Reference
      •  In C++, arrays are passed by reference. This means the
         address of the array is passed to a function:
int  main()
{
     char  arr[3] = {'a', 'b',  'c'};
     func(arr);
     cout  << "arr[1] is now "  << arr[1];
     return  0;
}
void  func(char arr[])
{
     arr[1]  = 'z';
}
                                 5
---
      Arrays: Pass by Reference
      •  In C++, arrays are passed by reference. This means the
         address of the array is passed to a function:
int  main()
{
     char  arr[3] = {'a', 'b',  'c'};
     func(arr);
     cout  << "arr[1] is now "  << arr[1];
}    return  0;                  This prints “arr[1] is now z”.
void  func(char arr[])           Draw a memory diagram to
{    arr[1]  = 'z';              visualize.
}
                                 5
---
      Arrays: Pass by Reference
      •  In C++, arrays are passed by reference. This means the
         address of the array is passed to a function:
int  main()
{
     char  arr[3] = {'a', 'b',  'c'};
     func(arr);
     cout  << "arr[1] is now "  << arr[1];
     return  0;
}
                                               arr    {‘a’, ‘b’, ‘c’ }
void  func(char arr[])
{
     arr[1]  = 'z';
}
                                              main()
                                 6
---
      Arrays: Pass by Reference
      •  In C++, arrays are passed by reference. This means the
         address of the array is passed to a function:
int  main()                                    arr
{
     char  arr[3] = {'a', 'b',  'c'};
     func(arr);
     cout  << "arr[1] is now "  << arr[1];
}    return  0;                               func()
                                               arr    {‘a’, ‘b’, ‘c’ }
void  func(char arr[])
{
     arr[1]  = 'z';
}
                                              main()
                                 6
---
      Arrays: Pass by Reference
      •  In C++, arrays are passed by reference. This means the
         address of the array is passed to a function:
int  main()                                    arr
{
     char  arr[3] = {'a', 'b',  'c'};
     func(arr);
     cout  << "arr[1] is now "  << arr[1];
}    return  0;                               func()
                                               arr    {‘a’, ‘z’, ‘c’ }
void  func(char arr[])
{
     arr[1]  = 'z';
}
                                              main()
                                 7
---
      Arrays: Pass by Reference
      •  In C++, arrays are passed by reference. This means the
         address of the array is passed to a function:
int  main()                                    arr
{
     char  arr[3] = {'a', 'b',  'c'};
     func(arr);
     cout  << "arr[1] is now "  << arr[1];
}    return  0;                               func()
                                               arr    {‘a’, ‘z’, ‘c’ }
void  func(char arr[])
{
     arr[1]  = 'z';
}
                                              main()
                                 7
---
      Arrays: Pass by Reference
      •  In C++, arrays are passed by reference. This means the
         address of the array is passed to a function:
int  main()
{
     char  arr[3] = {'a', 'b',  'c'};
     func(arr);
     cout  << "arr[1] is now "  << arr[1];
     return  0;
}
                                               arr    {‘a’, ‘z’, ‘c’ }
void  func(char arr[])
{
     arr[1]  = 'z';
}
                                              main()
                                 7
---
      Other Values: Pass by Reference
      •  In CS 11, you learned about pointers which allow us to
         eﬀectively pass any value by reference:
int  main()
{
     int example_var = 42;
     func(&example_var);
     cout << "example_var is now " << example_var;
     return 0;
}
void  func(int *x)
{
     *x = *x + 1;
}
                                   8
---
      Other Values: Pass by Reference
      •  In CS 11, you learned about pointers which allow us to
         eﬀectively pass any value by reference:
int  main()
{
     int example_var = 42;
     func(&example_var);
     cout << "example_var is now " << example_var;
}    return 0;               func takes a pointer to an int.
                        Here, * signifies x’s type is “int pointer.”
void  func(int *x)
{
     *x = *x + 1;
}
                                   8
---
      Other Values: Pass by Reference
      •  In CS 11, you learned about pointers which allow us to
         eﬀectively pass any value by reference:
int  main()
{
     int example_var = 42;
     func(&example_var);
     cout << "example_var is now " << example_var;
}    return 0;               func takes a pointer to an int.
                        Here, * signifies x’s type is “int pointer.”
void  func(int *x)
{
     *x = *x + 1;
}                  To use x’s value, we dereference it.
                   Here, * is the dereference operator.
                                   8
---
      Other Values: Pass by Reference
      •  In CS 11, you learned about pointers which allow us to
         eﬀectively pass any value by reference:
int  main()                   We pass func an integer pointer, i.e.,
{    int example_var = 42;    the address of an int variable. Here,
     func(&example_var);         & is the “address of” operator.
     cout << "example_var is now " << example_var;
     return 0;
}
void  func(int *x)
{
     *x = *x + 1;
}
                                   9
---
      Other Values: Pass by Reference
      •  In CS 11, you learned about pointers which allow us to
         eﬀectively pass any value by reference:
int  main()
{
     int example_var = 42;
     func(&example_var);
     cout << "example_var is now " << example_var;
     return 0;
}
void  func(int *x) This program will print out
{
}    *x = *x + 1;    “example_var is now 43”.
                  Draw the diagram for clarity.
                                   10
---
Reference Parameters
•  In CS 11, you may not have learned about reference
   parameters
•  We declare a reference parameter by adding a & before
   a parameter’s name:
              void func(int &x)
              {
                 …
              }
                      11
---
Reference Parameters
•  When a reference parameter is used, the address (not
   the value) of an argument is automatically passed to
   the function
              void  func(int &x)
              {
                 x  = x + 1;
              }
•  We then can use x as if it is a normal int (not an int
   pointer). No need to dereference!
                      12
---
    Reference Parameters
int main()
{
    int ex_var = 42;
    func(ex_var);
    cout << "ex_var is now "
         << ex_var;
    return 0;
}
void func(int &x)
{
    x = x + 1;
}
                              13
---
    Reference Parameters
int main()
{
    int ex_var = 42;
    func(ex_var);
    cout << "ex_var is now "
         << ex_var;
    return 0;
}
void func(int &x)
{
    x = x + 1;
}                   Notice: func takes a reference
                              13
---
    Reference Parameters
int main()
{   int ex_var =  42;  We pass int vars the same way
                      we would without references—
    func(ex_var);   but its address is being passed!
    cout << "ex_var is now  "
         << ex_var;
    return 0;
}
void func(int &x)
{
    x = x + 1;
}                    Notice: func takes a reference
                              13
---
    Reference Parameters
int main()
{   int ex_var = 42;  We pass int vars the same way
                     we would without references—
    func(ex_var);  but its address is being passed!
    cout << "ex_var is now "
         << ex_var;
    return 0;                    This program prints
}                                 “ex_var is now 43”
void func(int &x)
{
    x = x + 1;
}                   Notice: func takes a reference
                              13
---
    Reference Parameters
int main()                       int  main()
{                                {
    int ex_var = 42;                  int ex_var = 42;
    func(ex_var);                     func(&ex_var);
    cout << "ex_var is now "          cout << "ex_var is now "
         << ex_var;                       << ex_var;
    return 0;                         return 0;
}                                }
void func(int &x)                void func(int *x)
{                                {
    x = x + 1;                       *x = *x + 1;
}                                }
         These two programs are equivalent!
                              14
---
References
• If you understand pointers, you understand references!
                        15
---
References
•  If you understand pointers, you understand references!
•  With reference parameters, just label the parameter as
   a reference with &
                          15
---
References
•  If you understand pointers, you understand references!
•  With reference parameters, just label the parameter as
   a reference with &
   ‣  When we pass in variables, the address of the variable is
      automatically passed
                          15
---
References
•  If you understand pointers, you understand references!
•  With reference parameters, just label the parameter as
   a reference with &
   ‣  When we pass in variables, the address of the variable is
      automatically passed
   ‣  When we use the reference parameter, it is automatically
      dereferenced
                            15
---
References
•  If you understand pointers, you understand references!
•  With reference parameters, just label the parameter as
   a reference with &
   ‣  When we pass in variables, the address of the variable is
      automatically passed
   ‣  When we use the reference parameter, it is automatically
      dereferenced
•  In sum: reference parameters are an easy way for a
   function caller and callee to share the same variable
                          15
---
Returning References
•  Can functions return references to values?
•  Yes! But it must be a reference to something that exists
   beyond the lifetime of the function
   ‣ i.e., you should not return local variable references
                          16
---
One more aside: this pointer
•  In all class functions, a variable named this is available
•  It is a pointer to the object the function is called on
                         17
---
One more aside: this pointer
•  In all class functions, a variable named this is available
•  It is a pointer to the object the function is called on
                                     class Employee {
                                     public:
                                      float get_income();
                                     private:
                                       // Member variables
                                       float  base_salary;
                                       int overtime_hours;
                                       float  overtime_rate;
                                     };
                           17
---
    One more aside: this pointer
    •  In all class functions, a variable named this is available
    •  It is a pointer to the object the function is called on
                                      class Employee {
Employee e1;                          public:
e1.get_income()                        float get_income();
                                      private:
…                                            // Member variables
                                             float  base_salary;
float Employee::get_income()                 int overtime_hours;
{                                     };float       overtime_rate;
     // inside here, “this” is  a  pointer  to e1
     // the  following two  lines  are equivalent:
     return  base_salary +  overtime_hours  * overtime_rate;
     return  this->base_salary  +  this->overtime_hours *
                                   this->overtime_rate;
}
                                17
---
The Big Three
---
The Big Three
•  As we’ll see, weird behavior can occur when classes/
   structs use heap-allocated memory
•  To resolve this, we need to define three special functions:
     ‣  Overloaded assignment operator
     ‣  Copy constructor
     ‣  Destructor
• Let’s take a look!
                           19
---
Example Person Class
•  Notice:                   class Person  {
                             public:
   ‣  name is string             Person()  {
                                     name  = "";
   ‣                                 age  =  new  int;
      age is int*                }   *age  = -1;
                                 Person(string    newName, int newAge) {
                                     name  = newName;
                                     age  =  new  int;
                                     *age  = newAge;
                                 }
                                 void print() {   cout <<  name <<  " is  " <<
                                          *age <<  " years old." << endl;    }
                                 void setName(string newName) {     name  = newName; }
                                 void setAge(int   newAge) {  *age  =  newAge; }
                             private:
                                 // Just to see    the  different behavior,
                                 // let's  let age be   a pointer,
                                 // while  name is   a  non-pointer.
                                 string name;
                                 int *age;
                             };
                                     20
---
       Example Person Class
                                    class Person  {
                                    public:
                                        Person()  {
                                            name  = "";
 int  main()                                age  =  new  int;
 {                                          *age  = -1;
      Person p1("Alice", 30);           }
      p1.print();
                                        Person(string    newName, int newAge) {
      // let's play with assignment         name  = newName;
      Person p2;                            age  =  new  int;
      p2 = p1;                              *age  = newAge;
      p2.setName("Carol");              }
      p2.setAge(40);
                                        void print() {   cout <<  name <<  " is  " <<
      // what prints  now?                       *age <<  " years old." << endl;    }
      cout << "After  assignment:\n”;   void setName(string newName) {     name  = newName; }
      p1.print();                       void setAge(int   newAge) {  *age  =  newAge; }
      p2.print();
                                    private:
      return 0;                         // Just to see    the  different behavior,
}                                       // let's  let age be   a pointer,
                                        // while  name is   a  non-pointer.
                                        string name;
                                        int *age;
                                    };
                                            21
---
       Example Person Class
                       print out?
               will                 class Person  {
                                    public:
   What                                 Person()  {
                                            name  = "";
 int  main()                                age  =  new  int;
 {                                          *age  = -1;
      Person p1("Alice", 30);           }
      p1.print();
                                        Person(string    newName, int newAge) {
      // let's play with assignment         name  = newName;
      Person p2;                            age  =  new  int;
      p2 = p1;                              *age  = newAge;
      p2.setName("Carol");              }
      p2.setAge(40);
                                        void print() {   cout <<  name <<  " is  " <<
      // what prints  now?                       *age <<  " years old." << endl;    }
      cout << "After  assignment:\n”;   void setName(string newName) {     name  = newName; }
      p1.print();                       void setAge(int   newAge) {  *age  =  newAge; }
      p2.print();
                                    private:
      return 0;                         // Just to see    the  different behavior,
}                                       // let's  let age be   a pointer,
                                        // while  name is   a  non-pointer.
                                        string name;
                                        int *age;
                                    };
                                            21
---
Let’s Try
• shallow_example.cpp
                      22
---
       Result
 int  main()
 {
      Person p1("Alice", 30);               After assignment p2=p1,
      p1.print();
      // let's play with assignment    p2.setName only changed p2’s
      Person p2;                       name, but p2.setAge changed
      p2 = p1;
      p2.setName("Carol");                   *both* p1 and p2’s age
      p2.setAge(40);
      // what prints  now?                                Why?
      cout << "After  assignment:\n”;
      p1.print();
      p2.print();
      return 0;
}
                                            23
---
Shallow Copy
•  When copying a class/struct instance, by default,
   C++ performs a shallow copy
   ‣ All member variable values are copied, but no “deeper”
•  When a member variable is a pointer, C++ will copy
   the address stored in the variable, but not what is
   being pointed to
• Let’s see a memory diagram
                         24
---
       Shallow Copy in Memory
 int  main()                                     Stack                    Heap
 {
      Person p1("Alice", 30);
      p1.print();
      // let's play with assignment
      Person p2;
      p2 = p1;
      p2.setName("Carol");
      p2.setAge(40);
      // what prints  now?
      cout << "After  assignment:\n”;         main()
      p1.print();
      p2.print();
      return 0;
}
                                            25
---
       Shallow Copy in Memory
 int  main()                                     Stack                    Heap
 {
      Person p1("Alice", 30);
      p1.print();
      // let's play with assignment             p1    name   “Alice”         30
      Person p2;                                      age
      p2 = p1;
      p2.setName("Carol");
      p2.setAge(40);
      // what prints  now?
      cout << "After  assignment:\n”;         main()
      p1.print();
      p2.print();
      return 0;
}
                                            26
---
       Shallow Copy in Memory
 int  main()                                     Stack                    Heap
 {
      Person p1("Alice", 30);
      p1.print();
      // let's play with assignment             p1    name   “Alice”         30
      Person p2;                                      age
      p2 = p1;
      p2.setName("Carol");                      p2    name     “”
      p2.setAge(40);                                  age                     -1
      // what prints  now?
      cout << "After  assignment:\n”;         main()
      p1.print();
      p2.print();
      return 0;
}
                                            27
---
       Shallow Copy in Memory
 int  main()                                     Stack                    Heap
 {
      Person p1("Alice", 30);
      p1.print();
      // let's play with assignment             p1    name   “Alice”         30
      Person p2;                                      age
      p2 = p1;
      p2.setName("Carol");                      p2    name   “Alice”
      p2.setAge(40);                                  age                     -1
      // what prints  now?
      cout << "After  assignment:\n”;         main()
      p1.print();
      p2.print();
      return 0;
}
                                            28
---
       Shallow Copy in Memory
                   setName() rewrites the value of p2’s name variable
 int  main()                                    Stack                    Heap
 {
      Person p1("Alice", 30);
      p1.print();
      // let's play with assignment            p1     name   “Alice”        30
      Person p2;                                      age
      p2 = p1;
      p2.setName("Carol");                     p2     name   “Carol”
      p2.setAge(40);                                  age                    -1
      // what prints  now?
      cout << "After  assignment:\n”;         main()
      p1.print();
      p2.print();
      return 0;
}
                                            29
---
       Shallow Copy in Memory
                setAge() follows the pointer stored in p2’s age variable,
               changes value in heap. Also pointed to by p1’s age variable!
 int  main()                                    Stack                    Heap
 {
      Person p1("Alice", 30);
      p1.print();
      // let's play with assignment            p1     name   “Alice”        40
      Person p2;                                      age
      p2 = p1;
      p2.setName("Carol");                     p2     name   “Carol”
      p2.setAge(40);                                  age                    -1
      // what prints  now?
      cout << "After  assignment:\n”;         main()
      p1.print();
      p2.print();
      return 0;
}
                                            30
---
Trying to use a Destructor
•  Issue gets worse when we try to use a destructor
•  Recall: we need a destructor to recycle a class’
   heap-allocated memory
•  Let’s try to use this one:
            ~Person() { delete age; }
                        31
---
       Trying to use a Destructor
                         ~Person()       { delete       age; }
 int  main()                                    Stack                    Heap
 {
      Person p1("Alice", 30);
      p1.print();
      // let's play with assignment            p1     name   “Alice”        40
      Person p2;                                      age
      p2 = p1;
      p2.setName("Carol");                     p2     name   “Carol”
      p2.setAge(40);                                  age                    -1
      // what prints  now?
      cout << "After  assignment:\n”;         main()
      p1.print();
      p2.print();
      return 0;
}
                      Now that we have a destructor, our program will crash.
                                               Why?
                                            32
---
     Trying to use a Destructor
                    ~Person()    { delete     age; }
                                       Stack                Heap
•  Destructor called automatically          name  “Alice”      40
   when p2, p1 go out of scope (i.e.,  p1   age
   at the end of the main() function)
     ‣  Called in reverse order of     p2   name  “Carol”       -1
                                            age
        declaration (so, p2 first)
                                     main()
                                    33
---
     Trying to use a Destructor
                    ~Person()    { delete    age; }
                                       Stack               Heap
1)  Destructor called for p2  upon    p1   name  “Alice”      40
    exiting main().                        age
                                      p2   name  “Carol”      -1
                                           age
                                     main()
                                   34
---
     Trying to use a Destructor
                    ~Person()    { delete    age; }
                                       Stack               Heap
1)  Destructor called for p2  upon    p1   name  “Alice”      40
    exiting main().                        age
2)  Destructor called for p1.         p2   name  “Carol”      -1
                                           age
                                     main()
                                   35
---
     Trying to use a Destructor
                   ~Person()    { delete    age; }
                                      Stack               Heap
1)  Destructor called for p2 upon    p1   name  “Alice”     40
    exiting main().                       age
2)  Destructor called for p1.        p2   name  “Carol”      -1
                                          age
       Error: Memory at age’s address  main()
           was already recycled.
    This is called a double free error,
  and it will crash your program.
                                  35
---
       Solution: Deep Copy
 int  main()                       •  Shallow copy occurred on assignment
 {                                    p2   =   p1
      Person p1("Alice", 30);      •  Solution: C++ allows us to redefine
      p1.print();
      // let's play with assignment   (i.e., overload) the assignment operator
      Person p2;                      “=” for a particular class
      p2 = p1;
      p2.setName("Carol");         •
      p2.setAge(40);                  We will redefine “=” so it performs a
      // what prints  now?            deep copy
      cout << "After  assignment:\n”;
      p1.print();                     ‣  For pointers, it will copy the value pointed to
      p2.print();
      return 0;
}
                                            36
---
Overloaded Assignment Operator
                    p2 = p1;
    Person &Person::operator=(const Person &rhs)
    {
        if  (this == &rhs) {
             return *this;
        }
        *age  =  *rhs.age;
        name  =  rhs.name;
        return   *this;
    }
                        37
---
Overloaded Assignment Operator
                    p2 = p1;
                          This is a member function
                             of the Person class.
    Person &Person::operator=(const Person &rhs)
    {
        if  (this == &rhs) {
             return *this;
        }
        *age  =  *rhs.age;
        name  =  rhs.name;
        return   *this;
    }
                        37
---
Overloaded Assignment Operator
        “operator” tells C++ we are p2 = p1;
           defining an operator.
         “=” tells C++ the name of
               the operator.
    Person &Person::operator=(const Person &rhs)
    {
        if              (this == &rhs) {
                         return *this;
        }
        *age  =  *rhs.age;
        name  =  rhs.name;
        return   *this;
    }
                        38
---
Overloaded Assignment Operator
                     p2 = p1;
    Person &Person::operator=(const  Person &rhs)
    {
        if  (this == &rhs) {
             return *this;
        }                   Input is a reference to the
        *age  =  *rhs.age;  right hand side, e.g., p1 in
        name  =  rhs.name;     const this case.
        return   *this;        can’t  keyword means we
                                   make changes to the
    }                                parameter.
                         39
---
Overloaded Assignment Operator
                     p2 = p1; Return will be a reference
                             to the left hand side, i.e.,
                             p2. This allows for chaining
                            assignments, e.g., x = y = z.
    Person &Person::operator=(const  Person &rhs)
    {
        if  (this == &rhs) {
             return *this;
        }
        *age  =  *rhs.age;
        name  =  rhs.name;
        return   *this;
    }
                         40
---
Overloaded Assignment Operator
     First check if lhs and rhs  p2 = p1;
    are the same object. If so,
     return *this without doing
             anything.
    Person &Person::operator=(const  Person &rhs)
    {
        if           (this == &rhs) {
                      return *this;
        }
        *age  =  *rhs.age;
        name  =  rhs.name;
        return   *this;
    }
                         41
---
Overloaded Assignment Operator
      Copy the contents of rhs  p2 = p1;
     over to lhs. Notice we are
    doing a *deep* copy on age.
    Person &Person::operator=(const  Person &rhs)
    {
        if          (this == &rhs) {
                     return *this;
        }
        *age  =  *rhs.age;
        name  =  rhs.name;
        return   *this;
                                   Note: This code will only work if age
    }                              already points to some heap memory.
                                   If not, may need to allocate new memory.
                         42
---
Overloaded Assignment Operator
                    p2 = p1;
    Person &Person::operator=(const Person &rhs)
    {
        if  (this == &rhs) {
             return *this;
        }                         Return lhs.
        *age  =  *rhs.age;
        name  =  rhs.name;
        return   *this;
    }
                        43
---
      Deep Copy in Memory
Person &operator=(const Person &rhs)
{
    if (this == &rhs) {
        return *this;
    }
    *age  = *rhs.age;                           Stack                    Heap
    name  = rhs.name;
    return *this;
}                                                     name                  30
int  main()                                    p1            “Alice”
{    Person p1("Alice", 30);                          age
     p1.print();
     // let's play with assignment
     Person p2;
     p2 = p1;                                 main()
     p2.setName("Carol");
     p2.setAge(40);
     // what prints  now?
     cout << "After  assignment:\n”;
     p1.print();
     p2.print();
     return 0;
}                                          44
---
      Deep Copy in Memory
Person &operator=(const Person &rhs)
{
    if (this == &rhs) {
        return *this;
    }
    *age  = *rhs.age;                           Stack                    Heap
    name  = rhs.name;
    return *this;
}                                                     name                  30
int  main()                                    p1            “Alice”
{    Person p1("Alice", 30);                          age
     p1.print();                               p2     name    “”             -1
     // let's play with assignment                    age
     Person p2;
     p2 = p1;                                 main()
     p2.setName("Carol");
     p2.setAge(40);
     // what prints  now?
     cout << "After  assignment:\n”;
     p1.print();
     p2.print();
     return 0;
}                                          45
---
      Deep Copy in Memory
Person &operator=(const Person &rhs)
{
    if (this == &rhs) {
        return *this;
    }
    *age  = *rhs.age;                           Stack                    Heap
    name  = rhs.name;
    return *this;
}                                                    name                   30
int  main()                                    p1           “Alice”
{    Person p1("Alice", 30);                         age
     p1.print();                               p2    name   “Alice”          30
     // let's play with assignment                   age
     Person p2;
     p2 = p1;                                main()
     p2.setName("Carol");
     p2.setAge(40);
     // what prints  now?                                          We made a deep copy!
     cout << "After  assignment:\n”;                         p2’s age still points to its own
     p1.print();                                            place in memory, but we’ve copied
     p2.print();                                                      the value 30.
     return 0;
}                                          46
---
      Deep Copy in Memory
Person &operator=(const Person &rhs)
{
    if (this == &rhs) {
        return *this;
    }
    *age  = *rhs.age;                           Stack                    Heap
    name  = rhs.name;
    return *this;
}                                                     name                  30
int  main()                                    p1            “Alice”
{    Person p1("Alice", 30);                          age
     p1.print();                               p2     name  “Carol”          30
     // let's play with assignment                    age
     Person p2;
     p2 = p1;                                 main()
     p2.setName("Carol");
     p2.setAge(40);
     // what prints  now?
     cout << "After  assignment:\n”;
     p1.print();
     p2.print();
     return 0;
}                                          47
---
      Deep Copy in Memory
Person &operator=(const Person &rhs)
{
    if (this == &rhs) {
        return *this;
    }
    *age  = *rhs.age;                           Stack                    Heap
    name  = rhs.name;
    return *this;
}                                                     name                  30
int  main()                                    p1            “Alice”
{    Person p1("Alice", 30);                          age
     p1.print();                               p2     name  “Carol”          40
     // let's play with assignment                    age
     Person p2;
     p2 = p1;                                 main()
     p2.setName("Carol");
     p2.setAge(40);
     // what prints  now?
     cout << "After  assignment:\n”;
     p1.print();
     p2.print();
     return 0;
}                                          48
---
Copy Constructor
•  Assignment isn’t the only time a value gets copied
•  C++ gives us a way of creating a new instance of a
   class from an existing one:
                Person  p2(p1);
                        49
---
Copy Constructor
•  Assignment isn’t the only time a value gets copied
•  C++ gives us a way of creating a new instance of a
   class from an existing one:
                 Person   p2(p1);
•  This calls the copy constructor, which initializes
   p2 by making a copy of p1
   ‣ Just like assignment, by default this is a shallow copy
                         50
---
Copy Constructor
• Side note:  Person p2(p1);
              is equivalent to
            Person p2 = p1;
                   51
---
Copy Constructor
• Side note:     Person    p2(p1);
                   is equivalent to
                Person    p2  = p1;
   Because we are declaring
  the lhs, C++ uses the copy
  constructor instead of the
     assignment operator.
                          51
---
Copy Constructor: Function Calls
•  Copy constructor is also called for function calls:
   ‣  When we enter a function, the arguments are copied from
      the caller to the callee’s activation record
   ‣  When we exit a function, the return value is copied from
      the callee back to the caller’s activation record
             Person some_func(Person p)
             {
                 …some code…
                 return p;
             }
                       52
---
Copy Constructor
        Person::Person(const Person &other)
        {
            age = new int;
            *age  = *other.age;
            name  = other.name;
        }
                       53
---
Copy Constructor
                           Just like other
                          constructors, copy
                       constructor has the same
                          name as the class.
        Person::Person(const Person &other)
        {
            age = new int;
            *age  = *other.age;
            name  = other.name;
        }
                       53
---
Copy Constructor
            Just like assignment, input
            is a const reference to the
                  “other” Person.
        Person::Person(const Person &other)
        {
            age = new int;
            *age  = *other.age;
            name  = other.name;
        }
                       54
---
Copy Constructor
   Must allocate heap memory because
  we are creating a new Person (i.e., no
        heap space exists yet).
        Person::Person(const Person &other)
        {
            age = new int;
            *age  = *other.age;
            name  = other.name;
        }
                       55
---
Copy Constructor
   (deep) copy other’s contents.
        Person::Person(const Person &other)
        {
            age = new int;
            *age  = *other.age;
            name  = other.name;
        }
                       56
---
Destructor
•  The last of the big three—we know it already!
•  Use it to recycle any heap memory referred to by
   member variables
       ~Person::Person()  { delete age; }
                       57
---
The Big Three
•  Big Three
   ‣  Overloaded assignment operator
   ‣  Copy constructor
   ‣  Destructor
•  We call these the “big three” because any time you
   need to define one, you should define all three
• When are they needed?
                            58
---
The Big Three
•  Big Three
   ‣  Overloaded assignment operator
   ‣  Copy constructor
   ‣  Destructor
•  We call these the “big three” because any time you
   need to define one, you should define all three
• When are they needed?
   ‣  For any class where member variables use heap-allocated
      memory
                            59
---
The Big Three
• Let’s see them in action: deep_example.cpp
                        60